

# JAVA

## Java代码如何执行

### 执行方式

高级编程语言执行一般分为 编译 和 翻译两种执行方式。

#### 编译执行

​		将 源代码 转换成 机器语言，通常是 二进制形式(机器码) 并保存下来(复用)，等待执行。目的是生成 可执行的程序。
​		优点:
​			因为提前编译生成 机器码，所以直接执行 编译后的文件即可，因此速度较快。
​		缺点:
​			源代码编译后只能在该类机器上运行，无法跨平台。

#### 解释执行

​		在程序运行时，将源代码转换为 机器语言(机器码)，并立即执行。
​		工作模式:
​			1.分析源代码，并且直接执行。
​			2.把源代码翻译成相对更加高效率的中间码，然后立即执行它。
​			3.执行由解释器内部的编译器预编译后保存的代码。
​		优点:
​			跨平台性，因为无需编译，因此只要解释器支持多平台，就有跨平台性。
​		缺点:
​			运行速度慢，解释器要额外的开销。

### Java执行方式

源代码(.java) - javac -> 字节码(.class) - jvm -> 机器码。先通过javac编译为字节码(Java字节码指令被固定为一个字节)，执行时JVM将字节码解释为机器码(不同平台有对应的JVM，因此可以跨平台)。虚拟机另一个好处是带来一个托管环境(Managed Runtime)，可以帮我们处理一些代码冗余而且容易出错的部分，如内存管理和垃圾回收等。

运行时属于解释执行，为了提高运行效率(程序符合二八原则，20%的代码占用80%的资源)，JVM也提供了编译执行的方式。因此JVM属于混合执行，可通过JVM参数控制。

#### 编译执行机制		

###### JIT(Just In Time)

即时编译。运行时，以方法为单位，将频繁执行的热点代码编译为机器码保存起来(Code Cache，非堆区)，编译完成后(编译时还是以解释的方式执行，编译和解释执行可以并行)，后续调用则直接调用编译完成后的机器码，提高运行效率。

编译器:

​	C1:

​		client模式，将由1500次的收集计算出，启动性能好。

​	C2:

​		server模式，将根据10000次的收集计算出，峰值性能好。

​	Graal:

从Java7开始，HotSpot(JVM)默认采用分层编译的方式:热点方法先被C1编译，然后热点方法中的热点会被进一步被C2编译。为了不干扰应用的正常运行，即时编译是放在额外的编译线程中执行的。HotSpot会根据CPU的数据量设置编译线程的数据，并且按1:2的比例配置C1和C2的编译器。

理论上讲，即时编译后的Java程序的执行效率是可能超过C++的。这是因为和静态编译相比，即时编译拥有程序运行时信息，并且根据这个信息做出优化。

###### AOT(Ahead-of-Time Compilation)

运行之前，将应用中或JDK中的字节码编译成机器码(与即时编译器区别)



## 数据类型

Java语言中类型分为两大类，基本数据类型和引用类型。基本数据类型有八个，分别为boolean、byte、char、short、int、long、float、double。引用类型分为四种，分别为类、接口、数组、泛型，因为泛型是通过类型擦除(考虑到向后兼容)实现的，所有可以认为只存在前三种。

Java引入基本数据类型来支持数值计算，因为使用基本数据类型能够提高程序执行效率和减少内存占用。所有的计算操作都会被转换成整数运算。

| 类型    | 值域                 | 默认值   | 虚拟机内部符号 |
| ------- | -------------------- | -------- | -------------- |
| boolean | {false, true}        | false    | Z              |
| byte    | [-128, 128]          | 0        | B              |
| char    | [0, 65535]           | '\u0000' | C              |
| short   | [-32768, 32767]      | 0        | S              |
| int     | [-2^31, 2^31 - 1]    | 0        | I              |
| long    | [-2^63, 2^63 - 1]    | 0L       | J              |
| float   | ~[-3.4E38, 3.4E38]   | +0.0F    | F              |
| double  | ~[-1.8E308, 1.8E308] | +0.0D    | D              |

boolean在Java语言规范中使用true或false来表示，在JVM规范中，boolean会映射为int类型，true映射为1，false映射为0，编码规范约束了Java字节码的具体实现。

if(boolean) 会判断boolean是否为0，0就跳过。if(boolean == true)会判断boolean是否为1，不为1就跳过。



Java虚拟机每调用一个Java方法便会创建一个栈帧。在解释器的解释栈帧中，主要包括两个主要组成部分，分别是局部变量区()和字节码的操作数栈。这里的局部变量是广义的，除了普遍意义下的局部变量之外，它还包含实例方法的“this 指针”以及方法所接收的参数。

在 Java 虚拟机规范中，局部变量区等价于一个数组，并且可以用正整数来索引。除了 long、double 值需要用两个数组单元来存储之外，其他基本类型以及引用类型的值均占用一个数组单元。当然，这种情况仅存在于局部变量，而并不会出现在存储于堆中的字段或者数组元素上。

如将int类型的值存储到boolean类型时，为了保证堆中的 boolean 值是合法的，HotSpot 在存储时显式地进行掩码操作，也就是说，只取最后一位的值存入 boolean 字段或数组中。Java 虚拟机的算数运算几乎全部依赖于操作数栈。也就是说，我们需要将堆中的 boolean、byte、char 以及 short 加载到操作数栈上，而后将栈上的值当成 int 类型来运算。对于无符号类型，加载伴随着零扩展(高位补0)。对于有符号类型，加载伴随着符号扩展(类型值填充低字节，正数最高位补0，负数补1，其余全部补0)。

## Java类如何加载

### 类加载器

JDK8及之前

启动类加载器：加载最为基础、最为重要的类，如存放在JRE的lib目录下的jar包中的类(以及由虚拟机参数-Xbootclasspath指定的类)。由C++编写，在java代码中表现为null。

扩展类加载器：加载相对次要、但又通用的类，比如存放在JRE的lib\ext目录下jar包中的类(以及由系统变量java.ext.dirs指定的类)。

应用类加载器：负责加载应用程序路径下的类(指由虚拟机参数-cp/-classpath、系统环境变量java.class.path指定的路径)。默认情况下，应用程序中包含的类便是由应用类加载器加载的。

JDK9及现在(引入模块化)

启动类加载器：加载少数几个关键模块，如java.base。

平台类加载器：其他模块。

程序类加载器

### 双亲委派机制

每当一个类加载器接收到加载请求时，它会先将请求转发给父类加载器。在父类加载器没有找到所请求的类的情况下，该类加载器才会尝试去加载。

提供了隔离机制，在 Java 虚拟机中，类的唯一性是由类加载器实例以及类的全名一同确定的。即便是同一串字节流，经由不同的类加载器加载，也会得到两个不同的类。提供了安全机制，最核心的类(如String)由启动类加载器加载，不可被相同类名的文件破坏。

### 类加载过程

#### 加载：

​	根据类的全限定名将该类的字节码加载到内存，生成代表该类的Class对象

#### 链接：

​	将创建好的Class对象合并到JVM，使之能够执行的过程。

##### 验证：

​	确保被加载类能够满足 Java 虚拟机的约束条件。

##### 准备：

​	为被加载类的静态字段分配内存，并设置默认值。被final修饰的static字段不会设置，因为在编译时就分配了。

##### 解析：

​	将类成员的符号引用变成直接引用。如果符号引用指向一个未被加载的类，或者未被加载类的字段或方法，那么解析将触发这个类的加载（但未必触发这个类的链接以及初始化。）

#### 初始化：

​	执行类的构造器方法init()的过程。这个方法不需要定义，是javac编译器自动收集类中所有类变量的赋值动作和静态代码块中的语句合并来的。



类加载时不一定会触发初始化，只用主动使用类时，才会触发，如

1. 当虚拟机启动时，初始化用户指定的主类；
2. 当遇到用以新建目标类实例的 new 指令时，初始化 new 指令的目标类；
3. 当遇到调用静态方法的指令时，初始化该静态方法所在的类；
4. 当遇到访问静态字段的指令时，初始化该静态字段所在的类；
5. 子类的初始化会触发父类的初始化；
6. 如果一个接口定义了 default 方法，那么直接实现或者间接实现该接口的类的初始化，会触发该接口的初始化；
7. 使用反射 API 对某个类进行反射调用时，初始化这个类；
8. 当初次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的方法所在的类。

## Java如何执行方法调用

### Java方法调用

#### 重载

在 Java 程序里，如果同一个类中出现多个名字相同，但参数类型不同的方法，我们称之为重载。

重载的方法在编译过程中即可完成识别。具体到每一个方法调用，Java 编译器会根据所传入参数的声明类型（注意与实际类型区分）来选取重载方法。选取的过程共分为三个阶段：

1. 在不考虑对基本类型自动装拆箱（auto-boxing，auto-unboxing），以及可变长参数的情况下选取重载方法；
2. 如果在第 1 个阶段中没有找到适配的方法，那么在允许自动装拆箱，但不允许可变长参数的情况下选取重载方法；
3. 如果在第 2 个阶段中没有找到适配的方法，那么在允许自动装拆箱以及可变长参数的情况下选取重载方法。

如果 Java 编译器在同一个阶段中找到了多个适配的方法，那么它会在其中选择一个最为贴切的，而决定贴切程度的一个关键就是形式参数类型的继承关系。

除了同一个类中的方法，重载也可以作用于这个类所继承而来的方法。也就是说，如果子类定义了与父类中非私有方法同名的方法，而且这两个方法的参数类型不同，那么在子类中，这两个方法同样构成了重载。

#### 重写

如果子类具有一个和父类非私有方法的方法名，方法参数，方法返回值(可以不一致，但是必须是返回值的子类)一致的方法，如果是非静态的方法可以认为子类重写了父类方法，如果是静态方法，可以认为子类中的方法会隐藏掉父类的方法。

众所周知，Java 是一门面向对象的编程语言，它的一个重要特性便是多态。而方法重写，正是多态最重要的一种体现方式：它允许子类在继承父类部分功能的同时，拥有自己独特的行为。

### JVM方法调用

Java 虚拟机识别方法的关键在于类名、方法名以及方法描述符（method descriptor）。方法描述符是由方法的参数类型以及返回类型所构成。在同一个类中，如果同时出现多个名字相同且描述符也相同的方法，那么 Java 虚拟机会在类的验证阶段报错。

#### JVM 的静态绑定和动态绑定

Java 虚拟机与 Java 语言不同，它并不限制名字与参数类型相同，但返回类型不同的方法出现在同一个类中，对于调用这些方法的字节码来说，由于字节码所附带的方法描述符包含了返回类型，因此 Java 虚拟机能够准确地识别目标方法。

Java 虚拟机中关于方法重写的判定同样基于方法描述符。也就是说，如果子类定义了与父类中非私有、非静态方法同名的方法，那么只有当这两个方法的参数类型以及返回类型一致，Java 虚拟机才会判定为重写。

对于 Java 语言中重写而 Java 虚拟机中非重写的情况，编译器会通过生成桥接方法来实现 Java 中的重写语义。

在某些文章中，重载也被称为静态绑定（static binding），或者编译时多态（compile-time polymorphism）；而重写则被称为动态绑定（dynamic binding）。Java 虚拟机中的静态绑定指的是在解析时便能够直接识别目标方法的情况，而动态绑定则指的是需要在运行过程中根据调用者的动态类型来识别目标方法的情况。

Java 字节码中与调用相关的指令共有五种：

1. invokestatic：用于调用静态方法。
2. invokespecial：用于调用私有实例方法、构造器，以及使用 super 关键字调用父类的实例方法或构造器，和所实现接口的默认方法。
3. invokevirtual：用于调用非私有实例方法。
4. invokeinterface：用于调用接口方法。
5. invokedynamic：用于调用动态方法。

#### 调用指令的符号引用

​	在编译过程中，我们并不知道目标方法的具体内存地址。因此，Java 编译器会暂时用符号引用来表示该目标方法。这一符号引用包括目标方法所在的类或接口的名字，以及目标方法的方法名和方法描述符。

​	符号引用存储在 class 文件的常量池之中。根据目标方法是否为接口方法，这些引用可分为接口符号引用和非接口符号引用。在执行使用了符号引用的字节码前，Java 虚拟机需要解析这些符号引用，并替换为实际引用。

​	对于非接口符号引用，假定该符号引用所指向的类为 C，则 Java 虚拟机会按照如下步骤进行查找。

1. 在 C 中查找符合名字及描述符的方法。
2. 如果没有找到，在 C 的父类中继续搜索，直至 Object 类。
3. 如果没有找到，在 C 所直接实现或间接实现的接口中搜索，这一步搜索得到的目标方法必须是非私有、非静态的。并且，如果目标方法在间接实现的接口中，则需满足 C 与该接口之间没有其他符合条件的目标方法。如果有多个符合条件的目标方法，则任意返回其中一个。

​	从这个解析算法可以看出，静态方法也可以通过子类来调用。此外，子类的静态方法会隐藏（注意与重写区分）父类中的同名、同描述符的静态方法。

​	对于接口符号引用，假定该符号引用所指向的接口为 I，则 Java 虚拟机会按照如下步骤进行查找。

1. 在 I 中查找符合名字及描述符的方法。
2. 如果没有找到，在 Object 类中的公有实例方法中搜索。
3. 如果没有找到，则在 I 的超接口中搜索。这一步的搜索结果的要求与非接口符号引用步骤 3 的要求一致。

​	**经过上述的解析步骤之后，符号引用会被解析成实际引用。对于可以静态绑定的方法调用而言，实际引用是一个指向方法的指针。对于需要动态绑定的方法调用而言，实际引用则是一个方法表的索引。**

#### 虚方法调用

​	Java方法调用中的invokevirtual和invokeinterface指令属于Java虚拟机的虚方法调用。在绝大数情况下(除非方法被声明为final)，Java虚拟机需要根据调用者的动态类型来确定虚方法调用的目标方法，此过程称为动态绑定。相对于静态绑定的方法调用来说，动态绑定的方法调用更耗时。

​	Java方法调用中的invokestatic和invokespecial指令属于静态绑定。如果虚方法调用指向一个标记为 final 的方法，那么 Java 虚拟机也可以静态绑定该虚方法调用的目标方法。

#### 方法表

​	Java虚拟机采用了一种空间换时间的策略来实现动态绑定。它为每个类生成一张方法表(类加载阶段中的准备阶阶段创建)，来快速定位目标方法。	

​	方法表本质上是一个数组，里面存放当前类和祖先类中非私有的实例方法，这些方法可能是已经实现的方法，也可能是抽象方法。方法表满足两个特性，一是子类方法表中包含父类方法表中的所有方法，二是子类方法在方法表中的索引值，与它所重写的父类方法的索引值相同。

​	我们知道，方法调用指令中的符号引用会在执行之前解析成实际引用。对于静态绑定的方法调用而言，实际引用将指向具体的目标方法。对于动态绑定的方法调用而言，实际引用则是方法表的索引值（实际上并不仅是索引值）。

​	实际上，使用了方法表的动态绑定与静态绑定相比，仅仅多出几个内存解引用操作：访问栈上的调用者，读取调用者的动态类型，读取该类型的方法表，读取方法表中某个索引值所对应的目标方法。相对于创建并初始化 Java 栈帧来说，这几个内存解引用操作的开销简直可以忽略不计。

​	方法表的动态绑定存在于解释执行中和即时编译的超多态情况。

#### 内联缓存

​	内联缓存是一种加快动态绑定的优化技术。它能够缓存调用者的动态类型，以及该类型所对应的目标方法，以后执行时，如果碰到已缓存的类型，内联缓存便会直接调用该类型所对应的目标方法。如果没有碰到缓存类型，则会退化为方法表的动态绑定。

​	在针对多态的优化手段中，我们通常会提及以下三个术语。

 	1. 单态（monomorphic）指的是仅有一种状态的情况。
 	2. 多态（polymorphic）指的是有限数量种状态的情况。二态（bimorphic）是多态的其中一种。
 	3. 超多态（megamorphic）指的是更多种状态的情况。通常我们用一个具体数值来区分多态和超多态。在这个数值之下，我们称之为多态。否则，我们称之为超多态。

​	单态内联缓存，顾名思义，便是只缓存了一种动态类型以及它所对应的目标方法。它的实现非常简单：比较所缓存的动态类型，如果命中，则直接调用对应的目标方法。

​	多态内联缓存则缓存了多个动态类型及其目标方法。它需要逐个将所缓存的动态类型与当前动态类型进行比较，如果命中，则调用对应的目标方法。

​	超多态内联缓存则放弃了优化的机会，它将直接访问方法表，来动态绑定目标方法。

为了节省内存空间，Java 虚拟机只采用单态内联缓存。当内联缓存没有命中时，Java虚拟机则劣化为超多态状态，将直接访问方法表，来动态绑定目标方法。

​	虽然内联缓存附带内联二字，但是它并没有内联目标方法。这里需要明确的是，任何方法调用除非被内联，否则都会有固定开销。这些开销来源于保存程序在该方法中的执行位置，以及新建、压入和弹出新方法所使用的栈帧。对于极其简单的方法而言，比如说 getter/setter，这部分固定开销占据的 CPU 时间甚至超过了方法本身。此外，在即时编译中，方法内联不仅仅能够消除方法调用的固定开销，而且还增加了进一步优化的可能性。



## Java如何处理异常

异常处理的两大组成元素是抛出异常和捕获异常。这两大要素共同实现程序控制流的非正常转移。

### 抛出异常

​	抛出异常可分为显式和隐式。显式抛出是指应用程序使用 throw 关键字手动将异常实例抛出。隐式抛出是指Java虚拟机在执行过程中，碰到无法继续执行的异常状态时自动抛出。

### 捕获异常

​	捕获异常则涉及了如下三种代码块：

	1. try 代码块：用来标记需要进行异常监控的代码。
	1. catch 代码块：跟在 try 代码块之后，用来捕获在 try 代码块中触发的某种指定类型的异常。除了声明所捕获异常的类型之外，catch 代码块还定义了针对该异常类型的异常处理器。在 Java 中，try 代码块后面可以跟着多个 catch 代码块，来捕获不同类型的异常。Java 虚拟机会从上至下匹配异常处理器。因此，前面的 catch 代码块所捕获的异常类型不能覆盖后边的，否则编译器会报错。
	1. finally代码块：跟在try代码块和catch代码块后，用来声明一段必须执行的代码。设计的初衷是为了避免跳过某些关键的清理代码，如关闭一些打开的系统资源。

​	在程序正常执行后，会调用finally代码块。否则会在catch 代码块捕获并处理过异常后调用。如果catch没有捕获到异常，则直接执行finally代码块然后继续抛出该异常。如果catch 代码块也抛出异常，finally代码块运行后会继续抛出该异常。最糟糕的情况是finally代码块也遇到异常，此时中断执行，并往外抛出异常。

### 异常的基本概念

​	在Java规范中，所有异常都是Throwable类或者其子类的实例。Throwable由两大直接子类。第一个是Error，涵盖程序不该捕获的异常，当程序触发Error时，它的执行状态已经无法恢复，需要中止线程甚至中止虚拟机。第二个是Exception，涵盖可能需要捕获并且处理的异常。Exception有一个特殊的子类RuntimeException，用来表示程序虽然无法继续执行，但是还能抢救一下。

​	Error和RuntimeException属于非检查异常(unchecked exception)，其他异常属于检查异常(checked exception)。检查异常需要在程序中显式的捕获，或者在方法中标记throws关键字，抛到调用者去处理。

​	异常实例的构造十分昂贵。由于构造异常实例时，Java虚拟机需要生成该异常的栈轨迹(stack trace)。该操作会一一访问当前线程的Java栈帧，并记录下各种调式信息，包括栈帧指向的方法名、类名、以及触发的位置。

### Java虚拟机捕获异常

​	在编译生成的字节码中，每个方法都有一个异常表。表中的每条记录都代表一个异常处理器，记录中包括from指针、to指针、target指针和捕获的异常类型。这些指针的值时字节码索引，用以定位字节码。

​	其中form指针和to指针标示了该异常处理器监控的范围，如try代码块覆盖的范围。target指针指向异常处理器的起始位置，如catch代码块的起始位置。

​	当程序触发异常时，Java 虚拟机会从上至下遍历异常表中的所有条目。当触发异常的字节码的索引值在某个异常表条目的监控范围内，Java 虚拟机会判断所抛出的异常和该条目想要捕获的异常是否匹配。

​	finally 代码块的编译比较复杂。当前版本 Java 编译器的做法，是复制 finally 代码块的内容，分别放在 try-catch 代码块所有正常执行路径以及异常执行路径的出口中。



如果 catch 代码块捕获了异常，并且触发了另一个异常，那么 finally 捕获并且重抛的异常是哪个呢？答案是后者。也就是说原本的异常便会被忽略掉，这对于代码调试来说十分不利。

### Java7的Suppressed异常以及语法糖

​	Java7引入Suppressed异常来解决原本的异常被忽略掉的问题。这个特性允许将一个异常依附于另一个异常上，因此，抛出的异常可以附带多个异常信息。然而Java层面的finally代码块缺少指向所捕获的异常的引用(catch代码块可以声明异常，finally代码块不可以)，所以这个特性使用起来非常繁琐。

​	为此，Java7专门构建了一个try-with-resources 的语法糖，在字节码层面自动使用Suppressed异常。当然，该语法糖的主要目的并不是使用 Suppressed 异常，而是精简资源打开关闭的用法。

​	try-with-resources 语法糖允许在 try 关键字后声明并实例化实现了 AutoCloseable 接口的类，编译器将自动添加对应的 close() 操作。与手工代码调用close()操作相比，try-with-resources 还会使用 Suppressed 异常的功能，来避免原异常“被消失”。

​	除了 try-with-resources 语法糖之外，Java 7 还支持在同一 catch 代码块中捕获多种异常。实际实现非常简单，生成多个异常表条目即可。

## Java处理反射

### 反射 	

​	Reflection(反射) 是 Java 程序开发语言的特征之一，它允许运行中的 Java 程序对自身进行检查。通过反射，我们可以在运行时，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性。

#### 功能

Java 反射主要提供以下功能：

- 在运行时判断任意一个对象所属的类；
- 在运行时构造任意一个类的对象；
- 在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）；
- 在运行时调用任意一个对象的方法

#### 运用

​	Java反射的基本运用:

	+ 获得 Class 对象。有三种方式，Class.forName("类名") 、对象.getClass() 、int.class。
	+ 判断是否为某个类的实例。instanceof关键字或者Class.对象的isInstance()方法。
	+ 创建实例。使用Class对象的newInstance()方法来创建Class对象对应类的实例。或者先通过Class对象获取指定的Constructor对象，再调用Constructor对象的newInstance()方法来创建实例。
	+ 获取方法。`getDeclaredMethods` 方法返回类或接口声明的所有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法。`getMethods` 方法返回某个类的所有公用（public）方法，包括其继承类的公用方法。
	+ 获取类的成员变量（字段）信息。`getFiled`：访问公有的成员变量。`getDeclaredField`：所有已声明的成员变量，但不能得到其父类的成员变量
	+ 调用方法。Method.invoke
	+ 利用反射创建数组。Array.newInstance(Class<?>,int)

### 反射调用实现

​	方法的反射调用通过Method.invoke实现，方法执行时会委派给MethodAccessor执行。MethodAccessor 是一个接口，它有两个已有的具体实现：一个通过本地方法来实现反射调用，另一个则使用了委派模式。每个 Method 实例的第一次反射调用都会生成一个委派实现，它所委派的具体实现便是一个本地实现(C++调用)。

~~~java
    public Object invoke(Object obj, Object... args)
        throws IllegalAccessException, IllegalArgumentException,
           InvocationTargetException
    {
        if (!override) {
            Class<?> caller = Reflection.getCallerClass();
            checkAccess(caller, clazz,
                        Modifier.isStatic(modifiers) ? null : obj.getClass(),
                        modifiers);
        }
        MethodAccessor ma = methodAccessor;             // read volatile
        if (ma == null) {
            ma = acquireMethodAccessor();
        }
        return ma.invoke(obj, args);
    }
~~~

​	反射调用先是调用了 Method.invoke，然后进入委派实现（DelegatingMethodAccessorImpl），再然后进入本地实现（NativeMethodAccessorImpl），最后到达目标方法。

​	Java 的反射调用机制还设立了另一种动态生成字节码的实现（下称动态实现），直接使用 invoke 指令来调用目标方法。之所以采用委派实现，便是为了能够在本地实现以及动态实现中切换。

~~~java
// 动态实现的伪代码，这里只列举了关键的调用逻辑，其实它还包括调用者检测、参数检测的字节码。
// 生成直接调用方法的Java代码，和平时写的方法调用一样
package jdk.internal.reflect;
public class GeneratedMethodAccessor1 extends ... { 
    @Overrides 
    public Object invoke(Object obj, Object[] args) throws ... { 
    	Test.target((int) args[0]); 
        return null; 
    }
}
~~~

​	动态实现和本地实现相比，其运行效率要快上 20 倍  。这是因为动态实现无需经过 Java 到 C++ 再到 Java 的切换，但由于生成字节码十分耗时，仅调用一次的话，反而是本地实现要快上 3 到 4 倍 。

​	考虑到许多反射调用仅会执行一次，Java 虚拟机设置了一个阈值 15（可以通过 -Dsun.reflect.inflationThreshold= 来调整），当某个反射调用的调用次数在 15 之下时，采用本地实现；当达到 15 时，便开始动态生成字节码，并将委派实现的委派对象切换至动态实现，这个过程我们称之为 Inflation。反射调用的 Inflation 机制是可以通过参数（-Dsun.reflect.noInflation=true）来关闭的。这样一来，在反射调用一开始便会直接生成动态实现，而不会使用委派实现或者本地实现。

### 反射调用开销

​	反射调用涉及到Class.forName，Class.getMethod 以及 Method.invoke 三个操作。其中，Class.forName 会调用本地方法，Class.getMethod 则会遍历该类的公有方法。如果没有匹配到，它还将遍历父类的公有方法。以 getMethod 为代表的查找方法操作，会返回查找得到结果的一份拷贝，将带来额外的堆空间消耗。

​	方法的反射调用会带来不少性能开销，原因主要有三个：变长参数方法导致的 Object 数组(Method.invoke是个变长参数)	，基本类型的自动装箱、拆箱，还有最重要的方法内联。

## JVM实现invokedynamic

​	在 Java 中，方法调用会被编译为 invokestatic，invokespecial，invokevirtual 以及 invokeinterface 四种指令。这些指令与包含目标方法类名、方法名以及方法描述符的符号引用捆绑。在实际运行之前，Java 虚拟机将根据这个符号引用链接到具体的目标方法。在这四种调用指令中，Java 虚拟机明确要求方法调用需要提供目标方法的类名。

​	Java 7 引入了一条新的指令 invokedynamic。该指令的调用机制抽象出调用点这一个概念，并允许应用程序将调用点链接至任意符合条件的方法上。 invokedynamic的实现基于方法句柄（MethodHandle）。

​	方法句柄是一个强类型的、能够被直接执行的引用。它仅关心所指向方法的参数类型以及返回类型，而不关心方法所在的类以及方法名。方法句柄的权限检查发生在创建过程中，相较于反射调用节省了调用时反复权限检查的开销。

​	方法句柄可以通过 invokeExact 以及 invoke 来调用。其中，invokeExact 要求传入的参数和所指向方法的描述符严格匹配。方法句柄还支持增删改参数的操作，这些操作是通过生成另一个充当适配器的方法句柄来实现的。

​	方法句柄可以通过 invokeExact 以及 invoke 来调用。其中，invokeExact 要求传入的参数和所指向方法的描述符严格匹配。方法句柄还支持增删改参数的操作，这些操作是通过生成另一个充当适配器的方法句柄来实现的。

​	invokedymaic 指令抽象出调用点的概念，并且将调用该调用点所链接的方法句柄。在第一次执行 invokedynamic 指令时，Java 虚拟机将执行它所对应的启动方法，生成并且绑定一个调用点。之后如果再次执行该指令，Java 虚拟机则直接调用已经绑定了的调用点所链接的方法。

​	Lambda 表达式到函数式接口的转换是通过 invokedynamic 指令来实现的。该 invokedynamic 指令对应的启动方法将通过 ASM 生成一个适配器类。对于没有捕获其他变量的 Lambda 表达式，该 invokedynamic 指令始终返回同一个适配器类的实例。对于捕获了其他变量的 Lambda 表达式，每次执行 invokedynamic 指令将新建一个适配器类实例。

​	不管是捕获型的还是未捕获型的 Lambda 表达式，它们的性能上限皆可以达到直接调用的性能。其中，捕获型 Lambda 表达式借助了即时编译器中的逃逸分析，来避免实际的新建适配器类实例的操作。

## Java字节码

​	Java字节码为Java虚拟机所使用的指令集，该指令集包含200多个指令，使用8bit(2^8=256)就能存下，因此被称为字节码。字节码与Java虚拟机基于栈的计算模型是密不可分的。

​	在解释执行时，每当Java方法分配栈帧时，Java虚拟机往往需要开辟一块额外的空间作为操作数栈，来存放计算的操作数以及返回结果。具体来说就是：执行每一条指令之前，Java虚拟机要求该指令的操作数已被压入操作数栈中。在执行指令时，Java虚拟机会将该指令所需的操作数弹出，并将指令的结果重新压入栈。栈帧另一重要组成部分则是局部变量表，字节码程序可以将计算结果缓存在局部变量表中。实际上，Java虚拟机将局部变量表当成一个数组，依次存放this指针(仅非静态方法)，所传入的参数，以及字节码中的局部变量。

### 操作数栈

#### 直接作用在操作数栈的指令

​	dup：复制栈顶元素。常用于复制new指令所生成的未经初始化的引用，当执行new指令时，Java虚拟机会将指向一块已分配、未初始化的内存的引用压入操作数栈中。接下来，需要以这个引用作为调用者来调用其构造器，也就是invokespeical指令，该指令将消耗操作数栈的元素，作为它的调用者和参数。如果不复制，引用被消耗后，会丢失引用。

​	pop：舍弃栈顶元素。常用于舍弃调用指令的返回结果。

​	上述两条指令只能处理非long和非double类型的值，因为long和double类型的值需要占用两个栈单元，其他类型的值只会占用一个栈单元。当遇到long或double类型的值时，复制栈顶元素使用dup2指令，舍弃栈顶元素使用pop2指令。

​	swap：交换栈顶两个元素的值。

#### 常量加载指令

​	ldc:load constant

| 类型                            | 常数指令 | 范围                          |
| ------------------------------- | -------- | ----------------------------- |
| int(boolean, byte, char, short) | iconst   | [-1, 5]                       |
|                                 | bipush   | [-128, 127]                   |
|                                 | sipush   | [-32768, 32767]               |
|                                 | ldc      | any int value                 |
| long                            | lconst   | 0, 1                          |
|                                 | ldc      | any long value                |
| float                           | fconst   | 0, 1, 2                       |
|                                 | ldc      | any float value               |
| double                          | dconst   | 0, 1                          |
|                                 | ldc      | any double value              |
| reference                       | aconst   | null                          |
|                                 | ldc      | String literal, Class literal |

​	正常情况下，操作数栈的压入弹出都是一条一条指令完成的。但是在抛异常时，Java虚拟机会清除操作数栈上的所有内容，而后将异常压入操作数栈上。

### 局部变量表

​	和操作数栈一样，long和double类型的值占据两个单元，其余类型占据一个的单元。

#### 局部变量表访问指令

| 类型                            | 加载指令 | 存储指令 |
| ------------------------------- | -------- | -------- |
| int(boolean, byte, char, short) | iload    | istore   |
| long                            | lload    | lstore   |
| float                           | fload    | fstore   |
| double                          | dload    | dstore   |
| reference                       | aload    | astore   |

​	局部变量数组的加载、存储指令都要指明所加载单元的下标。

​	Java字节码中唯一能直接作用于局部变量表的指令是iinc M N(M为非负整数，N为整数)，该指令指的是将局部变量数组的第M个单元的int值加N，常用于for循环中自增量的更新。

### 其他类别指令

​	new：后跟目标类，生成该类的未初始化的对象。

​	instanceof：后跟目标类，判断栈顶元素是否为目标类/接口的实例，是则压入1，否则压入0。

​	checkstat：后跟目标类，判断栈顶元素是否为目标类/接口的实例，不是便抛出异常。

​	athrow：将栈顶异常抛出。

​	monitorenter：为栈顶元素加锁。

​	monitorexit：为栈顶元素解锁。

​	getstatic：静态字段访问。

​	putstatic：静态字段赋值。

​	getfield：实例字段访问。

​	putfield：实例字段赋值。

​	invokestatic：执行静态方法。

​	invokespecial：执行私有的实例方法，构造器，通过super调用的方法等。

​	invokeinterface：执行从接口继承的方法。

​	invokevirtual：执行非私有的实例方法。

​	invokedynamic：执行动态绑定方法。

### 数组相关指令

​	newarray：新建基本类型的数组。

​	anewarray：新建引用类型的数组。

​	multianewarray：生成多维数组。

​	arraylength：数组长度。

#### 数组访问指令

​	数组的加载指令和存储指令。

| 类型          | 加载指令 | 存储指令 |
| ------------- | -------- | -------- |
| byte(boolean) | baload   | bastore  |
| char          | caload   | castore  |
| short         | saload   | sastore  |
| int           | iaload   | iastore  |
| long          | laload   | lastore  |
| float         | faload   | fastore  |
| double        | daload   | dastore  |
| reference     | aaload   | aastore  |

### 返回指令表

​	控制流指令，包括无条件跳转的goto，条件跳转指令，tableswitch(密集的case)和lookupswitch(非密集的case)，返回指令，以及被废弃的jsr，ret指令。返回指令区分类型。

| 返回类型                        | 返回指令 |
| ------------------------------- | -------- |
| void                            | return   |
| int(boolean, byte, char, short) | ireturn  |
| long                            | lreturn  |
| float                           | freturn  |
| double                          | dreturn  |
| reference                       | areturn  |

## Java语法糖

### 自动装箱和自动拆箱

​	Java语言中拥有8个基本类型，每个基本类型都有对应的包装类型。之所以需要包装类型，是因为许多Java核心类库的API都是面向对象的。如，Java核心类库的容器类，就只支持引用类型。

​	当我们向一个存储包装类对象的容器存入一个基本数据时，首先需要将其转换为对应的包装类([Wrapper].valueOf)，这个过程可以是显示的，也可以是隐式的，隐式的话就是自动装箱。

​	当我们使用一个包装类对象和对应的基本类型比较时，包装类型会自动转换为基本数据类型([Wrapper].xxValue)，然后进行比较，自动地从包装类型转换到基本数据类型的过程就是自动拆箱。

### 泛型与类型擦除

​	当我们不知道会使用什么类型时，一般会使用泛型来声明，然后到真正使用时在传入真正的类型。

​	虽然我们在存入时会存真正类型的对象，但是存储到底层时，依然会存储Object对象(对于限定了基层类的泛型参数，经过类型擦除后，所有的泛型参数都将变成所限定的继承类)，取出时在强转成真正类型的对象，这个过程叫做类型擦除。泛型使用类型擦除的机制来做主要为了向后兼容。虽然经过类型擦除后，对象会变为Object类型，但是编译时，Java编译器还是会对数据进行类型校验的。

### 桥接方法

​	在Java中，如果子类从父类继承了一个方法，然后将返回值改为父类返回值的子类，我们仍然认为符合Java语言的重写，毕竟都使用了@Override注解。但是在Java虚拟机层面，因为方法描述符不一样，会认为是两个不同的方法，为了保证编译而成的Java字节码能够保留重写的语义，Java编译器额外添加了一个桥接方法，桥接方法在字节码层面重写了父类的方法(返回值类型一致，方法描述符一样)，并将调用子类的方法(返回值是父类返回值的子类)。

​	在javap的输出中，桥接方法的访问标识符会出现ACC_BRIDGE(代表桥接方法)之外，还会出现ACC_SYNTHETIC(代表不可见)。当尝试调用桥接方法时，Java编译器会报错，如果想调用这个方法，需要使用反射机制。

### 其他语法糖

​	变长参数：可以不指定参数个数，可以随意输入多个。

​	try-with-resource：自动释放资源(需要实现AutoCloseable接口)。

​	同一个cath代码块可以捕获多种异常

​	foreach循环允许Java程序在for循环里遍历数组或者Iterable对象。对数组来说foreach循环将从0开始逐一访问数组中的元素，直至数组的末尾。

​	字符串switch，实际就是一个哈希桶，由于每个字符串都是常量，因此会将字符串转换为int值switch，比较字符串的哈希值。由于字符串哈希值容易碰撞，因此还需要用String.equals诸葛比较相同哈希值的字符串。

## 即时编译

​	即时编译是一项用来提升应用程序运行效率的技术。通常而言，字节码会先被JVM解释执行，之后反复执行的热点代码(以方法为单位)则会被即时编译为机器码，直接运行在底层硬件上，来提升运行效率。

### 分层编译模式

​	HotSpot虚拟机包含多个即时编译器C1，C2和Graal。Graal是个实现性质的即时编译器，可以通过参数-XX:UnlockExperimentalVMOptions -XX:UserJVMC1Compiler启动，来替换C2即时编译器。

​	在JDK7之前，我们需要根据程序的特性选择对应的即时编译器。对于执行时间较短的，或对程序启动性能有要求的程序，我们采用代码编译效率较快的C1，对应参数 -client。对于执行时间较长的，或对程序峰值性能有要求的程序，我们采用代码执行效率较快的C2，对应参数 -server。

​	JDK7引入了分层编译(-XX:TieredCompilation)的概念，综合了C1的启动性能优势和C2的峰值性能优势。JDK8默认开启了分层编译。分层编译将JVM的执行状态分为了5个层次。

 +	解释执行；
 +	执行不带profiling的C1代码(C1编译器生成的机器码)；
 +	执行仅带方法调用次数以及循环回边执行次数的profiling的C1代码；
 +	执行带所有profiling的C1代码；
 +	执行C2代码(C2编译器生成的机器码)。

​	通常情况下，C2代码的执行效率要比C1代码高出30%以上。然而，对于C1代码的三种状态，按执行效率从高到低则是1层 > 2层 > 3层。这是因为profiling越多，其额外的性能开销越大。

​	profiling是指程序执行过程中，收集能够反映程序执行状态数据的过程。收集到的数据我们称之为程序的profile，profiler大多通过注入(instrumentation)或者JVMTI事件来实现的。JVM也内置了profiling。

​	在5个层次的执行状态中，1层和4层为终止状态，当一个方法被终止状态编译后，如果编译后的代码没有失效，那么JVM是不会再次发出该方法的编译请求的。

![即时编译器的层级](.\static\image\即时编译器的层级.webp)

​	上图为4个不同的编译路径。

​	通常情况下，热点方法hi被三层的C1编译，然后在被4层的C2编译。

​	如果方法的字节码数据较少(getter/setter)，而且3层的profiling没有可收集的数据。那么，JVM会判定对于C1代码和C2代码的执行效率相同，JVM会在3层编译后，直接选择1层的C1编译。这是一个终止状态，因此JVM不会继续使用4层的C2编译。

​	C1忙碌时，JVM会在解释执行时对程序进行profiling，而后直接由4层的C2编译。

​	C2忙碌时，方法会被2层的C1编译，然后在被3层的C1编译，以减少方法在3层的执行时间。

	### 即时编译的触发

​	JVM是根据方法的调用次数以及循环回边的执行次数来触发即时编译的。前面提到，JVM在0层，2层和3层执行状态是进行profiling，其中就包含方法的调用次数和循环回边次数。循环回边是一个控制流图的概念。在字节码中，可以简单理解为往回跳转的指令。

​	在即时编译过程中，我们会识别循环的头部和尾部。循环尾部到循环头部的控制流边就是真正意义上的循环回边，C1编译器将在这个位置插入增加循环回边计数器的代码。

​	解释执行和C1代码中增加循环回边计数器的位置并不相同，但不影响程序。实际上，JVM并不会对即时编译器进行同步操作，因此收集的执行次数并不一定准确，但是即时编译的触发并不需要非常精准的数值，只要该数值足够大， 就说明包含热点代码。

​	不开启分层编译的情况下，当方法的调用次数和循环回边次数的和，超过阈值(-XX:CompileThreshold, C1默认1500，C2默认10000)时，便会触发即时编译。开启分层编译时，阈值将动态调整。

​	所谓的动态调整其实并不复杂：在比较阈值时，Java 虚拟机会将阈值与某个系数 s 相乘。该系数与当前待编译的方法数目成正相关，与编译线程的数目成负相关。

````
系数的计算方法为：
s = queue_size_X / (TierXLoadFeedback * compiler_count_X) + 1

其中X是执行层次，可取3或者4；
queue_size_X是执行层次为X的待编译方法的数目；
TierXLoadFeedback是预设好的参数，其中Tier3LoadFeedback为5，Tier4LoadFeedback为3；
compiler_count_X是层次X的编译线程数目。
````

​	在 64 位 Java 虚拟机中，默认情况下编译线程的总数目是根据处理器数量来调整的（对应参数 -XX:+CICompilerCountPerCPU，默认为 true；当通过参数 -XX:+CICompilerCount=N 强制设定总编译线程数目时，CICompilerCountPerCPU 将被设置为 false）。Java 虚拟机会将这些编译线程按照 1:2 的比例分配给 C1 和 C2（至少各为 1 个）。

### OSR 编译

​	可以看到，决定一个方法是否为热点代码的因素有两个：方法的调用次数、循环回边的执行次数。即时编译便是根据这两个计数器的和来触发的。为什么 Java 虚拟机需要维护两个不同的计数器呢？实际上，除了以方法为单位的即时编译之外，Java 虚拟机还存在着另一种以循环为单位的即时编译，叫做 On-Stack-Replacement（OSR）编译。循环回边计数器便是用来触发这种类型的编译的。

​	OSR 实际上是一种技术，它指的是在程序执行过程中，动态地替换掉 Java 方法栈桢，从而使得程序能够在非方法入口处进行解释执行和编译后的代码之间的切换。事实上，去优化（deoptimization）采用的技术也可以称之为 OSR。在不启用分层编译的情况下，触发 OSR 编译的阈值是由参数 -XX:CompileThreshold 指定的阈值的倍数。

```
(OnStackReplacePercentage - InterpreterProfilePercentage)/100其中-XX:InterpreterProfilePercentage的默认值为33，当使用C1时-XX:OnStackReplacePercentage为933，当使用C2时为140。
```

​	在启用分层编译的情况下，触发 OSR 编译的阈值则是由参数 -XX:TierXBackEdgeThreshold 指定的阈值乘以系数。OSR 编译在正常的应用程序中并不多见。它只在基准测试时比较常见，因此并不需要过多了解。

### Profiling

​	分层编译中的 0 层、2 层和 3 层都会进行 profiling，收集能够反映程序执行状态的数据。其中，最为基础的便是方法的调用次数以及循环回边的执行次数。它们被用于触发即时编译。

​	此外，0 层和 3 层还会收集用于 4 层 C2 编译的数据，比如说分支跳转字节码的分支 profile（branch profile），包括跳转次数和不跳转次数，以及非私有实例方法调用指令、强制类型转换 checkcast 指令、类型测试 instanceof 指令，和引用类型的数组存储 aastore 指令的类型 profile（receiver type profile）。

​	分支 profile 和类型 profile 的收集将给应用程序带来不少的性能开销。据统计，正是因为这部分额外的 profiling，使得 3 层 C1 代码的性能比 2 层 C1 代码的低 30%。在通常情况下，我们不会在解释执行过程中收集分支 profile 以及类型 profile。只有在方法触发 C1 编译后，Java 虚拟机认为该方法有可能被 C2 编译，方才在该方法的 C1 代码中收集这些 profile。

​	那么这些耗费巨大代价收集而来的 profile 具体有什么作用呢？答案是，C2 可以根据收集得到的数据进行猜测，假设接下来的执行同样会按照所收集的 profile 进行，从而作出比较激进的优化。

#### 基于分支 profile 的优化

​	根据条件跳转指令的分支 profile，即时编译器可以将从未执行过的分支剪掉，以避免编译这些很有可能不会用到的代码，从而节省编译时间以及部署代码所要消耗的内存空间。

​	此外，“剪枝”将精简程序的数据流，从而触发更多的优化。在现实中，分支 profile 出现仅跳转或者仅不跳转的情况并不多见。当然，即时编译器对分支 profile 的利用也不仅限于“剪枝”。它还会根据分支 profile，计算每一条程序执行路径的概率，以便某些编译器优化优先处理概率较高的路径。

#### 基于类型 profile 的优化

​	instanceof 以及方法调用的类型 profile。

​	在 Java 虚拟机中，instanceof 测试并不简单。如果 instanceof 的目标类型是 final 类型，那么 Java 虚拟机仅需比较测试对象的动态类型是否为该 final 类型。如果目标类型不是 final 类型，那么 Java 虚拟机需要从测试对象的动态类型开始，依次测试该类，该类的父类、祖先类，该类所直接实现或者间接实现的接口是否与目标类型一致。

​	和基于分支 profile 的优化一样，基于类型 profile 的优化同样也是作出假设，从而精简控制流以及数据流。

#### 去优化

​	不管是基于分支 profile 的优化，还是基于类型 profile 的优化，这两者的核心都是假设。对于分支 profile，即时编译器假设的是仅执行某一分支；对于类型 profile，即时编译器假设的是对象的动态类型仅为类型 profile 中的那几个。

​	那么当假设失败时，JVM会从执行即时编译生成的机器码切换回解释执行。即去优化。

​	在生成的机器码中，即时编译器将在假设失败的位置上插入一个陷阱（trap）。该陷阱实际上是一条 call 指令，调用至 Java 虚拟机里专门负责去优化的方法。与普通的 call 指令不一样的是，去优化方法将更改栈上的返回地址，并不再返回即时编译器生成的机器码中。

​	去优化的过程相当复杂。由于即时编译器采用了许多优化方式，其生成的代码和原本的字节码的差异非常之大。在去优化的过程中，需要将当前机器码的执行状态转换至某一字节码之前的执行状态，并从该字节码开始执行。这便要求即时编译器在编译过程中记录好这两种执行状态的映射。

​	举例来说，经过逃逸分析之后，机器码可能并没有实际分配对象，而是在各个寄存器中存储该对象的各个字段。在去优化过程中，Java 虚拟机需要还原出这个对象，以便解释执行时能够使用该对象。当根据映射关系创建好对应的解释执行栈桢后，Java 虚拟机便会采用 OSR 技术，动态替换栈上的内容，并在目标字节码处开始解释执行。

​	此外，在调用 Java 虚拟机的去优化方法时，即时编译器生成的机器码可以根据产生去优化的原因来决定是否保留这一份机器码，以及何时重新编译对应的 Java 方法。

+ 如果去优化的原因与优化无关，即使重新编译也不会改变生成的机器码，那么生成的机器码可以在调用去优化方法时传入 Action_None，表示保留这一份机器码，在下一次调用该方法时重新进入这一份机器码。
+ 如果去优化的原因与静态分析的结果有关，例如类层次分析，那么生成的机器码可以在调用去优化方法时传入 Action_Recompile，表示不保留这一份机器码，但是可以不经过重新 profile，直接重新编译。
+ 如果去优化的原因与基于 profile 的激进优化有关，那么生成的机器码需要在调用去优化方法时传入 Action_Reinterpret，表示不保留这一份机器码，而且需要重新收集程序的 profile。这是因为基于 profile 的优化失败的时候，往往代表这程序的执行状态发生改变，因此需要更正已收集的 profile，以更好地反映新的程序执行状态。

## 即时编译器的中间表达形式

###	中间表达形式（Intermediate Representation）

​	在编译原理课程中，我们通常将编译器分为前端和后端。其中，前端会对所输入的程序进行词法分析、语法分析、语义分析，然后生成中间表达形式，也就是 IR（Intermediate Representation ）。后端会对 IR 进行优化，然后生成目标代码。

​	对于即时编译器来说，所输入的 Java 字节码剥离了很多高级的 Java 语法，而且其采用的基于栈的计算模型非常容易建模。因此，即时编译器并不需要重新进行词法分析、语法分析以及语义分析，而是直接将 Java 字节码作为一种 IR。

​	不过，Java 字节码本身并不适合直接作为可供优化的 IR。这是因为现代编译器一般采用静态单赋值（Static Single Assignment，SSA）IR。这种 IR 的特点是每个变量只能被赋值一次，而且只有当变量被赋值之后才能使用。

​	借助了 SSA IR，编译器则可以通过查找赋值了但是没有使用的变量，来识别冗余赋值。并且对其他优化方式也有很大的帮助，例如常量折叠（constant folding）、常量传播（constant propagation）、强度削减（strength reduction）以及死代码删除（dead code elimination）等。

```
示例：
x1=4*1024经过常量折叠后变为x1=4096x1=4; 
y1=x1经过常量传播后变为x1=4; 
y1=4y1=x1*3经过强度削减后变为y1=(x1<<1)+x1
if(2>1){y1=1;}else{y2=1;}经过死代码删除后变为y1=1
```

​	SSA IR 会带来一个问题，那便是不同执行路径可能会对同一变量设置不同的值。例如下面这段代码 if 语句的两个分支中，变量 y 分别被赋值为 0 或 1，并且在接下来的代码中读取 y 的值。此时，根据不同的执行路径，所读取到的值也很有可能不同。为了解决这个问题，我们需要引入一个 Phi 函数的概念，能够根据不同的执行路径选择不同的值。

​	总之，即时编译器会将 Java 字节码转换成 SSA IR。更确切的说，是一张包含控制流和数据流的 IR 图，每个字节码对应其中的若干个节点（注意，有些字节码并没有对应的 IR 节点）。然后，即时编译器在 IR 图上面进行优化。我们可以将每一种优化看成一个独立的图算法，它接收一个 IR 图，并输出经过转换后的 IR 图。整个编译器优化过程便是一个个优化串联起来的。

### Sea-of-nodes

​	HotSpot 里的 C2 采用的是一种名为 Sea-of-Nodes 的 SSA IR。它的最大特点，便是去除了变量的概念，直接采用变量所指向的值，来进行运算。

​	Graal 的 IR 同样也是 Sea-of-Nodes 类型的，并且可以认为是 C2 IR 的精简版本。

#### IR 图

​	红色加粗线条为控制流，蓝色线条为数据流，而其他颜色的线条则是特殊的控制流或数据流。被控制流边所连接的是固定节点，其他的皆属于浮动节点。若干个顺序执行的节点将被包含在同一个基本块之中。

#### 基本块直接的控制流关系

​	基本块是仅有一个入口和一个出口的指令序列（IR 节点序列）。一个基本块的出口可以和若干个基本块的入口相连接，反之亦然。

​	浮动节点的位置并不固定。在编译过程中，编译器需要（多次）计算浮动节点具体的排布位置。这个过程我们称之为节点调度（node scheduling）。节点调度是根据节点之间的依赖关系来进行的。

​	需要注意的是，C2 没有固定节点这一概念，所有的 IR 节点都是浮动节点。它将根据各个基本块头尾之间的控制依赖，以及数据依赖和内存依赖，来进行节点调度。这里的内存依赖是什么一个概念呢？假设一段程序往内存中存储了一个值，而后又读取同一内存，那么显然程序希望读取到的是所存储的值。即时编译器不能任意调度对同一内存地址的读写，因为它们之间存在依赖关系。

​	C2 的做法便是将这种时序上的先后记录为内存依赖，并让节点调度算法在进行调度时考虑这些内存依赖关系。Graal 则将内存读写转换成固定节点。由于固定节点存在先后关系，因此无须额外记录内存依赖。

### Global Value Numbering

​	Global Value Numbering（GVN）是一种发现并消除等价计算的优化技术。因 Sea-of-Nodes 而变得非常容易。

​	举例来说，如果一段程序中出现了多次操作数相同的乘法，那么即时编译器可以将这些乘法并为一个，从而降低输出机器码的大小。如果这些乘法出现在同一执行路径上，那么 GVN 还将省下冗余的乘法操作。

​	在 Sea-of-Nodes 中，由于只存在值的概念，因此 GVN 算法将非常简单：如果一个浮动节点本身不存在内存副作用（由于 GVN 可能影响节点调度，如果有内存副作用的话，那么将引发一些源代码中不可能出现的情况） ，那么即时编译器只需判断该浮动节点是否与已存在的浮动节点的类型相同，所输入的 IR 节点是否一致，便可以将这两个浮动节点归并成一个。

​	我们可以将 GVN 理解为在 IR 图上的公共子表达式消除（Common Subexpression Elimination，CSE）。这两者的区别在于，GVN 直接比较值的相同与否，而 CSE 则是借助词法分析器来判断两个表达式相同与否。因此，在不少情况下，CSE 还需借助常量传播来达到消除的效果。

## 方法内联

​	方法内联是在编译过程中遇到方法调用时，将目标方法的方法体纳入编译范围之中，并取代原方法调用的优化手段。方法内联不仅可以消除调用本身带来的性能开销，还可以进一步触发更多的优化。

​	以getter/setter方法为列，如果没有方法内联，在调用时，程序需要保存当前方法的执行位置，创建并压入用于getter/setter的栈帧、访问字段、弹出栈帧、最后在恢复当前方法的执行。而当内联了对getter/setter方法的调用后，上诉操作仅剩字段访问。

​	方法内联是在解析字节码的过程中完成的。每当遇到方法调用的字节码时，即时编译器将决定是否需要内联该方法的调用。如果需要内联，则开始解析目标方法的字节码。即时编译器既可以在解析过程中替换方法调用字节码，也可以在 IR 图中替换方法调用 IR 节点。这两者都需要将目标方法的参数以及返回值映射到当前方法来。

​	即时编译器首先解析字节码，并生成 IR 图，然后在该 IR 图上进行优化。优化是由一个个独立的优化阶段（optimization phase）串联起来的。每个优化阶段都会对 IR 图进行转换。最后即时编译器根据 IR 图的节点以及调度顺序生成机器码。先比于C2编译器，Graal编译器还拥有一个独立的优化阶段，即寻找指代方法调用的IR节点，并将之替换为对目标方法的IR图。

### 方法内联的条件

​	方法内联能够触发更多的优化。通常而言，内联越多，生成代码的执行效率越高。然而，对于即时编译器来说，内联越多，编译时间也就越长，而程序达到峰值性能的时刻也被推迟。此外，内联越多也将导致生成的机器码越长。在JVM中，编译生成的机器码会被存储在Code Cache中。这个Code Cache是由大小限制的(-XX:ReservedCodeCacheSize)。

​	生成的机器码越长，越容易填满Code Cache，从而出现Code Cache已满，即时编译已被关闭的警告信息(Code Cache is full.Compiler has been disabled)。

​	因此，即时编译器不会无限制地进行方法内联。方法内联有一些规则。

+ 自动拆箱总会被内联、Throwable类的方法不能被其它类中的方法锁内联；
+ 由-XX:CompileCommand中的inline指令指定的方法，以及由@ForceInline注解的方法(仅限JDK内部方法)会被强制内联。
+ 由-XX:CompileCommand中的dontinline指令或exclude指令指定的方法，以及由@DontInline注解的方法(仅限JDK内部方法)，不会被内联。
+ 如果调用字节码对应的符号引用未被解析、目标方法所在的类未被初始化，或者目标方法是 native 方法，都将导致方法调用无法内联。
+ C2 不支持内联超过 9 层的调用（-XX:MaxInlineLevel ），以及 1 层的直接递归调用（ -XX:MaxRecursiveInlineLevel ）。PS：如果方法 a 调用了方法 b，而方法 b 调用了方法 c，那么我们称 b 为 a 的 1 层调用，而 c 为 a 的 2 层调用。
+ 即时编译器将根据方法调用指令所在的程序路径的热度，目标方法的调用次数及大小，以及当前 IR 图的大小来决定方法调用能否被内联。总体来说，即时编译器中的内联算法更青睐于小方法。

![方法内联相关参数](.\static\image\方法内联相关参数.webp)

### 虚方法调用的去虚化

​	方法内联对于静态方法调用，即时编译器可以轻易地确定唯一的目标方法。然而对于需要动态绑定的虚方法调用来说，即时编译器则需要先对虚方法调用进行去虚化（devirtualize），即转换为一个或多个直接调用，然后才能进行方法内联。

​	即时编译器的去虚化方式可分为完全去虚化以及条件去虚化（guarded devirtualization）。

#### 完全去虚化

​	完全去虚化是通过类型推导或者类层次分析（class hierarchy analysis），识别虚方法调用的唯一目标方法，从而将其转换为直接调用的一种优化手段。它的关键在于证明虚方法调用的目标方法是唯一的。

##### 基于类型推导的完全去虚化

​	基于类型推导的完全去虚化将通过数据流分析推导出调用者的动态类型，从而确定具体的目标方法。

​	在 Sea-of-Nodes 的 IR 系统中，变量不复存在，取而代之的是具体值。这些具体值的类型往往要比变量的声明类型精确。因此，通过将字节码转换为 Sea-of-Nodes IR 之后，即时编译器便可以直接去虚化，并将唯一的目标方法进一步内联进来。

​	对于需要额外的数据流分析方能确定动态类型时，即时编译器会放弃推导出调用者的动态类型，从而放弃内联，以节省编译时间，并依赖接下来的去虚化手段进行优化。其原因在于类型推导属于全局优化，本身比较浪费时间；另一方面，就算不进行基于类型推导的完全去虚化，也有接下来的基于类层次分析的去虚化，以及条件去虚化兜底，覆盖大部分的代码情况。

##### 基于类层次分析的完全去虚化

​	基于类层次分析的完全去虚化通过分析 Java 虚拟机中所有已被加载的类，判断某个抽象方法或者接口方法是否仅有一个实现。如果是，那么对这些方法的调用将只能调用至该具体实现中。

​	对于这些方法，JVM会为当前编译结果注册若干个假设，假定某抽象类只有一个子类，或者某抽象方法只有一个具体实现，又或者某类没有子类等。之后，每当新的类被加载，Java 虚拟机便会重新验证这些假设。如果某个假设不再成立，那么 Java 虚拟机便会对其所属的编译结果进行去优化。

#### 条件去虚化

​	条件去虚化则是将虚方法调用转换为若干个类型测试以及直接调用的一种优化手段。它的关键在于找出需要进行比较的类型。具体的原理是将调用者的动态类型，依次与 Java 虚拟机所收集的类型 Profile 中记录的类型相比较。如果匹配，则直接调用该记录类型所对应的目标方法。

​	如果遍历完类型 Profile 中的所有记录，仍旧匹配不到调用者的动态类型，那么即时编译器有两种选择。

​	第一，如果类型 Profile 是完整的，也就是说，所有出现过的动态类型都被记录至类型 Profile 之中，那么即时编译器可以让程序进行去优化，重新收集类型 Profile。

​	第二，如果类型 Profile 是不完整的，也就是说，某些出现过的动态类型并没有记录至类型 Profile 之中，那么重新收集并没有多大作用。此时，即时编译器(Graal)可以让程序进行原本的虚调用，通过内联缓存进行调用，或者通过方法表进行动态绑定。对于C2即时编译器，如果类型 Profile 是不完整的，即时编译器压根不会进行条件去虚化，而是直接使用内联缓存或者方法表。

## HotSpot VM的intrinsic

​	JDK9引入了@HotSpotIntrinsicCandidate注解。在 HotSpot 虚拟机中，所有被该注解标注的方法都是 HotSpot intrinsic。对这些方法的调用，会被 HotSpot 虚拟机替换成高效的指令序列(CPU 指令)，而原本的方法实现则会被忽略掉。

​	换句话说，HotSpot 虚拟机将为标注了@HotSpotIntrinsicCandidate注解的方法额外维护一套高效实现。当其他虚拟机没有维护这些intrinsic实现时，它们会使用原本的代码实现。

​	为什么不直接在源代码中使用这些高效实现呢？这是因为高效实现通常依赖于具体的 CPU 指令，而这些 CPU 指令不好在 Java 源程序中表达。再者，换了一个体系架构，说不定就没有对应的 CPU 指令，也就无法进行 intrinsic 优化了。

### intrinsic 与方法内联

​	HotSpot 虚拟机中，intrinsic 的实现方式分为两种。

​	一种是独立的桩程序。它既可以被解释执行器利用，直接替换对原方法的调用；也可以被即时编译器所利用，它把代表对原方法的调用的 IR 节点，替换为对这些桩程序的调用的 IR 节点。以这种形式实现的 intrinsic 比较少，主要包括Math类中的一些方法。

​	另一种则是特殊的编译器 IR 节点。这种实现方式仅能够被即时编译器所利用。在编译过程中，即时编译器会将对原方法的调用的 IR 节点，替换成特殊的 IR 节点，并参与接下来的优化过程。最终，即时编译器的后端将根据这些特殊的 IR 节点，生成指定的 CPU 指令。大部分的 intrinsic 都是通过这种方式实现的。

​	这个替换过程是在方法内联时进行的。当即时编译器碰到方法调用节点时，它将查询目标方法是不是 intrinsic。如果是，则插入相应的特殊 IR 节点；如果不是，则进行原本的内联工作。（即判断是否需要内联目标方法的方法体，并在需要内联的情况下，将目标方法的 IR 图纳入当前的编译范围之中。）

​	不少被标记为 intrinsic 的方法都是 native 方法。原本对这些 native 方法的调用需要经过 JNI（Java Native Interface），其性能开销十分巨大。但是，经过即时编译器的 intrinsic 优化之后，这部分 JNI 开销便直接消失不见，并且最终的结果也十分高效。

### 已有 intrinsic 简介

​	Unsafe类的方法。

​	StringBuilder和StringBuffer类的方法。

​	基本类型的包装类、Object类、Math类、System类中各个功能性方法，反射 API、MethodHandle类中与调用机制相关的方法，压缩、加密相关方法。

## 逃逸分析

​	逃逸分析是“一种确定指针动态范围的静态分析，它可以分析在程序的哪些地方可以访问到指针”。

​	在 Java 虚拟机的即时编译语境下，逃逸分析将判断新建的对象是否逃逸。即时编译器判断对象是否逃逸的依据，一是对象是否被存入堆中（静态字段或者堆中对象的实例字段），二是对象是否被传入未知代码中。

​	前者很好理解：一旦对象被存入堆中，其他线程便能获得该对象的引用。即时编译器也因此无法追踪所有使用该对象的代码位置。关于后者，由于 Java 虚拟机的即时编译器是以方法为单位的，对于方法中未被内联的方法调用，即时编译器会将其当成未知代码，毕竟它无法确认该方法调用会不会将调用者或所传入的参数存储至堆中。因此，我们可以认为方法调用的调用者以及参数是逃逸的。通常来说，即时编译器里的逃逸分析是放在方法内联之后的，以便消除这些“未知代码”入口。

​	逃逸分析结果分为三种，不逃逸、方法逃逸、线程逃逸。

### 基于逃逸分析的优化

​	即时编译器可以根据逃逸分析的结果进行诸如锁消除、栈上分配以及标量替换的优化。

​	如果即时编译器能够证明锁对象不逃逸，那么对该锁对象的加锁、解锁操作没有意义。这是因为其他线程并不能获得该锁对象，因此也不可能对其进行加锁。在这种情况下，即时编译器可以消除对该不逃逸锁对象的加锁、解锁操作。实际上，传统编译器仅需证明锁对象不逃逸出线程，便可以进行锁消除。由于 Java 虚拟机即时编译的限制，上述条件被强化为证明锁对象不逃逸出当前编译的方法。

​	Java 虚拟机中对象都是在堆上分配的，而堆上的内容对任何线程都是可见的。与此同时，Java 虚拟机需要对所分配的堆内存进行管理，并且在对象不再被引用时回收其所占据的内存。如果逃逸分析能够证明某些新建的对象不逃逸，那么 Java 虚拟机完全可以将其分配至栈上，并且在 new 语句所在的方法退出时，通过弹出当前方法的栈桢来自动回收所分配的内存空间。这样一来，我们便无须借助垃圾回收器来处理不再被引用的对象。

​	由于实现起来需要更改大量假设了“对象只能堆分配”的代码，因此 HotSpot 虚拟机并没有采用栈上分配，而是使用了标量替换这么一项技术。所谓的标量，就是仅能存储一个值的变量，比如 Java 代码中的局部变量。与之相反，聚合量则可能同时存储多个值，其中一个典型的例子便是 Java 对象。标量替换这项优化技术，可以看成将原本对对象的字段的访问，替换为一个个局部变量的访问。由于该对象没有被实际分配，因此和栈上分配一样，它同样可以减轻垃圾回收的压力。与栈上分配相比，它对字段的内存连续性不做要求，而且，这些字段甚至可以直接在寄存器中维护，无须浪费任何内存空间。

### 部分逃逸分析

​	C2 的逃逸分析与控制流无关，相对来说比较简单。Graal 则引入了一个与控制流有关的逃逸分析，名为部分逃逸分析（partial escape analysis）。它解决了所新建的实例仅在部分程序路径中逃逸的情况。

```java

public static void bar(boolean cond) {
  Object foo = new Object();
  if (cond) {
    foo.hashCode();
  }
}
// 可以手工优化为：
public static void bar(boolean cond) {
  if (cond) {
    Object foo = new Object();
    foo.hashCode();
  }
}
```

再上述代码中，假设 if 语句的条件成立的可能性只有 1%，那么在 99% 的情况下，程序没有必要新建对象。其手工优化的版本正是部分逃逸分析想要自动达到的成果。

​	部分逃逸分析将根据控制流信息，判断出新建对象仅在部分分支中逃逸，并且将对象的新建操作推延至对象逃逸的分支中。这将使得原本因对象逃逸而无法避免的新建对象操作，不再出现在只执行 if-else 分支的程序路径之中。综上，与 C2 所使用的逃逸分析相比，Graal 所使用的部分逃逸分析能够优化更多的情况，不过它编译时间也更长一些。

## 代码优化

### 字段访问相关优化

​	标量替换，可以看成将对象本身拆散为一个个字段，并把原本对对象字段的访问，替换为对一个个局部变量的访问。并且由于 Sea-of-Nodes IR 的特性，局部变量不复存在，取而代之的是一个个值。这样有利于编译器优化。

#### 	字段读取优化

​	即时编译器会优化实例字段以及静态字段访问，以减少总的内存访问数目。具体来说，它将沿着控制流，缓存各个字段存储节点将要存储的值，或者字段读取节点所得到的值。当即时编译器遇到对同一字段的读取节点时，如果缓存值还没有失效，那么它会将读取节点替换为该缓存值。

​	当即时编译器遇到对同一字段的存储节点时，它会更新所缓存的值。当即时编译器遇到可能更新字段的节点时，如方法调用节点（在即时编译器看来，方法调用会执行未知代码），或者内存屏障节点（其他线程可能异步更新了字段），那么它会采取保守的策略，舍弃所有缓存值。

#### 字段存储优化

​	除了字段读取优化之外，即时编译器还将消除冗余的存储节点。如果一个字段先后被存储了两次，而且这两次存储之间没有对第一次存储内容的读取，那么即时编译器可以将第一个字段存储给消除掉。

​	实际上，即便是在这两个字段存储操作之间读取该字段，即时编译器还是有可能在字段读取优化的帮助下，将第一个存储操作当成冗余存储给消除掉。

​	当然，如果所存储的字段被标记为 volatile，那么即时编译器也不能将冗余的存储操作消除掉。这种情况看似很蠢，但实际上并不少见，比如说两个存储之间隔着许多其他代码，或者因为方法内联的缘故，将两个存储操作（如构造器中字段的初始化以及随后的更新）纳入同一个编译单元里。

#### 死代码消除

​	除了字段存储优化之外，局部变量的死存储（dead store）同样也涉及了冗余存储。这是死代码消除（dead code eliminiation）的一种。不过，由于 Sea-of-Nodes IR 的特性，死存储的优化无须额外代价。死存储还有一种变体，即在部分程序路径上有冗余存储。

​	另一种死代码消除则是不可达分支消除。不可达分支就是任何程序路径都不可到达的分支，我们之前已经多次接触过了。在即时编译过程中，我们经常因为方法内联、常量传播以及基于 profile 的优化等，生成许多不可达分支。通过消除不可达分支，即时编译器可以精简数据流，并且减少编译时间以及最终生成机器码的大小。

### 循环优化

#### 循环无关代码外提

​	循环无关代码（Loop-invariant Code），指的是循环中值不变的表达式。如果能够在不改变程序语义的情况下，将这些循环无关代码提出循环之外，那么程序便可以避免重复执行这些表达式，从而达到性能提升的效果。

#### 循环展开

​	它指的是在循环体中重复多次循环迭代，并减少循环次数的编译优化。

​	在 C2 中，只有计数循环（Counted Loop）才能被展开。所谓的计数循环需要满足如下四个条件。

  		1.	维护一个循环计数器，并且基于计数器的循环出口只有一个（但可以有基于其他判断条件的出口）。
  		2.	循环计数器的类型为 int、short 或者 char（即不能是 byte、long，更不能是 float 或者 double）。
  		3.	每个迭代循环计数器的增量为常数。
  		4.	循环计数器的上限（增量为正数）或下限（增量为负数）是循环无关的数值。

​		循环展开的缺点显而易见：它可能会增加代码的冗余度，导致所生成机器码的长度大幅上涨。不过，随着循环体的增大，优化机会也会不断增加。一旦循环展开能够触发进一步的优化，总体的代码复杂度也将降低。

​	循环展开有一种特殊情况，那便是完全展开（Full Unroll）。当循环的数目是固定值而且非常小时，即时编译器会将循环全部展开。此时，原本循环中的循环判断语句将不复存在，取而代之的是若干个顺序执行的循环体。即时编译器会在循环体的大小与循环展开次数之间做出权衡。例如，对于仅迭代三次（或以下）的循环，即时编译器将进行完全展开；对于循环体 IR 节点数目超过阈值的循环，即时编译器则不会进行任何循环展开。

#### 其他循环优化

​	除了循环无关代码外提以及循环展开之外，即时编译器还有两个比较重要的循环优化技术：循环判断外提（loop unswitching）以及循环剥离（loop peeling）。

​	循环判断外提指的是将循环中的 if 语句外提至循环之前，并且在该 if 语句的两个分支中分别放置一份循环代码。循环判断外提与循环无关检测外提所针对的代码模式比较类似，都是循环中的 if 语句。不同的是，后者在检查失败时会抛出异常，中止当前的正常执行路径；而前者所针对的是更加常见的情况，即通过 if 语句的不同分支执行不同的代码逻辑。

​	循环剥离指的是将循环的前几个迭代或者后几个迭代剥离出循环的优化方式。一般来说，循环的前几个迭代或者后几个迭代都包含特殊处理。通过将这几个特殊的迭代剥离出去，可以使原本的循环体的规律性更加明显，从而触发进一步的优化。

### 向量化

##### 	SIMD 指令

​	我们知道，X86_64 体系架构上通用寄存器的大小为 64 位（即 8 个字节），无法暂存这些超长的数据。因此，即时编译器将借助长度足够的 XMM 寄存器，来完成 int 数组与 long 数组的向量化读取和写入操作。（为了实现方便，byte 数组的向量化读取、写入操作同样使用了 XMM 寄存器。）

​	所谓的 XMM 寄存器，是由 SSE（Streaming SIMD Extensions）指令集所引入的。它们一开始仅为 128 位。自从 X86 平台上的 CPU 开始支持 AVX（Advanced Vector Extensions）指令集后（2011 年），XMM 寄存器便升级为 256 位，并更名为 YMM 寄存器。原本使用 XMM 寄存器的指令，现将使用 YMM 寄存器的低 128 位。前几年推出的 AVX512 指令集，更是将 YMM 寄存器升级至 512 位，并更名为 ZMM 寄存器。

​	SSE 指令集以及之后的 AVX 指令集都涉及了一个重要的概念，那便是单指令流多数据流（Single Instruction Multiple Data，SIMD），即通过单条指令操控多组数据的计算操作。这些指令我们称之为 SIMD 指令。

​	SIMD 指令将 XMM 寄存器（或 YMM 寄存器、ZMM 寄存器）中的值看成多个整数或者浮点数组成的向量，并且批量进行计算。

​	举例来说，128 位 XMM 寄存器里的值可以看成 16 个 byte 值组成的向量，或者 8 个 short 值组成的向量，4 个 int 值组成的向量，两个 long 值组成的向量；而 SIMD 指令PADDB、PADDW、PADDD以及PADDQ，将分别实现 byte 值、short 值、int 值或者 long 值的向量加法。

​	下图中内存的右边是高位，寄存器的左边是高位，因此数组元素的顺序是反过来的。![数组和寄存器高位对比](.\static\image\数组和寄存器高位对比.webp)

​	也就是说，原本需要c.length次加法操作的代码，现在最少只需要c.length/4次向量加法即可完成。因此，SIMD 指令也被看成 CPU 指令级别的并行。这里c.length/4次是理论值。现实中，C2 还将考虑缓存行对齐等因素，导致能够应用向量化加法的仅有数组中间的部分元素。

#### 使用 SIMD 指令的 HotSpot Intrinsic

​	SIMD 指令虽然非常高效，但是使用起来却很麻烦。这主要是因为不同的 CPU 所支持的 SIMD 指令可能不同。一般来说，越新的 SIMD 指令，它所支持的寄存器长度越大，功能也越强。为了能够尽量利用新的 SIMD 指令，我们需要提前知道程序会被运行在支持哪些指令集的 CPU 上，并在编译过程中选择所支持的 SIMD 指令中最新的那些。

​	我们知道，Java 虚拟机所执行的 Java 字节码是平台无关的。它首先会被解释执行，而后反复执行的部分才会被 Java 虚拟机即时编译为机器码。简而言之，在进行即时编译时，Java 虚拟机已经运行在目标 CPU 之上，可以轻易地得知其所支持的指令集。然而，Java 字节码的平台无关性却引发了另一个问题，那便是 Java 程序无法像 C++ 程序那样，直接使用由 Intel 提供的，将被替换为具体 SIMD 指令的 intrinsic 方法。

​	HotSpot 虚拟机提供的替代方案是 Java 层面的 intrinsic 方法，这些 intrinsic 方法的语义要比单个 SIMD 指令复杂得多。在运行过程中，HotSpot 虚拟机将根据当前体系架构来决定是否将对该 intrinsic 方法的调用替换为另一高效的实现。如果不，则使用原本的 Java 实现。

​	这些 intrinsic 方法只能做到点覆盖，在不少情况下，应用程序并不会用到这些 intrinsic 的语义，却又存在向量化优化的机会。这个时候，我们便需要借助即时编译器中的自动向量化（auto vectorization）。

#### 自动向量化

​	即时编译器的自动向量化将针对能够展开的计数循环，进行向量化优化。如这段代码，即时编译器便能够自动将其展开优化成使用PADDD指令的向量加法。

```java

void foo(int[] a, int[] b, int[] c) {
  for (int i = 0; i < c.length; i++) {
    c[i] = a[i] + b[i];
  }
}
```

​	之前描述过计数循环的判定，现在说下自动向量化的条件。

 	1.	循环变量的增量应为 1，即能够遍历整个数组。
 	2.	循环变量不能为 long 类型，否则 C2 无法将循环识别为计数循环。
 	3.	循环迭代之间最好不要有数据依赖，例如出现类似于a[i] = a[i-1]的语句。当循环展开之后，循环体内存在数据依赖，那么 C2 无法进行自动向量化。
 	4.	循环体内不要有分支跳转。
 	5.	不要手工进行循环展开。如果 C2 无法自动展开，那么它也将无法进行自动向量化。

​	我们可以看到，自动向量化的条件较为苛刻。而且，C2 支持的整数向量化操作并不多，据我所致只有向量加法，向量减法，按位与、或、异或，以及批量移位和批量乘法。C2 还支持向量点积的自动向量化，即两两相乘再求和，不过这需要多条 SIMD 指令才能完成，因此并不是十分高效。

​	为了解决向量化 intrinsic 以及自动向量化覆盖面过窄的问题，我们在 OpenJDK 的 Paname 项目[3]中尝试引入开发人员可控的向量化抽象。该抽象将提供一套通用的跨平台 API，让 Java 程序能够定义诸如IntVector的向量，并使用由它提供的一系列向量化 intrinsic 方法。即时编译器负责将这些 intrinsic 的调用转换为符合当前体系架构 /CPU 的 SIMD 指令。如果你感兴趣的话，可以参考 Vladimir Ivanov 今年在 JVMLS 上的演讲。

### 注解处理器

​	注解（annotation）是 Java 5 引入的，用来为类、方法、字段、参数等 Java 结构提供额外信息的机制。比如，Java 核心类库中的@Override注解是被用来声明某个实例方法重写了父类的同名同参数类型的方法。

```java

package java.lang;

@Target(ElementType.METHOD)
@Retention(RetentionPolicy.SOURCE)
public @interface Override {
}
```

​	@Override注解本身被另外两个元注解（即作用在注解上的注解）所标注。其中，@Target用来限定目标注解所能标注的 Java 结构，这里@Override便只能被用来标注方法。@Retention则用来限定当前注解生命周期。注解共有三种不同的生命周期：SOURCE，CLASS或RUNTIME，分别表示注解只出现在源代码中，只出现在源代码和字节码中，以及出现在源代码、字节码和运行过程中。

​	这里@Override便只能出现在源代码中。一旦标注了@Override的方法所在的源代码被编译为字节码，该注解便会被擦除。不难猜到，@Override仅对 Java 编译器有用。事实上，它会为 Java 编译器引入了一条新的编译规则，即如果所标注的方法不是 Java 语言中的重写方法，那么编译器会报错。而当编译完成时，它的使命也就结束了。

​	Java 的注解机制允许开发人员自定义注解。这些自定义注解同样可以为 Java 编译器添加编译规则。不过，这种功能需要由开发人员提供，并且以插件的形式接入 Java 编译器中，这些插件我们称之为注解处理器（annotation processor）。除了**引入新的编译规则**之外，注解处理器还可以用于**修改已有的 Java 源文件（不推荐**），或者**生成新的 Java 源文件**。

#### 注解处理器的原理

![注解处理器工作流程](.\static\image\注解处理器工作流程.webp)

如上图所示 ，Java 源代码的编译过程可分为三个步骤：

1. 将源文件解析为抽象语法树；
2. 调用已注册的注解处理器；
3. 生成字节码。

如果在第 2 步调用注解处理器过程中生成了新的源文件，那么编译器将重复第 1、2 步，解析并且处理新生成的源文件。每次重复我们称之为一轮（Round）。也就是说，第一轮解析、处理的是输入至编译器中的已有源文件。如果注解处理器生成了新的源文件，则开始第二轮、第三轮，解析并且处理这些新生成的源文件。当注解处理器不再生成新的源文件，编译进入最后一轮，并最终进入生成字节码的第 3 步。

#### 自定义注解编译器引入新的编译规则

##### 自定义注解

​	首先需要自定义注解，比如自定义注解@CheckGetter，用于检查被标记的类或字段是否拥有GET方法。

```java

package foo;

import java.lang.annotation.*;

@Target({ ElementType.TYPE, ElementType.FIELD })
@Retention(RetentionPolicy.SOURCE)
public @interface CheckGetter {
}
```

##### 自定义注解处理器	

接下来需要实现一个处理@CheckGetter注解的处理器。它将遍历被标注的类中的实例字段，并检查有没有相应的getter方法。

```java

public interface Processor {

  void init(ProcessingEnvironment processingEnv);
  
  Set<String> getSupportedAnnotationTypes();
  
  SourceVersion getSupportedSourceVersion();
  
  boolean process(Set<? extends TypeElement> annotations, RoundEnvironment roundEnv);
  
  ...
}
```

​	所有的注解处理器类都要实现接口Processor。该接口主要由四个重要方法。

	1.	init方法用来存放注解处理器的初始化代码。之所以不用构造器，是因为在 Java 编译器中，注解处理器的实例是通过反射 API 生成的。也正是因为使用反射 API，每个注解处理器类都需要定义一个无参数构造器。通常来说，当编写注解处理器时，我们不声明任何构造器，并依赖于 Java 编译器，为之插入一个无参数构造器。而具体的初始化代码，则放入init方法之中。
	1.	getSupportedAnnotationTypes方法将返回注解处理器所支持的注解类型，这些注解类型只需用字符串形式表示即可。
	1.	getSupportedSourceVersion方法将返回该处理器所支持的 Java 版本，通常，这个版本需要与你的 Java 编译器版本保持一致。
	1.	process方法则是最为关键的注解处理方法

​		JDK 提供了一个实现Processor接口的抽象类AbstractProcessor。该抽象类实现了init、getSupportedAnnotationTypes和getSupportedSourceVersion方法。它的子类可以通过@SupportedAnnotationTypes和@SupportedSourceVersion注解来声明所支持的注解类型以及 Java 版本。

```java

package bar;

import java.util.Set;

import javax.annotation.processing.*;
import javax.lang.model.SourceVersion;
import javax.lang.model.element.*;
import javax.lang.model.util.ElementFilter;
import javax.tools.Diagnostic.Kind;

import foo.CheckGetter;

@SupportedAnnotationTypes("foo.CheckGetter")
@SupportedSourceVersion(SourceVersion.RELEASE_10)
public class CheckGetterProcessor extends AbstractProcessor {

  @Override
  public boolean process(Set<? extends TypeElement> annotations, RoundEnvironment roundEnv) {
    // TODO: annotated ElementKind.FIELD
    for (TypeElement annotatedClass : ElementFilter.typesIn(roundEnv.getElementsAnnotatedWith(CheckGetter.class))) {
      for (VariableElement field : ElementFilter.fieldsIn(annotatedClass.getEnclosedElements())) {
        if (!containsGetter(annotatedClass, field.getSimpleName().toString())) {
          processingEnv.getMessager().printMessage(Kind.ERROR,
              String.format("getter not found for '%s.%s'.", annotatedClass.getSimpleName(), field.getSimpleName()));
        }
      }
    }
    return true;
  }

  private static boolean containsGetter(TypeElement typeElement, String name) {
    String getter = "get" + name.substring(0, 1).toUpperCase() + name.substring(1).toLowerCase();
    for (ExecutableElement executableElement : ElementFilter.methodsIn(typeElement.getEnclosedElements())) {
      if (!executableElement.getModifiers().contains(Modifier.STATIC)
          && executableElement.getSimpleName().toString().equals(getter)
          && executableElement.getParameters().isEmpty()) {
        return true;
      }
    }
    return false;
  }
}
```

​	该注解处理器仅重写了process方法。这个方法将接收两个参数，分别代表该注解处理器所能处理的注解类型，以及囊括当前轮生成的抽象语法树的RoundEnvironment。由于该处理器针对的注解仅有@CheckGetter一个，而且我们并不会读取注解中的值，因此第一个参数并不重要。

​	process方法涉及各种不同类型的Element，分别指代 Java 程序中的各个结构。如TypeElement指代类或者接口，VariableElement指代字段、局部变量、enum 常量等，ExecutableElement指代方法或者构造器。

##### 注册自定义注解处理器

在将该注解处理器编译成 class 文件后，我们便可以将其注册为 Java 编译器的插件，并用来处理其他源代码。

###### 使用 javac 命令的-processor参数

```bash
javac -cp /CLASSPATH/TO/CheckGetterProcessor -processor bar.CheckGetterProcessor Foo.java
```

###### SPI

将注解处理器编译生成的 class 文件压缩入 jar 包中，并在 jar 包的配置文件中记录该注解处理器的包名及类名，即bar.CheckGetterProcessor。

在 ‘META-INF/services/javax.annotation.processing.Processor’ 路径下配置

```
bar.CheckGetterProcessor
```

当启动 Java 编译器时，它会寻找 classpath 路径上的 jar 包是否包含上述配置文件，并自动注册其中记录的注解处理器。

###### 通过IDE 中配置注解处理器

#### 利用注解处理器生成源代码

​	注解处理器可以用来修改已有源代码或者生成源代码。确切地说，注解处理器并不能真正地修改已有源代码。这里指的是修改由 Java 源代码生成的抽象语法树，在其中修改已有树节点或者插入新的树节点，从而使生成的字节码发生变化。对抽象语法树的修改涉及了 Java 编译器的内部 API，这部分很可能随着版本变更而失效。因此，并不推荐这种修改方式。

​	用注解处理器来生成源代码则比较常用。通过Filer.createSourceFile方法获得一个类似于文件的概念，并通过PrintWriter将具体的内容一一写入即可。当将该注解处理器作为插件接入 Java 编译器时，编译前面的源代码将生成新的代码，并且触发新一轮的编译。

### 基准测试框架JMH

#### 性能基准测试

​	性能测试要考虑JVM(即时编译器优化)、操作系统和硬件系统所带来的影响。

​	JVM要考虑热点代码，即时编译器优化，方法内联等。操作系统要考虑CPU缓存、分支预测器、超线程技术。硬件系统要考虑温度对硬件的影响。

​	就 CPU 缓存而言，如果程序的数据本地性较好，那么它的性能指标便会非常好；如果程序存在 false sharing 的问题，即几个线程写入内存中属于同一缓存行的不同部分，那么它的性能指标便会非常糟糕。

​	超线程技术是另一个可能误导性能测试工具的因素。超线程技术将为每个物理核心虚拟出两个虚拟核心，从而尽可能地提高物理核心的利用率。如果性能测试的两个线程被安排在同一物理核心上，那么得到的测试数据显然要比被安排在不同物理核心上的数据糟糕得多。

#### JMH（Java Microbenchmark Harness）

​	JMH 是一个面向 Java 语言或者其他 Java 虚拟机语言的性能基准测试框架。它针对的是纳秒级别（出自官网介绍，个人觉得精确度没那么高）、微秒级别、毫秒级别，以及秒级别的性能测试。

​	JMH 内置了许多功能来控制即时编译器的优化。对于其他影响性能评测的因素，JMH 也提供了不少策略来降低影响，甚至是彻底解决。因此，使用这个性能基准测试框架的开发人员，可以将精力完全集中在所要测试的业务逻辑，并以最小的代价控制除了业务逻辑之外的可能影响性能的因素。

​	通常来说，性能基准测试的结果反映的是所测试的业务逻辑在所运行的 Java 虚拟机，操作系统，硬件系统这一组合上的性能指标，而根据这些性能指标得出的通用结论则需要经过严格论证。

##### 生成JMH项目

```bash
$ mvn archetype:generate \
          -DinteractiveMode=false \
          -DarchetypeGroupId=org.openjdk.jmh \
          -DarchetypeArtifactId=jmh-java-benchmark-archetype \
          -DgroupId=org.sample \
          -DartifactId=test \
          -Dversion=1.21
$ cd test
```

​	该命令将在当前目录下生成一个test文件夹（对应参数-DartifactId=test，可更改），其中便包含了定义该 maven 项目依赖的pom.xml文件，以及自动生成的测试文件src/main/org/sample/MyBenchmark.java（这里org/sample对应参数-DgroupId=org.sample，可更改）

```java

/*
 * Copyright ...
 */
package org.sample;

import org.openjdk.jmh.annotations.Benchmark;

public class MyBenchmark {

    @Benchmark
    public void testMethod() {
        // This is a demo/sample template for building your JMH benchmarks. Edit as needed.
        // Put your benchmark code here.
    }

}
```

​	这里面，类名MyBenchmark以及方法名testMethod可以随意更改。重要的是@Benchmark注解。被它标注的方法，便是 JMH 基准测试的测试方法。

##### 编译和运行JMH项目

​	JMH 利用注解处理器来自动生成性能测试的代码。除了@Benchmark之外，JMH 的注解处理器还将处理所有位于org.openjdk.jmh.annotations包下的注解。

​	编译项目

```bash

$ mvn compile
$ ls target/generated-sources/annotations/org/sample/generated/
MyBenchmark_jmhType.java            MyBenchmark_jmhType_B1.java         MyBenchmark_jmhType_B2.java         MyBenchmark_jmhType_B3.java         MyBenchmark_testMethod_jmhTest.java
```

​	在这些源代码里，所有以MyBenchmark_jmhType为前缀的 Java 类都继承自MyBenchmark。这是注解处理器的常见用法，即通过生成子类来将注解所带来的额外语义扩张成方法。具体来说，它们之间的继承关系是MyBenchmark_jmhType -> B3 -> B2 -> B1 -> MyBenchmark（这里A -> B代表 A 继承 B）。其中，B2 存放着 JMH 用来控制基准测试的各项字段。

​	为了避免这些控制字段对MyBenchmark类中的字段造成 false sharing 的影响，JMH 生成了 B1 和 B3，分别存放了 256 个 boolean 字段，从而避免 B2 中的字段与MyBenchmark类、MyBenchmark_jmhType类中的字段（或内存里下一个对象中的字段）会出现在同一缓存行中。之所以不能在同一类中安排这些字段，是因为 Java 虚拟机的字段重排列。而类之间的继承关系，便可以避免不同类所包含的字段之间的重排列。

​	打包项目

```bash
$ mvn package
$ java -jar target/benchmarks.jar
```

​	这里 JMH 会有非常多的输出，输出的最后便是本次基准测试的结果。其中比较重要的两项指标是Score和Error，分别代表本次基准测试的平均吞吐量（每秒运行testMethod方法的次数）以及误差范围。

##### JMH中的注解

 +	@Fork代表JMH为了获得一个相对干净的虚拟机环境， 会 Fork 出一个新的 Java 虚拟机，来运行性能基准测试。通过运行更多的 Fork，并将每个 Java 虚拟机的性能测试结果平均起来，可以增强最终数据的可信度，使其误差更小。
 +	@BenchmarkMode允许指定性能数据的格式。除了吞吐量之外，还可以输出其他格式的性能数据，例如运行一次操作的平均时间。
 +	@Warmup可以配置预热迭代的次数以及每次迭代的持续时间。@Warmup注解有四个参数，分别为预热迭代的次数iterations，每次迭代持续的时间time和timeUnit（前者是数值，后者是单位。例如上面代码代表的是每次迭代持续 100 毫秒），以及每次操作包含多少次对测试方法的调用batchSize。
 +	@Measurement配置测试迭代。可配置选项和@Warmup的一致。与预热迭代不同的是，每个 Fork 中测试迭代的数目越多，我们得到的性能数据也就越精确。
 +	@State配置程序的状态。通常来说，我们所要测试的业务逻辑只是整个应用程序中的一小部分，例如某个具体的 web app 请求。这要求在每次调用测试方法前，程序处于准备接收请求的状态。我们可以把上述场景抽象一下，变成程序从某种状态到另一种状态的转换，而性能测试，便是在收集该转换的性能数据。JMH 提供了@State注解，被它标注的类便是程序的状态。由于 JMH 将负责生成这些状态类的实例，因此，它要求状态类必须拥有无参数构造器，以及当状态类为内部类时，该状态类必须是静态的。JMH 还将程序状态细分为整个虚拟机的程序状态，线程私有的程序状态，以及线程组私有的程序状态，分别对应@State注解的参数Scope.Benchmark，Scope.Thread和Scope.Group。需要注意的是，这里的线程组并非 JDK 中的那个概念。
 +	@Setup和@TearDown在测试前初始化程序状态，在测试后校验程序状态。和 JUnit 测试一样，被它们标注的方法必须是状态类中的方法。而且，JMH 并不限定状态类中@Setup方法以及@TearDown方法的数目。当存在多个@Setup方法或者@TearDown方法时，JMH 将按照定义的先后顺序执行。
 +	@CompilerControl控制每个方法是否内联。

### Java虚拟机的监控及诊断工具

#### jps

​	打印所有正在运行的 Java 进程的相关信息。

​	在默认情况下，jps的输出信息包括 Java 进程的进程 ID 以及主类名。我们还可以通过追加参数，来打印额外的信息。例如，-l将打印模块名以及包名；-v将打印传递给 Java 虚拟机的参数（如-XX:+UnlockExperimentalVMOptions -XX:+UseZGC）；-m将打印传递给主类的参数。

​	如果某 Java 进程关闭了默认开启的UsePerfData参数（即使用参数-XX:-UsePerfData），那么jps命令（以及下面介绍的jstat）将无法探知该 Java 进程。

#### jstat

​	打印目标 Java 进程的性能数据，它包括多条子命令。默认情况下，jstat只会打印一次性能数据。我们可以将它配置为每隔一段时间打印一次，直至目标 Java 进程终止，或者达到我们所配置的最大打印次数。

​	jstat有一个非常有用的参数-t，它将在每行数据之前打印目标 Java 进程的启动时间。

​	我们可以比较 Java 进程的启动时间以及总 GC 时间（GCT 列），或者两次测量的间隔时间以及总 GC 时间的增量，来得出 GC 时间占运行时间的比例。如果该比例超过 20%，则说明目前堆的压力较大；如果该比例超过 90%，则说明堆里几乎没有可用空间，随时都可能抛出 OOM 异常。

​	jstat还可以用来判断是否出现内存泄漏。在长时间运行的 Java 程序中，我们可以运行jstat命令连续获取多行性能数据，并取这几行数据中 OU 列（即已占用的老年代内存）的最小值。然后，我们每隔一段较长的时间重复一次上述操作，来获得多组 OU 最小值。如果这些值呈上涨趋势，则说明该 Java 程序的老年代内存已使用量在不断上涨，这意味着无法回收的对象在不断增加，因此很有可能存在内存泄漏。

```

$ jstat -options
-class 类加载相关的数据
-compiler 即时编译相关的数据
-gc 垃圾回收相关的数据
-gccapacity
-gccause
-gcmetacapacity
-gcnew
-gcnewcapacity
-gcold
-gcoldcapacity
-gcutil
-printcompilation 即时编译相关的数据
```

#### jmap

​	分析 Java 虚拟机堆中的对象。

```
jamp 子命令:
-clstats，该子命令将打印被加载类的信息。
-finalizerinfo，该子命令将打印所有待 finalize 的对象。
-histo，该子命令将统计各个类的实例数目以及占用内存，并按照内存使用量从多至少的顺序排列。此外，-histo:live只统计堆中的存活对象。
-dump，该子命令将导出 Java 虚拟机堆的快照。同样，-dump:live只保存堆中的存活对象。我们通常会利用
```

​	由于jmap将访问堆中的所有对象，为了保证在此过程中不被应用线程干扰，jmap需要借助安全点机制，让所有线程停留在不改变堆中数据的状态。也就是说，由jmap导出的堆快照必定是安全点位置的。这可能导致基于该堆快照的分析结果存在偏差。举个例子，假设在编译生成的机器码中，某些对象的生命周期在两个安全点之间，那么:live选项将无法探知到这些对象。另外，如果某个线程长时间无法跑到安全点，jmap将一直等下去。

​	jstat则不同。这是因为垃圾回收器会主动将jstat所需要的摘要数据保存至固定位置之中，而jstat只需直接读取即可。

​	jmap（以及jinfo、jstack和jcmd）依赖于 Java 虚拟机的Attach API，因此只能监控本地 Java 进程。一旦开启 Java 虚拟机参数DisableAttachMechanism（即使用参数-XX:+DisableAttachMechanism），基于 Attach API 的命令将无法执行。反过来说，如果你不想被其他进程监控，那么你需要开启该参数。

#### jinfo

​	查看目标 Java 进程的参数。如传递给 Java 虚拟机的-X（即输出中的 jvm_args）、-XX参数（即输出中的 VM Flags），以及可在 Java 层面通过System.getProperty获取的-D参数（即输出中的 System Properties）。

#### jstack

​	打印目标 Java 进程中各个线程的栈轨迹，以及这些线程所持有的锁。

​	jstack的其中一个应用场景便是死锁检测。jstack不仅会打印线程的栈轨迹、线程状态（BLOCKED）、持有的锁（locked …）以及正在请求的锁（waiting to lock …），而且还会分析出具体的死锁。

#### jcmd

​	使用jcmd命令，可以来替代前面除了jstat之外的所有命令。

​	至于jstat的功能，虽然jcmd复制了jstat的部分代码，并支持通过PerfCounter.print子命令来打印所有的 Performance Counter，但是它没有保留jstat的输出格式，也没有重复打印的功能。

#### eclipse MAT

​	解析Java 虚拟机堆的二进制快照的工具。快照可以使用jmap导出，也可以使用MAT本身获取。eclipse  MAT获取时将借助jps列出当前正在运行的 Java 进程，以供选择并获取快照。由于jps会将自己列入其中，因此你会在列表中发现一个已经结束运行的jps进程。获取快照的本质都是在使用Attach API。

​	MAT 计算对象占据内存的有两种方式。第一种是 Shallow heap，指的是对象自身所占据的内存。第二种是 Retained heap，指的是当对象不再被引用时，垃圾回收器所能回收的总内存，包括对象自身所占据的内存，以及仅能够通过该对象引用到的其他对象所占据的内存。

​	MAT 包括了两个比较重要的视图，分别是直方图（histogram）和支配树（dominator tree）。

​	MAT 的直方图和jmap的-histo子命令一样，都能够展示各个类的实例数目以及这些实例的 Shallow heap 总和。但是，MAT 的直方图还能够计算 Retained heap，并支持基于实例数目或 Retained heap 的排序方式（默认为 Shallow heap）。此外，MAT 还可以将直方图中的类按照超类、类加载器或者包名分组。

​	支配树的概念源自图论。在一则流图（flow diagram）中，如果从入口节点到 b 节点的所有路径都要经过 a 节点，那么 a 支配（dominate）b。在 a 支配 b，且 a 不同于 b 的情况下（即 a 严格支配 b），如果从 a 节点到 b 节点的所有路径中不存在支配 b 的其他节点，那么 a 直接支配（immediate dominate）b。这里的支配树指的便是由节点的直接支配节点所组成的树状结构。

​	需要注意的是，对象的引用型字段未必对应支配树中的父子节点关系。假设对象 a 拥有两个引用型字段，分别指向 b 和 c。而 b 和 c 各自拥有一个引用型字段，但都指向 d。如果没有其他引用指向 b、c 或 d，那么 a 直接支配 b、c 和 d，而 b（或 c）和 d 之间不存在支配关系。当在支配树视图中选中某一对象时，我们还可以通过 Path To GC Roots 功能，反向列出该对象到 GC Roots 的引用路径。

​	MAT 还将自动匹配内存泄漏中的常见模式，并汇报潜在的内存泄漏问题。

#### Java Mission Control

​	Java Mission Control（JMC）是 Java 虚拟机平台上的性能监控工具。它包含一个 GUI 客户端，以及众多用来收集 Java 虚拟机性能数据的插件，如 JMX Console（能够访问用来存放虚拟机各个子系统运行数据的MXBeans），以及虚拟机内置的高效 profiling 工具 Java Flight Recorder（JFR）。

​	JFR 的性能开销很小，在默认配置下平均低于 1%。与其他工具相比，JFR 能够直接访问虚拟机内的数据，并且不会影响虚拟机的优化。因此，它非常适用于生产环境下满负荷运行的 Java 程序。当启用时，JFR 将记录运行过程中发生的一系列事件。其中包括 Java 层面的事件，如线程事件、锁事件，以及 Java 虚拟机内部的事件，如新建对象、垃圾回收和即时编译事件。

​	按照发生时机以及持续时间来划分，JFR 的事件共有四种类型，它们分别为以下四种。

1. 瞬时事件（Instant Event），用户关心的是它们发生与否，例如异常、线程启动事件。
2. 持续事件（Duration Event），用户关心的是它们的持续时间，例如垃圾回收事件。
3. 计时事件（Timed Event），是时长超出指定阈值的持续事件。
4. 取样事件（Sample Event），是周期性取样的事件。取样事件的其中一个常见例子便是方法抽样（Method Sampling），即每隔一段时间统计各个线程的栈轨迹。如果在这些抽样取得的栈轨迹中存在一个反复出现的方法，那么我们可以推测该方法是热点方法。

​	JFR 的取样事件要比其他工具更加精确。以方法抽样为例，其他工具通常基于 JVMTI（Java Virtual Machine Tool Interface）的GetAllStackTraces API。该 API 依赖于安全点机制，其获得的栈轨迹总是在安全点上，由此得出的结论未必精确。JFR 则不然，它不依赖于安全点机制，因此其结果相对来说更加精确。

​	JFR 的启用方式主要有三种。

​	第一种是在运行目标 Java 程序时添加-XX:StartFlightRecording=参数。如

```
# Time fixed
$ java -XX:StartFlightRecording=delay=5s,duration=20s,filename=myrecording.jfr,settings=profile MyApp
```

​	JFR 将会在 Java 虚拟机启动 5s 后（对应delay=5s）收集数据，持续 20s（对应duration=20s）。当收集完毕后，JFR 会将收集得到的数据保存至指定的文件中（对应filename=myrecording.jfr）。settings=profile指定了 JFR 所收集的事件类型。默认情况下，JFR 将加载配置文件$JDK/lib/jfr/default.jfc，并识别其中所包含的事件类型。当使用了settings=profile配置时，JFR 将加载配置文件$JDK/lib/jfr/profile.jfc。该配置文件所包含的事件类型要多于默认的default.jfc，因此性能开销也要大一些（约为 2%）。default.jfc以及profile.jfc均为 XML 文件。后面我会介绍如何利用 JMC 来进行修改。

```
# Continuous, dump on exit
$ java -XX:StartFlightRecording=dumponexit=true,filename=myrecording.jfr MyApp
```

​	JFR 将在 Java 虚拟机启动之后持续收集数据，直至进程退出。在进程退出时（对应dumponexit=true），JFR 会将收集得到的数据保存至指定的文件中。

```
# Continuous, dump on demand
$ java -XX:StartFlightRecording=maxage=10m,maxsize=100m,name=SomeLabel MyAppStarted recording 1.

Use jcmd 38502 JFR.dump name=SomeLabel filename=FILEPATH to copy recording data to file.
...
```

​	JFR 将在 Java 虚拟机启动之后持续收集数据，直至进程退出。该命令不会主动保存 JFR 收集得到的数据。，maxage=10m指的是仅保留 10 分钟以内的事件，maxsize=100m指的是仅保留 100MB 以内的事件。一旦所收集的事件达到其中任意一个限制，JFR 便会开始清除不合规格的事件。

​	然而，为了保持较小的性能开销，JFR 并不会频繁地校验这两个限制。因此，在实践过程中你往往会发现指定文件的大小超出限制，或者文件中所存储事件的时间超出限制。

​	该命令不会主动保存 JFR 收集得到的数据。用户需要运行jcmd JFR.dump命令方能保存。



​	第二种启用方式，即通过jcmd来让 JFR 开始收集数据、停止收集数据，或者保存所收集的数据，对应的子命令分别为JFR.start，JFR.stop，以及JFR.dump。

​	JFR.start子命令所接收的配置及格式和-XX:StartFlightRecording=参数的类似。这些配置包括delay、duration、settings、maxage、maxsize以及name。前几个参数我们都已经介绍过了，最后一个参数name就是一个标签，当同一进程中存在多个 JFR 数据收集操作时，我们可以通过该标签来辨别。在启动目标进程时，我们不再添加-XX:StartFlightRecording=参数。在目标进程运行过程中，我们可以运行JFR.start子命令远程启用目标进程的 JFR 功能。

​	

​	第三种启用 JFR 的方式则是 JMC 中的 JFR 插件。

### JNI(Java Native Interface)

​	**JNI** （**Java Native Interface，Java本地接口**）是一种编程框架，使得Java虚拟机中的Java程序可以调用本地应用/或库(Java 核心类库无法提供的/某个体系架构或者操作系统特有的功能)，也可以被其他程序调用。这种方式会牺牲可移植性。

​	Java 中标记为native的、没有方法体的方法就是JNI的例子。当在 Java 代码中调用这些 native 方法时，Java 虚拟机将通过 JNI，调用至对应的 C 函数。

​	举个例子，Object.hashCode方法便是一个 native 方法。它对应的 C 函数将计算对象的哈希值，并缓存在对象头、栈上锁记录（轻型锁）或对象监视锁（重型锁所使用的 monitor）中，以确保该值在对象的生命周期之内不会变更。

#### native 方法的链接

​	在调用 native 方法前，Java 虚拟机需要将该 native 方法链接至对应的 C 函数上。

​	链接方式主要有两种。

​	第一种是让 Java 虚拟机自动查找符合默认命名规范的 C 函数，并且链接起来。可以使用javac -h命令，便可以根据 Java 程序中的 native 方法声明，自动生成包含符合命名规范的 C 函数的头文件。native 方法对应的 C 函数都需要以Java\_为前缀，之后跟着完整的包名和方法名。由于 C 函数名不支持/字符，因此我们需要将/转换为\_，而原本方法名中的\_符号，则需要转换为\_1。当某个类出现重载的 native 方法时，Java 虚拟机还会将参数类型纳入自动链接对象的考虑范围之中。具体的做法便是在前面 C 函数名的基础上，追加\_\_以及方法描述符作为后缀。方法描述符的特殊符号同样会被替换掉，如引用类型所使用的;会被替换为\_2，数组类型所使用的[会被替换为_3。

​	第二种链接方式则是在 C 代码中主动链接。这种链接方式对 C 函数名没有要求。通常我们会使用一个名为registerNatives的 native 方法，并按照第一种链接方式定义所能自动链接的 C 函数。在该 C 函数中，我们将手动链接该类的其他 native 方法。

​	举个例子，Object类便拥有一个registerNatives方法，所对应的 C 代码如下所示：

```java

// 注：Object类的registerNatives方法的实现位于java.base模块里的C代码中
static JNINativeMethod methods[] = {
    {"hashCode",    "()I",                    (void *)&JVM_IHashCode},
    {"wait",        "(J)V",                   (void *)&JVM_MonitorWait},
    {"notify",      "()V",                    (void *)&JVM_MonitorNotify},
    {"notifyAll",   "()V",                    (void *)&JVM_MonitorNotifyAll},
    {"clone",       "()Ljava/lang/Object;",   (void *)&JVM_Clone},
};

JNIEXPORT void JNICALL
Java_java_lang_Object_registerNatives(JNIEnv *env, jclass cls)
{
    (*env)->RegisterNatives(env, cls,
                            methods, sizeof(methods)/sizeof(methods[0]));
}
```

​	当使用第二种方式进行链接时，我们需要在其他 native 方法被调用之前完成链接工作。因此，我们往往会在类的初始化方法里调用该registerNatives方法。具体示例如下所示：

```java
public class Object {
    private static native void registerNatives();
    static {
        registerNatives();
    }
}
```

​		在使用JNI时，需要将C函数编译为动态链接库，这里需要注意的是，动态链接库的名字须以lib为前缀，以.dylib(或 Linux 上的.so）为扩展名。

```bash
# 该命令仅适用于macOS
$ gcc -I$JAVA_HOME/include -I$JAVA_HOME/include/darwin -o libfoo.dylib -shared foo.c
```

​	如果libfoo.dylib不在当前路径下，我们可以在启动 Java 虚拟机时配置java.library.path参数，使其指向包含libfoo.dylib的文件夹。具体命令如下所示：

```bash
$ java -Djava.library.path=/PATH/TO/DIR/CONTAINING/libfoo.dylib org.example.FooHello, World
```

#### JNI 的 API

​	在 C 代码中，我们也可以使用 Java 的语言特性，如 instanceof 测试等。这些功能都是通过特殊的 JNI 函数（JNI Functions）来实现的。

​	Java 虚拟机会将所有 JNI 函数的函数指针聚合到一个名为JNIEnv的数据结构之中。这是一个线程私有的数据结构。Java 虚拟机会为每个线程创建一个JNIEnv，并规定 C 代码不能将当前线程的JNIEnv共享给其他线程，否则 JNI 函数的正确性将无法保证。

​	这么设计的原因主要有两个。一是给 JNI 函数提供一个单独命名空间。二是允许 Java 虚拟机通过更改函数指针替换 JNI 函数的具体实现，例如从附带参数类型检测的慢速版本，切换至不做参数类型检测的快速版本。在 HotSpot 虚拟机中，JNIEnv被内嵌至 Java 线程的数据结构之中。部分虚拟机代码甚至会从JNIEnv的地址倒推出 Java 线程的地址。因此，如果在其他线程中使用当前线程的JNIEnv，会使这部分代码错误识别当前线程。

​	JNI 会将 Java 层面的基本类型以及引用类型映射为另一套可供 C 代码使用的数据结构。其中，基本类型的对应关系如下表所示：

| Java类型 | C数据结构 |
| -------- | --------- |
| boolean  | jboolean  |
| byte     | jbyte     |
| char     | jchar     |
| short    | jshort    |
| int      | jint      |
| float    | jfloat    |
| long     | jlong     |
| double   | jdouble   |
| void     | jvoid     |

​	引用类型对应的数据结构之间也存在着继承关系，具体如下所示：

```

jobject
|- jclass (java.lang.Class objects)
|- jstring (java.lang.String objects)
|- jthrowable (java.lang.Throwable objects)
|- jarray (arrays)
   |- jobjectArray (object arrays)
   |- jbooleanArray (boolean arrays)
   |- jbyteArray (byte arrays)
   |- jcharArray (char arrays)
   |- jshortArray (short arrays)
   |- jintArray (int arrays)
   |- jlongArray (long arrays)
   |- jfloatArray (float arrays)
   |- jdoubleArray (double arrays)
```

​	在C代码中获取字段:

```c
// foo.c
#include <stdio.h>
#include "org_example_Foo.h"

JNIEXPORT void JNICALL Java_org_example_Foo_bar__Ljava_lang_String_2Ljava_lang_Object_2
  (JNIEnv *env, jobject thisObject, jstring str, jobject obj) {
  jclass cls = (*env)->GetObjectClass(env, thisObject);
  jfieldID fieldID = (*env)->GetFieldID(env, cls, "i", "I");
  jint value = (*env)->GetIntField(env, thisObject, fieldID);
  printf("Hello, World 0x%x\n", value);
  return;
}
```

​	我们可以看到，在 JNI 中访问字段类似于反射 API：我们首先需要通过类实例获得FieldID，然后再通过FieldID获得某个实例中该字段的值。与 Java 代码相比，上述代码处理异常的方式不同。当调用 JNI 函数时，Java 虚拟机便已生成异常实例，并缓存在内存中的某个位置。与 Java 编程不一样的是，它并不会显式地跳转至异常处理器或者调用者中，而是继续执行接下来的 C 代码。因此，当从可能触发异常的 JNI 函数返回时，我们需要通过 JNI 函数ExceptionOccurred检查是否发生了异常，并且作出相应的处理。如果无须抛出该异常，那么我们需要通过 JNI 函数ExceptionClear显式地清空已缓存的异常。

#### 局部引用与全局引用

​	在 C 代码中，我们可以访问所传入的引用类型参数，也可以通过 JNI 函数创建新的 Java 对象。这些 Java 对象显然也会受到垃圾回收器的影响。因此，Java 虚拟机需要一种机制，来告知垃圾回收算法，不要回收这些 C 代码中可能引用到的 Java 对象。这种机制便是 JNI 的局部引用（Local Reference）和全局引用（Global Reference）。垃圾回收算法会将被这两种引用指向的对象标记为不可回收。

​	事实上，无论是传入的引用类型参数，还是通过 JNI 函数（除NewGlobalRef及NewWeakGlobalRef之外）返回的引用类型对象，都属于局部引用。不过，一旦从 C 函数中返回至 Java 方法之中，那么局部引用将失效。也就是说，垃圾回收器在标记垃圾时不再考虑这些局部引用。

​	这就意味着，我们不能缓存局部引用，以供另一 C 线程或下一次 native 方法调用时使用。对于这种应用场景，我们需要借助 JNI 函数NewGlobalRef，将该局部引用转换为全局引用，以确保其指向的 Java 对象不会被垃圾回收。相应的，我们还可以通过 JNI 函数DeleteGlobalRef来消除全局引用，以便回收被全局引用指向的 Java 对象。此外，当 C 函数运行时间极其长时，我们也应该考虑通过 JNI 函数DeleteLocalRef，消除不再使用的局部引用，以便回收被引用的 Java 对象。

​	另一方面，由于垃圾回收器可能会移动对象在内存中的位置，因此 Java 虚拟机需要另一种机制，来保证局部引用或者全局引用将正确地指向移动过后的对象。HotSpot 虚拟机是通过**句柄（handle）**来完成上述需求的。这里句柄指的是内存中 Java 对象的指针的指针。当发生垃圾回收时，如果 Java 对象被移动了，那么句柄指向的指针值也将发生变动，但句柄本身保持不变。

​	无论是局部引用还是全局引用，都是句柄。其中，局部引用所对应的句柄有两种存储方式，一是在本地方法栈帧中，主要用于存放 C 函数所接收的来自 Java 层面的引用类型参数；另一种则是线程私有的句柄块，主要用于存放 C 函数运行过程中创建的局部引用。

​	当从 C 函数返回至 Java 方法时，本地方法栈帧中的句柄将会被自动清除。而线程私有句柄块则需要由 Java 虚拟机显式清理。进入 C 函数时对引用类型参数的句柄化，和调整参数位置（C 调用和 Java 调用传参的方式不一样），以及从 C 函数返回时清理线程私有句柄块，共同造就了 JNI 调用的额外性能开销。

### Java Agent

​	在JDK1.5版本开始，Java增加了Instrumentation(Java Agent API)和JVMTI(JVM Tool Interface)功能，该功能可以实现JVM在加载某个class文件对其字节码进行修改，也可以对已经加载的字节码进行一个重新的加载。而在1.6版本新增了attach(附加方式)方式，可以对运行中的Java进程插入Agent。Java Agent可以去实现字节码插桩、动态跟踪分析等。

#### 运行模式

​	Java Agent需要以jar包的形式运行或加载，我们需要将编写好的Agent程序打包成一个jar文件。并且，Java Agent还强制要求了所有的jar文件中必须包含/META-INF/MANIFEST.MF文件，且该文件中必须定义Premain-Class(静态负载)或Agent-Class(动态负载)配置。

##### 静态负载(premain，启动时添加)

​	在应用程序启动时加载 Java 代理称为静态加载。 在执行任何代码之前，静态加载会在启动时修改字节码。静态加载使用*premain*方法，该方法将在任何应用程序代码运行之前运行(在agent.jar的MANIFEST.MF指定的Premain-class)：	

```
java -javaagent:agent.jar -jar application.jar
```

##### 动态负载(agentmain，运行时附加)

​	将 Java 代理加载到已运行的 JVM 中的过程称为动态加载，使用Java Attach API连接代理(在agent.jar的MANIFEST.MF指定的Agent-Class)。

```java
VirtualMachine jvm = VirtualMachine.attach(jvmPid);
jvm.loadAgent(agentFile.getAbsolutePath());
```

#### Java Agent类

​	Java Agent和普通的Java类并没有任何区别，普通的Java程序中规定了main方法为程序入口，而Java Agent则将premain和agentmain作为了Agent程序的入口，两者所接受的参数是完全一致的，如下：

```java
public static void premain(String args, Instrumentation inst) {} 
public static void agentmain(String args, Instrumentation inst) {}
```

`premain()`方法有两种写法,如下：

```java
public static void premain(String agentArgs, Instrumentation inst)    
public static void premain(String agentArgs)
```

`agentmain`方法允许以下面两种方式定义：

```
public static void agentmain(String agentArgs)
public static void agentmain(String agentArgs, Instrumentation inst)
```

JVM会去优先加载带 Instrumentation 签名的方法，加载成功忽略第二种，如果第一种没有，则加载第二种方法。

#### Instrumentation

​	Instrumentation接口的方法允许在运行时操作java程序，提供了诸如改变字节码，新增jar包，替换class等功能，而通过这些功能使Java具有了更强的动态控制和解释能力。Instrumentation中有3个方法比较重要和常用，分别为addTransformer、removeTransformer和redefineClasses 。

##### addTransformer

​	该方法允许我们在类加载之前，重新定义Class。

```java
void addTransformer(ClassFileTransformer transformer);
```

​	ClassFileTransformer是一个接口，只有一个`transform`方法，它在主程序的`main`方法执行前，装载的每个类都要经过`transform`执行一次，可以将它称为转换器。

​	ClassFileTransformer可以实现profile的收集。

##### redefineClasses

​	重定义class，通俗点来讲的话就是实现指定类的替换。

```java
void redefineClasses(ClassDefinition... definitions) throws  ClassNotFoundException, UnmodifiableClassException;
```

​	它的参数是可变长的`ClassDefinition`数组，再看一下`ClassDefinition`的构造方法：

```java
public ClassDefinition(Class<?> theClass,byte[] theClassFile) {...}
```

​	`ClassDefinition`中指定了的Class对象和修改后的字节码数组，简单来说，就是使用提供的类文件字节，替换了原有的类。并且，在`redefineClasses`方法重定义的过程中，传入的是`ClassDefinition`的数组，它会按照这个数组顺序进行加载，以便满足在类之间相互依赖的情况下进行更改。

##### retransformClasses

​	`retransformClasses`应用于agentmain模式，可以在类加载之后重新定义Class，即触发类的重新加载。

```java
void retransformClasses(Class<?>... classes) throws UnmodifiableClassException;
```

​	它的参数`classes`是需要转换的类数组，可变长参数也说明了它和`redefineClasses`方法一样，也可以批量转换类的定义。

##### 其他方法

```
removeTransformer：删除一个ClassFileTransformer类转换器
getAllLoadedClasses：获取当前已经被加载的Class
getInitiatedClasses：获取由指定的ClassLoader加载的Class
getObjectSize：获取一个对象占用空间的大小
appendToBootstrapClassLoaderSearch：添加jar包到启动类加载器
appendToSystemClassLoaderSearch：添加jar包到系统类加载器
isNativeMethodPrefixSupported：判断是否能给native方法添加前缀，即是否能够拦截native方法
setNativeMethodPrefix：设置native方法的前缀
```

### Graal

​	GraalVM 是一个高性能的、支持多种编程语言的执行环境。它既可以在传统的 OpenJDK 上运行，也可以通过 AOT（Ahead-Of-Time）编译成可执行文件单独运行，甚至可以集成至数据库中运行。除此之外，它还移除了编程语言之间的边界，并且支持通过即时编译技术，将混杂了不同的编程语言的代码编译到同一段二进制码之中，从而实现不同语言之间的无缝切换。

​	GraalVM 的基石是 Graal 编译器，这是一个用 Java 写就的即时编译器，它从 Java 9u 开始便被集成自 JDK 中，Graal 编译器可以通过 Java 虚拟机参数-XX:+UnlockExperimentalVMOptions -XX:+UseJVMCICompiler启用。当启用时，它将替换掉 HotSpot 中的 C2 编译器，并响应原本由 C2 负责的编译请求。

#### JVMCI（Compiler Interface，JVMCI）

​	即时编译器是 Java 虚拟机中相对独立的模块，它主要负责接收 Java 字节码，并生成可以直接运行的二进制码。具体来说，即时编译器与 Java 虚拟机的交互可以分为如下三个方面。

1. 响应编译请求；
2. 获取编译所需的元数据（如类、方法、字段）和反映程序执行状态的 profile；
3. 将生成的二进制码部署至代码缓存（code cache）里。

​	即时编译器通过这三个功能组成了一个响应编译请求、获取编译所需的数据，完成编译并部署的完整编译周期。

​	传统情况下，即时编译器是与 Java 虚拟机紧耦合的。也就是说，对即时编译器的更改需要重新编译整个 Java 虚拟机。为了让JVM和即时编译器解耦，引入了Java 虚拟机编译器接口（JVM Compiler Interface，JVMCI），将上述三个功能抽象成一个 Java 层面的接口。这样一来，在即时编译器所依赖的 JVMCI 版本不变的情况下，仅需要替换即 编译器相关的 jar 包，便可完成即时编译器升级。

​	JVMCI 的作用并不局限于完成由 Java 虚拟机发出的编译请求。实际上，Java 程序可以直接调用 Graal，编译并部署指定方法。

#### Graal和C2的区别

​	Graal 和 C2 最为明显的一个区别是：Graal 是用 Java 写的，而 C2 是用 C++ 写的。相对来说，Graal 更加模块化，也更容易开发与维护。

​	C++ 写的 C2 并不一定比 Graal 快。在充分预热的情况下，Java 程序中的热点代码(这里值Graal的热点代码)早已经通过即时编译转换为二进制码，在执行速度上并不亚于静态编译的 C++ 程序。再者，即便是解释执行 Graal，也仅是会减慢编译效率，而并不影响编译结果的性能。

​	换句话说，如果 C2 和 Graal 采用相同的优化手段，那么它们的编译结果是一样的。所以，程序达到稳定状态（即不再触发新的即时编译）的性能，也就是峰值性能，将也是一样的。

#### Graal 的实现

​	Graal 编译器将编译过程分为前端和后端两大部分。前端用于实现平台无关的优化（如方法内联），以及小部分平台相关的优化；而后端则负责大部分的平台相关优化（如寄存器分配），以及机器码的生成。

​	Graal 和 C2 都采用了 Sea-of-Nodes IR。严格来说，这里指的是 Graal 的前端，而后端采用的是另一种非 Sea-of-Nodes 的 IR。通常，我们将前端的 IR 称之为 High-level IR，或者 HIR；后端的 IR 则称之为 Low-level IR，或者 LIR。

​	Graal 的前端是由一个个单独的优化阶段（optimization phase）构成的。我们可以将每个优化阶段想象成一个图算法：它会接收一个规则的图，遍历图上的节点并做出优化，并且返回另一个规则的图。

​	Graal 和 C2 都采用了激进的投机性优化手段（speculative optimization）。这些优化都基于某种假设（assumption）。当假设出错的情况下，Java 虚拟机会借助去优化（deoptimization）这项机制，从执行即时编译器生成的机器码切换回解释执行，在必要情况下，它甚至会废弃这份机器码，并在重新收集程序 profile 之后，再进行编译。

​	Graal 与 C2 相比会更加激进。它从设计上便十分青睐这种基于假设的优化手段。在编译过程中，Graal 支持自定义假设，并且直接与去优化节点相关联。

​	Java 虚拟机的另一个能够大幅度提升性能的特性是 intrinsic 方法。在 Graal 中，实现高性能的 intrinsic 方法也相对比较简单。Graal 提供了一种替换方法调用的机制，在解析 Java 字节码时会将匹配到的方法调用，替换成对另一个内部方法的调用，或者直接替换为特殊节点。

### Truffle

​	实现一门新编程语言的传统做法是实现一个编译器，也就是把用该语言编写的程序转换成可直接在硬件上运行的机器码。通常来说，编译器分为前端和后端：前端负责词法分析、语法分析、类型检查和中间代码生成，后端负责编译优化和目标代码生成。

​	另一种比较取巧的做法则是将新语言编译成某种已知语言，或者已知的中间形式，例如将 Scala、Kotlin 编译成 Java 字节码。这样做的好处是可以直接享用 Java 虚拟机自带的各项优化，包括即时编译、自动内存管理等等。因此，这种做法对所生成的 Java 字节码的优化程度要求不高。

​	不过，不管是附带编译优化的编译器，还是生成中间形式并依赖于其他运行时的即时编译优化的编译器，它们所针对的都是编译型语言，在运行之前都需要这一额外的编译步骤。

​	与编译型语言相对应的则是解释型语言。对于这些语言来说，它们无须额外的编译步骤，而是依赖于解释执行器进行解析并执行。

​	为了让该解释执行器能够高效地运行大型程序，语言实现开发人员通常会将其包装在虚拟机里，并实现诸如即时编译、垃圾回收等其他组件。这些组件对语言设计 本身并无太大贡献，仅仅是为了实用性而不得不进行的工程实现。在理想情况下，我们希望在不同的语言实现中复用这些组件。也就是说，每当开发一门新语言时，我们只需要实现它的解释执行器，便能够直接复用即时编译、垃圾回收等组件，从而达到高性能的效果。这也是 Truffle 项目的目标。

#### Truffle 项目简介

​	Truffle 是一个用 Java 写就的语言实现框架。基于 Truffle 的语言实现仅需用 Java 实现词法分析、语法分析以及针对语法分析所生成的抽象语法树（Abstract Syntax Tree，AST）的解释执行器，便可以享用由 Truffle 提供的各项运行时优化。

​	就一个完整的 Truffle 语言实现而言，由于实现本身以及其所依赖的 Truffle 框架部分都是用 Java 实现的，因此它可以运行在任何 Java 虚拟机之上。当然，如果 Truffle 运行在附带了 Graal 编译器的 Java 虚拟机之上，那么它将调用 Graal 编译器所提供的 API，主动触发对 Truffle 语言的即时编译，将对 AST 的解释执行转换为执行即时编译后的机器码。在这种情况下，Graal 编译器相当于一个提供了即时编译功能的库，宿主虚拟机本身仍可使用 C2 作为其唯一的即时编译器，或者分层编译模式下的 4 层编译器。

#### Partial Evaluation

​	假设有一段程序P，它将一系列输入I转换成输出O（即P: I -> O）。而这些输入又可以进一步划分为编译时已知的常量IS，和编译时未知的ID。那么，我们可以将程序P: I -> O转换为等价的另一段程序P': ID -> O。这个新程序P'便是P的特化（Specialization），而从P转换到P'的这个过程便是所谓的 Partial Evaluation(感觉可以理解为IR的优化，对于常量直接返回)。

​	回到 Truffle 这边，我们可以将 Truffle 语言的解释执行器当成P，将某段用 Truffle 语言写就的程序当作IS，并通过 Partial Evaluation 特化为P'。由于 Truffle 语言的解释执行器是用 Java 写的，因此我们可以利用 Graal 编译器将P'编译为二进制码。

#### 节点重写

​	在动态语言中，许多变量的类型是在运行过程中方能确定的。以加法符号+为例，它既可以表示整数加法，还可以表示浮点数加法，甚至可以表示字符串加法。

​	如果是静态语言，我们可以通过推断加法的两个操作数的具体类型，来确定该加法的类型。但对于动态语言来说，我们需要在运行时动态确定操作数的具体类型，并据此选择对应的加法操作。这种在运行时选择语义的节点，会十分不利于即时编译，从而严重影响到程序的性能。Truffle 语言解释器会收集每个 AST 节点所代表的操作的类型，并且在即时编译时，作出针对所收集得到的类型 profile 的特化（specialization）。

​	这种优化是基于假设的投机性优化，以及在假设失败时的去优化。

	#### Polyglot

​	Truffle 语言实现框架则支持 Polyglot，允许在同一段代码中混用不同的编程语言，从而使得开发人员能够自由地选择合适的语言来实现子组件。与其他 Polyglot 框架不同的是，Truffle 语言之间能够共用对象。也就是说，在不对某个语言中的对象进行复制或者序列化反序列化的情况下，Truffle 可以无缝地将该对象传递给另一门语言。因此，Truffle 的 Polyglot 在切换语言时，性能开销非常小，甚至经常能够达到零开销。

​	Truffle 的 Polyglot 特性是通过 Polyglot API 来实现的。每个实现了 Polyglot API 的 Truffle 语言，其对象都能够被其他 Truffle 语言通过 Polyglot API 解析。实际上，当通过 Polyglot API 解析外来对象时，我们并不需要了解对方语言，便能够识别其数据结构，访问其中的数据，并进行进一步的计算。

## Java对象内存布局

### 对象结构

#### 对象头(Object Header)

##### 对象标记(markOop)

​	存储对象本身运行时的数据，如哈希码、GC标记(分代年龄？)、锁信息、线程关联信息等。这部分数据在64位JVM占8字节(64bit/8byte)。

##### 类元信息(klassOop)

​	存储指向对象本身的类元数据(即Klass)的首地址。这部分数据在64位JVM中，如果开启压缩指针占4字节，不开启占8字节。

#### 数组长度

​	这部分只有是数组对象才有，如果是非数组对象，就没这部分了，这部分占4字节（32bit）。

#### 实例数据(Instance Data)

​	分为基础数据类型和引用类型。基础数据类型按照类型的大小计算，引用类型在64位JVM中，如果开启压缩指针占4字节，不开启占8字节。

#### 对齐填充(Padding)

​	默认情况下，Java 虚拟机堆中对象的起始地址需要对齐至 8(对应虚拟机选项 -XX:ObjectAlignmentInBytes，默认值为 8) 的倍数(内存对齐)。如果一个对象用不到 8N 个字节，那么空白的那部分空间就浪费掉了。这些浪费掉的空间我们称之为对象间的填充。-XX:ObjectAlignmentInBytes设置的越大越浪费，比如对于一个17字节的对象，如果ObjectAlignmentInBytes=8，则需要填充7字节。如果ObjectAlignmentInBytes=16，则需要填充15字节。

​	内存对齐和压缩指针有一定的关系。压缩指针的原理是寻址单位不同。未开启压缩指针前，指针保存对象的真实内存地址,开启后保存对象的映射地址。打个比方，路上停着的全是房车，而且每辆房车恰好占据两个停车位。现在，我们按照顺序给它们编号。也就是说，停在 0 号和 1 号停车位上的叫 0 号车，停在 2 号和 3 号停车位上的叫 1 号车，依次类推。原本的内存寻址用的是车位号。比如说我有一个值为 6 的指针，代表第 6 个车位，那么沿着这个指针可以找到 3 号车。现在我们规定指针里存的值是车号，比如 3 指代 3 号车。当需要查找 3 号车时，我便可以将该指针的值乘以 2，再沿着 6 号车位找到 3 号车。

​	默认情况下，JVM以8((对应虚拟机选项 -XX:ObjectAlignmentInBytes，默认值为 8))字节对齐，所以映射地址可以映射出真实内存地址的8倍。压缩指针占4个字节(32bit)，CPU寻址的单位为byte，映射的最大真实内存地址为 2 ^ 32 * 8 (byte)=  32G。所以对于64位JVM，不超过32G内存时自动开启压缩指针。

​	当然，就算是关闭了压缩指针，Java 虚拟机还是会进行内存对齐。此外，内存对齐不仅存在于对象与对象之间，也存在于对象中的字段之间。比如说，Java 虚拟机要求 long 字段、double 字段，以及非压缩指针状态下的引用字段地址为 8 的倍数。

​	字段内存对齐的其中一个原因，是让字段只出现在同一 CPU 的缓存行中。如果字段不是对齐的，那么就有可能出现跨缓存行的字段。也就是说，该字段的读取可能需要替换两个缓存行，而该字段的存储也会同时污染两个缓存行。这两种情况对程序的执行效率而言都是不利的。

#### 字段重排序

​	**字段重排列，顾名思义，就是 Java 虚拟机重新分配字段的先后顺序，以达到内存对齐的目的。**Java 虚拟机中有三种排列方法（对应 Java 虚拟机选项 -XX:FieldsAllocationStyle，默认值为 1），但都会遵循如下两个规则。

​	其一，**如果一个字段占据 C 个字节，那么该字段的偏移量需要对齐至 NC。这里偏移量指的是字段地址与对象的起始地址差值。**以 long 类为例，它仅有一个 long 类型的实例字段。在使用了压缩指针的 64 位虚拟机中，尽管对象头的大小为 12 个字节，该 long 类型字段的偏移量也只能是 16，而中间空着的 4 个字节便会被浪费掉。

​	其二，**子类所继承字段的偏移量，需要与父类对应字段的偏移量保持一致。在具体实现中，Java 虚拟机还会对齐子类字段的起始位置。**对于使用了压缩指针的 64 位虚拟机，子类第一个字段需要对齐至 4N；而对于关闭了压缩指针的 64 位虚拟机，子类第一个字段则需要对齐至 8N。

~~~java
class A {
  long l;
  int i；
}

class B extends A {
  long l;
  int i;
}
~~~

~~~java
# 启用压缩指针时，B类的字段分布
B object internals:
 OFFSET  SIZE   TYPE DESCRIPTION
      0     4        (object header)
      4     4        (object header)
      8     4        (object header)
     12     4    int A.i                                       0
     16     8   long A.l                                       0
     24     8   long B.l                                       0
     32     4    int B.i                                       0
     36     4        (loss due to the next object alignment)
~~~

​	当启用压缩指针时，可以看到 Java 虚拟机将 A 类的 int 字段放置于 long 字段之前，以填充因为 long 字段对齐造成的 4 字节缺口。由于对象整体大小需要对齐至 8N，因此对象的最后会有 4 字节的空白填充。

~~~
# 关闭压缩指针时，B类的字段分布
B object internals:
 OFFSET  SIZE   TYPE DESCRIPTION
      0     4        (object header)
      4     4        (object header)
      8     4        (object header)
     12     4        (object header)
     16     8   long A.l
     24     4    int A.i
     28     4        (alignment/padding gap)                  
     32     8   long B.l
     40     4    int B.i
     44     4        (loss due to the next object alignment)
~~~

​	Java 8 还引入了一个新的注释 @Contended，用来解决对象字段之间的虚共享（false sharing）问题。这个注释也会影响到字段的排列。Java 虚拟机会让不同的 @Contended 字段处于独立的缓存行中，因此你会看到大量的空间被浪费掉。

## 垃圾回收(Garbage Collection)

​	JVM中内存是自动管理的，由垃圾回收器将已经分配出去的，但却不再使用的内存回收回来，以便能够再次分配。大致流程为先辨别(标记)出不使用的对象，然后进行回收。

### 标记方法

#### 引用计数法(reference counting)

​	为每个对象添加一个引用计数器，用来统计指向该对象的引用个数。一旦某个对象的引用计数器为 0，则说明该对象已经死亡，便可以被回收了。

​	除了需要额外的空间来存储计数器，以及繁琐的更新操作，引用计数法还有一个重大的漏洞，那便是无法处理循环引用对象。假设对象 a 与 b 相互引用，除此之外没有其他引用指向 a 或者 b。在这种情况下，a 和 b 实际上已经死了，但由于它们的引用计数器皆不为 0，在引用计数法的心中，这两个对象还活着。因此，这些循环引用对象所占据的空间将不可回收，从而造成了内存泄露。

#### 根可达算法

​	这个算法的实质在于将一系列 GC Roots 作为初始的存活对象合集（live set），然后从该合集出发，探索所有能够被该集合引用到的对象，并将其加入到该集合中，这个过程我们也称之为标记（mark）。最终，未被探索到的对象便是死亡的，是可以回收的。

​	GC Roots可以暂时理解为由堆外指向堆内的引用，一般分为如下几种：

 	1. 已加载类的静态变量；
 	2. 常量引用的对象；
 	3. Java 方法栈桢中的局部变量；
 	4. 本地方法占中引用的对象；

​	虽然可达性分析的算法本身很简明，但是在实践中还是有不少其他问题需要解决的。比如说，在多线程环境下，其他线程可能会更新已经访问过的对象中的引用，从而造成误报（将引用设置为 null）或者漏报（将引用设置为未被访问过的对象）。误报对于JVM来说，最多损失了部分垃圾回收的机会。但是漏报比较麻烦，如果垃圾回收器回收事实上仍被引用的对象内存。一旦从原引用访问已经被回收了的对象，则很有可能会直接导致 Java 虚拟机崩溃。

##### Stop-the-world 以及安全点

​	怎么解决这个问题呢？在 Java 虚拟机里，传统的垃圾回收算法采用的是一种简单粗暴的方式，那便是 Stop-the-world，停止其他非垃圾回收线程的工作，直到完成垃圾回收。这也就造成了垃圾回收所谓的暂停时间（GC pause）。

​	**Java 虚拟机中的 Stop-the-world 是通过安全点（safepoint）机制来实现的。当 Java 虚拟机收到 Stop-the-world 请求，它便会等待所有的线程都到达安全点，才允许请求 Stop-the-world 的线程进行独占的工作。**安全点的初始目的并不是让其他线程停下，而是找到一个稳定的执行状态。在这个执行状态下，Java 虚拟机的堆栈不会发生变化。这么一来，垃圾回收器便能够“安全”地执行可达性分析。

​	举个例子，当 Java 程序通过 JNI 执行本地代码时，如果这段代码不访问 Java 对象、调用 Java 方法或者返回至原 Java 方法，那么 Java 虚拟机的堆栈不会发生改变，也就代表着这段本地代码可以作为同一个安全点。只要不离开这个安全点，Java 虚拟机便能够在垃圾回收的同时，继续运行这段本地代码。

​	由于本地代码需要通过 JNI 的 API 来完成上述三个操作，因此 Java 虚拟机仅需在 API 的入口处进行安全点检测（safepoint poll），测试是否有其他线程请求停留在安全点里，便可以在必要的时候挂起当前线程。

​	除了执行 JNI 本地代码外，Java 线程还有其他几种状态：解释执行字节码、执行即时编译器生成的机器码和线程阻塞。阻塞的线程由于处于 Java 虚拟机线程调度器的掌控之下，因此属于安全点。其他几种状态则是运行状态，**需要虚拟机保证在可预见的时间内进入安全点。否则，垃圾回收线程可能长期处于等待所有线程进入安全点的状态，从而变相地提高了垃圾回收的暂停时间。**

​	对于解释执行来说，字节码与字节码之间皆可作为安全点。Java 虚拟机采取的做法是，当有安全点请求时，执行一条字节码便进行一次安全点检测。

​	执行即时编译器生成的机器码则比较复杂。由于这些代码直接运行在底层硬件之上，不受 Java 虚拟机掌控，因此在生成机器码时，即时编译器需要插入安全点检测，以避免机器码长时间没有安全点检测的情况。HotSpot 虚拟机的做法便是在生成代码的方法出口以及非计数循环的循环回边（back-edge）处插入安全点检测。

​	那么为什么不在每一条机器码或者每一个机器码基本块处插入安全点检测呢？原因主要有两个。

​	第一，安全点检测本身也有一定的开销。不过 HotSpot 虚拟机已经将机器码中安全点检测简化为一个内存访问操作。在有安全点请求的情况下，Java 虚拟机会将安全点检测访问的内存所在的页设置为不可读，并且定义一个 segfault 处理器，来截获因访问该不可读内存而触发 segfault 的线程，并将它们挂起。

​	第二，即时编译器生成的机器码打乱了原本栈桢上的对象分布状况。在进入安全点时，机器码还需提供一些额外的信息，来表明哪些寄存器，或者当前栈帧上的哪些内存空间存放着指向对象的引用，以便垃圾回收器能够枚举 GC Roots。

### 整理方法

#### 清除(sweep)

​	将死亡对象所占据的内存标记为空闲内存，并记录在一个空闲列表（free list）之中。当需要新建对象时，内存管理模块便会从该空闲列表中寻找空闲内存，并划分给新建的对象。

​	清除这种回收方式的原理及其简单，但是有两个缺点。一是会**造成内存碎片**。由于 Java 虚拟机的堆中对象必须是连续分布的，因此可能出现总空闲内存足够，但是无法分配的极端情况。另一个则是**分配效率较低**。如果是一块连续的内存空间，那么我们可以通过指针加法（pointer bumping）来做分配。而对于空闲列表，Java 虚拟机则需要逐个访问列表中的项，来查找能够放入新建对象的空闲内存。

#### 压缩	

​	将存活的对象聚集到内存区域的起始位置，从而留下一段连续的内存空间。这种做法能够解决内存碎片化的问题，但代价是压缩算法的性能开销。

#### 复制

​	即把内存区域分为两等分，分别用两个指针 from 和 to 来维护，并且只是用 from 指针指向的内存区域来分配内存。当发生垃圾回收时，便把存活的对象复制到 to 指针指向的内存区域中，并且交换 from 指针和 to 指针的内容。复制这种回收方式同样能够解决内存碎片化的问题，但是它的缺点也极其明显，即堆空间的使用效率极其低下。

### 分代回收

​	根据假设，大部分的 Java 对象只存活一小段时间，而存活下来的小部分 Java 对象则会存活很长一段时间。提出了JVM的分代回收思想，新生代和老年代，可以对不同代使用不同的回收算法。

​	对于新生代，我们猜测大部分的 Java 对象只存活一小段时间，那么便可以频繁地采用耗时较短的垃圾回收算法，让大部分的垃圾都能够在新生代被回收掉。对于老年代，我们猜测大部分的垃圾已经在新生代中被回收了，而在老年代中的对象有大概率会继续存活。当真正触发针对老年代的回收时，则代表这个假设出错了，或者堆的空间已经耗尽了。这时候，Java 虚拟机往往需要做一次全堆扫描，耗时也将不计成本。

### JVM堆划分

​	前面提到，Java 虚拟机将堆划分为新生代和老年代。其中，新生代又被划分为 Eden 区，以及两个大小相同的 Survivor 区。默认情况下，Java 虚拟机采取的是一种动态分配的策略（对应 Java 虚拟机参数 -XX:+UsePSAdaptiveSurvivorSizePolicy），根据生成对象的速率，以及 Survivor 区的使用情况动态调整 Eden 区和 Survivor 区的比例。当然，你也可以通过参数 -XX:SurvivorRatio 来固定这个比例。但是需要注意的是，其中一个 Survivor 区会一直为空，因此比例越低浪费的堆空间将越高。

​	通常来说，当我们调用 new 指令时，它会在 Eden 区中划出一块作为存储对象的内存。由于堆空间是线程共享的，因此直接在这里边划空间是需要进行同步的。否则，将有可能出现两个对象共用一段内存的事故。为了防止该情况，JVM采用TLAB（Thread Local Allocation Buffer，对应虚拟机参数 -XX:+UseTLAB，默认开启）预先给线程分配一段连续的内存，作为线程私有的 TLAB。这个操作需要加锁，线程需要维护两个指针（实际上可能更多，但重要也就两个），一个指向 TLAB 中空余内存的起始位置，一个则指向 TLAB 末尾。接下来的 new 指令，便可以直接通过指针加法（bump the pointer）来实现，即把指向空余内存位置的指针加上所请求的字节数。如果加法后空余内存指针的值仍小于或等于指向末尾的指针，则代表分配成功。否则，TLAB 已经没有足够的空间来满足本次新建操作。这个时候，便需要当前线程重新申请新的 TLAB。

​	当 Eden 区的空间耗尽了怎么办？这个时候 Java 虚拟机便会触发一次 Minor GC，来收集新生代的垃圾。存活下来的对象，则会被送到 Survivor 区。前面提到，新生代共有两个 Survivor 区，我们分别用 from 和 to 来指代。其中 to 指向的 Survivior 区是空的。当发生 Minor GC 时，Eden 区和 from 指向的 Survivor 区中的存活对象会被复制到 to 指向的 Survivor 区中，然后交换 from 和 to 指针，以保证下一次 Minor GC 时，to 指向的 Survivor 区还是空的。

​	Java 虚拟机会记录 Survivor 区中的对象一共被来回复制了几次。如果一个对象被复制的次数为 15（对应虚拟机参数 -XX:+MaxTenuringThreshold，对象头中使用4bit来存，因此最大15），那么该对象将被晋升（promote）至老年代。另外，如果单个 Survivor 区已经被占用了 50%（对应虚拟机参数 -XX:TargetSurvivorRatio），那么较高复制次数的对象也会被晋升至老年代。

​	总而言之，当发生 Minor GC 时，我们应用了标记 - 复制算法，将 Survivor 区中的老存活对象晋升到老年代，然后将剩下的存活对象和 Eden 区的存活对象复制到另一个 Survivor 区中。理想情况下，Eden 区中的对象基本都死亡了，那么需要复制的数据将非常少，因此采用这种标记 - 复制算法的效果极好。Minor GC 的另外一个好处是不用对整个堆进行垃圾回收。但是，它却有一个问题，那就是老年代的对象可能引用新生代的对象。也就是说，在标记存活对象的时候，我们需要扫描老年代中的对象。如果该对象拥有对新生代对象的引用，那么这个引用也会被作为 GC Roots。

​	这样一来，岂不是又做了一次全堆扫描呢？

### 卡表

​	HotSpot 给出的解决方案是一项叫做卡表（Card Table）的技术。该技术将整个堆划分为一个个大小为 512 字节的卡，并且维护一个卡表，用来存储每张卡的一个标识位。这个标识位代表对应的卡是否可能存有指向新生代对象的引用。如果可能存在，那么我们就认为这张卡是脏的。

​	在进行 Minor GC 的时候，我们便可以不用扫描整个老年代，而是在卡表中寻找脏卡，并将脏卡中的对象加入到 Minor GC 的 GC Roots 里。当完成所有脏卡的扫描之后，Java 虚拟机便会将所有脏卡的标识位清零。由于 Minor GC 伴随着存活对象的复制，而复制需要更新指向该对象的引用。因此，在更新引用的同时，我们又会设置引用所在的卡的标识位。这个时候，我们可以确保脏卡中必定包含指向新生代对象的引用。在 Minor GC 之前，我们并不能确保脏卡中包含指向新生代对象的引用。其原因和如何设置卡的标识位有关。首先，如果想要保证每个可能有指向新生代对象引用的卡都被标记为脏卡，那么 Java 虚拟机需要截获每个引用型实例变量的写操作，并作出对应的写标识位操作。这个操作在解释执行器中比较容易实现。但是在即时编译器生成的机器码中，则需要插入额外的逻辑。这也就是所谓的写屏障（write barrier，注意不要和 volatile 字段的写屏障混淆）。写屏障需要尽可能地保持简洁。这是因为我们并不希望在每条引用型实例变量的写指令后跟着一大串注入的指令。因此，写屏障并不会判断更新后的引用是否指向新生代中的对象，而是宁可错杀，不可放过，一律当成可能指向新生代对象的引用。

​	虽然写屏障不可避免地带来一些开销，但是它能够加大 Minor GC 的吞吐率（ 应用运行时间 /(应用运行时间 + 垃圾回收时间) ）。总的来说还是值得的。不过，在高并发环境下，写屏障又带来了虚共享（false sharing）问题。

​	在介绍对象内存布局中我曾提到虚共享问题，讲的是几个 volatile 字段出现在同一缓存行里造成的虚共享。这里的虚共享则是卡表中不同卡的标识位之间的虚共享问题。在 HotSpot 中，卡表是通过 byte 数组来实现的。对于一个 64 字节的缓存行来说，如果用它来加载部分卡表，那么它将对应 64 张卡，也就是 32KB 的内存。如果同时有两个 Java 线程，在这 32KB 内存中进行引用更新操作，那么也将造成存储卡表的同一部分的缓存行的写回、无效化或者同步操作，因而间接影响程序性能。为此，HotSpot 引入了一个新的参数 -XX:+UseCondCardMark，来尽量减少写卡表的操作。

### 垃圾回收器

## JAVA内存模型

​	由于计算机处理器和存储设备的运算速度有几个数量级的差距，所以现代计算机系统不得不加入一层高速缓存来作为内存和处理器之间的缓存。基于高速缓存的存储交互很好的解决了处理器和内存速度的矛盾，但引入了缓存一致性(Cache Coherence)问题，即多个高速缓存将同一个数据写入到主内存中，以哪个为准。为了解决一致性问题，又引入了一些协议，如MESI等。

​	JVM的即时编译器为了提高执行速度，可能会对执行进行重排序，以此来提高执行速度。但是无法对有数据以来的指令进行重排序，而且要遵守“线程内表现为串行的语义”(Within-Thread As-If-Serial Semantics)，即代码在单线程中重排序的执行结果和未重排序的执行结果一致。但因为执行重排序以及工作内存(高速缓存)与主内存同步延迟的情况导致会出现并发安全(执行结果不唯一(每次执行可能有不同的结果)，且与预期不符合)问题。

​	Java内存模型(Java Memory Model,JMM)来屏蔽各种硬件的和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。可以解决相同的代码在不同的平台并发行为不一致的情况。

​	JMM主要的目的时定义程序中各种变量(实例字段，静态字段和构成数组对象的元素，不包括线程私有的变量(如局部变量，方法参数))的访问规则，即关注在虚拟机中把变量值存储到内存中和从内存中取出变量值这样的底层细节。JMM规定所有的变量都存储在主内存中，每个线程还有自己的工作内存(保存主内存变量的副本，不是全部复制，只复制需要的字段)。线程对变量的操作要在工作内存中进行，不能直接操作主内存。不同线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。

### 内存间交互操作

​	关于主内存和工作内存之间具体的交互协议，即如何把一个变量从主内存复制到工作内存，如何把工作内存的变量同步回主内存。JMM定义了8个原子性操作来完成。

#### 原子性操作

+ lock：作用于主内存变量，将一个变量标记为线程独占。
+ unlock：作用于主内存变量，将处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。
+ read：作用于主内存变量，将变量的值从主内存拷贝到工作内存，以便随后的load操作使用。
+ load：作用于工作内存变量，将read操作拷贝的变量的值放到工作内存的变量副本中。
+ use：作用于工作内存变量，将工作内存的变量的值传递给执行引擎，每当JVM遇到一个需要使用变量的值的字节码指令时需要执行这个操作。
+ assign：作用于工作内存变量，将从执行引擎接收的值赋给工作内存中的变量，每当JVM遇到一个需要给变量赋值的字节码指令时需要执行这个操作。
+ store：作用于工作内存变量，将变量的值从工作内存拷贝到主内存，以便随后的write操作使用。
+ write：作用于主内存变量，将store操作拷贝的变量的值同步回主内存变量中。

read和load操作，还有store和write操作必须按顺序执行，但不要求连续执行。

#### 原子性操作规则

JMM还规定了8中基本操作时必须满足如下规则：

+ 不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者工作内存发起回写操作但主内存不接受的情况。
+ 不允许一个线程丢弃它最近的assign操作，即变量在工作内存中改变了必须把变化同步会主内存。
+ 不允许一个线程无原因地(没发生过任何assign操作)把变量从工作内存同步回主内存。
+ 一个新的变量只能在主内存中"产生"，不允许在工作内存中直接使用一个未被初始化(load或assign)的变量，换句话说就是对一个变量实施use、store操作之前，必须执行assign和load操作。
+ 一个变量在同一时刻只允许一个线程对其进行lock操作，但lock操作可以被同一个线程重复执行多次，多次执行lock操作后，必须执行相同次数的unlock操作才能解锁。
+ 如果对一个变量执行lock操作，将会清空工作内存中该变量的值，在执行引擎使用这个变量前，需要重新执行load或assign以初始化变量的值。
+ 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定的变量。
+ 对一个变量执行unlock操作之前，必须先把该变量同步会主内存中(执行store、write操作)。

为了准确地描述出Java程序那些内存访问操作在并发下是安全的。

#### volatile特殊规则

​	被volatile修饰的变量具有可见性和有序性(禁止指令重排序)，但不具有原子性。

​	可见性保证：因为volatile变量每次使用时都会进行read、load操作从主内存读取变量值，每次修改时都会进行store、write操作将变量的值同步回主内存中，因此volatile的值对所有线程是立刻可见的。

​	有序性保证（禁止指令重排序）：通过对比volatile变量和非volatile变量赋值的字节码可以发现，volatile变量赋值后会多执行一个"lock addl $0x0,(%esp)"操作，这个操作相当于一个内存屏障保证(Memory Barrier/Memory Fence，指令重排序时不能把后面的指令重排序到内存屏障之前的位置)。"lock addl $0x0,(%esp)"(把ESP寄存器的值加0)是一个空操作，不适用空操作专用指令nop是因为规定lock前缀不允许配合nop执行。lock前缀会将本处理器的缓存写入到内存中，相当于进行了store和write操作，可以让volatile变量的修改对其他处理器立刻可见。指令重排序无法对有依赖关系的数据进行排序，"lock addl $0x0,(%esp)"刷新缓存时，代表之前有数据依赖的操作都已生效，这样就筑起了“内存屏障”。

JMM对volatile变量定义的特殊规则

+ 要求use、load、read操作必须连续且一起出现。每次都能从主内存中获取最新的变量值。
+ 要求assign、store、write操作必须连续且一起出现。每次修改都能立刻同步会主内存。
+ 同一线程中，先对volatile变量A进行了use或assign操作，后对volatile变量B进行了use或assign操作，那么变量A的read或write操作先于变量B的read或write操作。规定volatile修饰的变量不会被指令重排序优化，从而保证代码的执行顺序和程序的顺序相同。

#### 针对long和double变量的特殊规则

​	JMM允许JVM对未被volatile修饰的64位数据读写分为两次32位的操作来进行。

#### 原子性、可见性和有序性

​	JMM围绕着在并发过程中如何处理原子性、可见性和有序性这三个特征建立的。下面罗列了哪些操作实现了这三个特性

​	原子性：JMM直接保证的原子性操作包括read、load、use、assign、store、write这六个。如果需要更大范围的原子性保证可以使用lock和unlock，JVM未暴露这两个操作，但提供了更高层次的字节码指令monitorenter和moniterexit来隐式地操作。这两个字节码指令对应着synchronized关键字。

​	可见性：volatile变量由每次读主内存的值，每次将修改写回主内存保证。synchronized由 对一个变量执行unlock操作之前，必须先把该变量同步会主内存中(执行store、write操作) 规则保证。final修饰的字段在构造器中一旦初始化完成，且构造器没将”this“的引用传递出去，其他线程就能看到final字段的值。

​	有序性：Java中，如果在本线程内观察，所有的操作都是有序的(线程内表现为串行的语义)；如果在一个线程内观察另一个线程，所有的操作都是无需的(指令重排序和工作内存和主内存同步延迟)。volatile变量通过内存屏障保证。synchronized由 一个变量在同一时刻只允许一个线程对其进行lock操作 规则保证。

#### 先行发生规则

​	先行发生时Java内存模型中定义的亮相操作之间的偏序关系，比如操作A先行发生于操作B，就是说操作B发生之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。通过先行发生规则，我们可以通过几个简单的规则一揽子解决并发环境下两个操作之间是否可能存在冲突的所有问题。

​	Java内存模型中有一些“天然的”先行发生关系，这些关系无须任何同步器协助便已存在，可以在编码中直接使用。

+ 程序次序规则（Program Order Rule）：在一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作。注意，这里说的是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。

+ 管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是“同一个锁”，而“后面”是指时间上的先后。

+ volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面对这个变量

  的读操作，这里的“后面”同样是指时间上的先后。

+ 线程启动规则（Thread Start Rule）：Thread对象的start()方法先行发生于此线程的每一个动作。

+ 线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread::join()方法是否结束、Thread::isAlive()的返回值等手段检测线程是否已经终止执行。

+ 线程中断规则（Thread Interruption Rule）：对线程interrupt()方法的调用先行发生于被中断线程

  的代码检测到中断事件的发生，可以通过Thread::interrupted()方法检测到是否有中断发生。

+ 对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的

  finalize()方法的开始。

+ 传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出

  操作A先行发生于操作C的结论。

Java语言无须任何同步手段保障就能成立的先行发生规则有且只有上面这些。

​	时间先后顺序与先行发生(逻辑上的发生)原则之间基本没有因果关系，所以我们衡量并发安全问题的时候不要受时间顺序的干扰，一切必须以先行发生原则为准。如根据程序次序规则，代码是按控制流顺序执行，但是因为即时编译器的重排序，导致代码的顺序改变，但是这并不影响先行发生规则的正确性，因为我们在这条线程之中没有办法感知到这一点。

## Java与线程

​	并发并不一定要依赖于多线程(多进程并发)，但是在Java中并发基本上都离不开多线程。在操作系统中，进程是资源分配的最小单位，线程是调度执行的最小单位。一个进程可以包含多个线程。

​	目前，线程是Java里面进行处理器资源调度的最小单位，如果日后Loom项目能为Java引入纤程(Fiber)的话，协程就能成为调度的最小单位。Java屏蔽了各平台线程操作的差异性，提供了Thread类，通过调用start()来开启一个线程。Thread类大部分方法都被native修饰，代表通过和平台相关的手段来实现线程。

### 线程的实现

​	实现线程的主要方式有三种：使用内核线程实现(1:1)，使用用户线程实现(1:N)，使用用户线程加轻量级进程混合实现(M:N)。

	#### 内核线程实现

​	内核线程(Kernel-Level Thraed，KLT)就是有操作系统内核(Kernel)支持的线程，这种线程由内核来完成线程切换，内核通过操作调度器(Scheduler)对线程进行调度，并负责将线程的任务人设到各个处理器上(CPU)。

​	程序一般不会直接使用内核线程，而是使用内核线程的一个高级接口-轻量级进程(Light Weight Process, LWP)，轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才有轻量级进程。

```
        P							 P
LWP    LWP     LWP              LWP     LWP
 |      |       |                |       |
KLT    KLT     KLT              KLT     KLT

                 |       |      |
                 Thread Scheduler
                  |	    |      |
                 CPU   CPU     CPU
```

​	由于内核线程的支持，每个轻量级进程成为一个独立的调度单元，即使其中一个被系统阻塞，也不影响整个进程继续执行。轻量级进程由自己的局限性：

+ 由于基于内核线程实现，所以线程的各种操作(创建、析构和同步)都要进行系统调用。而系统调用需要在用户态和内核态切换，代价较高(主要开销来自于响应中断、保护和恢复执行现场的成本)。
+ 由于每个轻量级进程都需要一个内核线程支持，因此轻量级进程需要消耗一定的内核资源(内核线程的栈空间)，因此一个系统支持的轻量级进程数量有限。

#### 用户线程

​	广义上讲，一个线程只要不是内核线程，都可以认为是用户线程(User Thread, UT)的一种。从这中定义上看，轻量级进程属于用户线程，但是由于基于内核线程，许多操作要进行系统调用，因此效率受限，不具备通常意义上用户线程的优点。

​	狭义上讲，用户线程是指完全建立在用户空间的线程库上，系统内核感知不到用户线程的存在及实现。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要切换到内核态，因此操作可以是非常快且低消耗，也能够支持更大规模的线程数量。

```
UT   UT   UT                   UT    UT
     P                             P
                  CPU
```

​	用户线程的优势在于不需要内核线程的支持，劣势也是由于缺少内核线程的支持，所有的线程操作都需要用户线程去处理。线程的创建、销毁、切换和调度都是用户必须考虑的问题，而且由于操作系统只把处理器资源分配到进程，那诸如“阻塞如何处理”，“多处理器系统中如何将线程映射到其他处理器上”这类问题解决是异常困难的，甚至无法解决。

#### 混合实现

​	即轻量级进程和用户线程并存。用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并且可以支持大规模的用户线程并发。而操作系统支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核线程的线程调度及处理器映射，并且用户线程的系统调用通过轻量级进程来完成，大大降低了整个进程被阻塞的风险。

```
UT      UT      UT
    LWP    LWP
    
    KLT    KLT
   Thread Scheduler
CPU   CPU      CPU   
```

#### Java线程的实现

​	Java线程如何实现不受Java虚拟机规范的约束。Java线程在早期的Classic虚拟机上，是基于一种被称为"绿色线程"的用户线程实现，后来主流的JVM线程模型慢慢都被替换成基于内核线程的实现。

### Java线程调度

​	线程调度是指系统为线程分配处理器使用权的过程。

	#### 协同式线程调度

​	线程的执行时间由线程本身来控制，线程把自己的工作执行完之后，要主动通知系统切换到另一个线程上区。协调式多线程的最大好处是实现简单，而且由于线程要把自己的事情都干完后才会进行线程切换，切换线程操作对于线程是可知的，所有一般不会有线程同步的问题。

​	缺点为线程执行时间不可控，甚至如果线程的代码编写有问题，一直不告知系统进行线程切换，那么程序会一直阻塞在那里。

#### 抢占式线程调度

​	线程的执行时间由系统来分配，线程的切换不由线程本身决定。线程可以出让执行时间，但不能主动获取执行时间。在这种方式下，线程的执行时间是系统可控的，也不会有一个线程导致整个进程或者整个系统阻塞的问题。Java就是采用抢占式线程的调度。

### Java线程状态

​	Java语言定义了6中线程状态，任一时间点中，一个线程有且只有一种状态。

	+	新建(New)：创建后尚未启动(Thread#start方法)的线程。
	+	运行(Runable)：调用Thread#start方法后，线程会处于运行态。该状态对应操作系统线程状态中的Running和Ready，该状态的线程可能处于执行中，也可能正在等待分配执行时间。
	+	无期限等待(Wating)：处于这种状态的线程不会被分配处理器执行时间，他们需要等待被其他线程显式唤醒(Object#notify/Object#notifyAll)。调用Object#wait/Thread#join/LockSupport#park方法会进入此状态。
	+	有期限等待(Timed Waitting)：处于这种状态的线程不会被分配处理器执行时间，不过无需等待被其他线程显式唤醒，在一定时间后会由系统自动唤醒。调用Object#wait(Timeout)/Thread#join调用Object#wait/Thread#join/LockSupport#park方法会进入此状态。/LockSupport#parkNanos/LockSupport#parkUntil方法会进入此状态。
	+	阻塞(Blocked)：线程被阻塞了，与等待状态的区别是阻塞状态在等待获取一个排它锁。
	+	结束(Terminated)：已终止线程的线程状态，线程已经结束执行。

```
状态转换图
New  					|---synchronized--->      Blocked
|						|
|----start()-->      Runable     ---sleep()--->   Timed Waitting
						|				 
						|				 
Wating		 <--wait()--|	     ---run()结束--->  Terminated
```

### 协程

​	当今对Web应用的服务要求不论是请求数量上还是复杂度上，对比十年前已经不可同日口语。一方面源于业务量的增长，另一方面源于为了应对业务复杂化而不断进行的服务细分。现代B/S系统对一次外部业务请求的相应，往往需要分布在不同机器上的大量服务共同协助来实现，这种服务细分的架构在减少单个服务复杂性、增加复用性的同时，也不可避免地增加了服务的数量，缩短了留给每个服务的响应时间。这要求每一个服务都必须在极短的时间内完成计算，也要求服务提供者能同时处理数量更庞大的请求，这样才不会出现请求由于某个服务被阻塞而出现等待。

​	这种情形下，当前的线程模型不足以支撑(64位Linux HotSpot给线程栈默认容量为1M，内存不足以支撑更大规模的线程，并且当线程多时，线程切换也会浪费很多资源)。因此需要更轻量级的线程，也就是协程。协程类比用户线程，更小，而且不用用户态和内核态切换，省资源，缺点为要自己写调度等操作。

​	Java将来可能会引入Loom项目的纤程(Fiber)。

## 线程安全与锁优化

​	高效并发要求在保证并发正确性的基础上，来实现高效。线程安全可以借鉴《Java并发编程实战》中的比较恰当的定义：“当多个线程同时访问同一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要额外的同步、或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获取正确的结果，那就称这个而对象是线程安全的”。可以简单理解为，多个线程对共享数据协调工作时，无需考虑线程的调度情况，得到的结果唯一且符合预期。

### Java语言中的线程安全

#### 不可变

​	在Java语言中，不可变(Immutable)对象一定是线程安全的。final关键字。

#### 绝对线程安全

​	满足上述线程安全的定义，即“不管运行时环境如何，调用者都不需要任何额外的同步措施”。

#### 相对线程安全

​	Java API中标注自己是线程安全的类，大多数是处于该级别。该级别保证对这个对象单次的操作是线程安全的，调用时无需进行额外的保障措施，但是对于一些特定顺序的调用，需要调用者使用额外的同步手段来保证。

#### 线程兼容

​	指对象本身并不是线程安全的，但是通过调用者正确地使用同步手段可以保证对象在并发环境中可以安全使用。

#### 线程对立

​	不管调用者是否采取同步措施，都无法保证线程安全。

### 线程安全的实现方法

#### 互斥同步

​	互斥同步(Mutual Exclusion & Synchorization)是一种最常见也是最主要的并发正确性保障手段。同步是指在多个线程并发访问共享数据时，保证共享数据在同一时刻只被一条(或者一些，使用信号量时)线程使用。而互斥时实现同步的一种手段，临界区(Critical Section)、互斥量(Mutex)、信号量(Semaphore)都是常见的互斥实现方式。因此互斥同步中，互斥是因，同步是果；互斥是方法，同步是目的。

​	Java提供了synchorized关键字来提供互斥同步，synchorized关键字在经过javac编译后，会在同步块前后生成monitorenter和monitorexit两个字节码指令。

​	JDK5引入了JUC，提供了Lock接口的实现ReentrantLock，相比于synchorized关键字，ReentrantLock有三种高级功能:

	+	等待可中断：当持有锁的下次你哼长期不释放锁时，正在等待的线程可以选择放弃等待，改为处理其他事情。可中断特性对于处理器执行时间非常长的同步块很有帮助。
	+	公平锁：当多个线程在等待同一个锁时，需要排队来依次获得锁。非公平锁是谁抢到算谁的，相比于公平锁，性能会好些。ReentrantLock支持公平锁，synchorized关键字只支持非公平锁。
	+	锁绑定多个条件：一个ReentrantLock对象可以绑定多个Condition对象。synchorized关键字中，锁对象的wait()和notify()/notifyAll()方法配合可以实现且只能实现一个隐含的条件。

​	synchorized关键字在JDK6添加了大量锁优化的手段，性能方面不会相差ReentrantLock很多，并且synchorized关键字的加锁解锁由JVM来管理，无需程序员介入，而且JVM针对synchorized关键字更方便做优化。因此如果不是为了上面三种高级功能，尽量使用synchorized关键字。

#### 非阻塞同步

​	互斥同步最主要的问题就是进行线程阻塞和唤醒所需要的性能开销，因此互斥同步也被称为阻塞同步。互斥同步属于一种悲观的并发策略，认为每次操作数据时都会有竞争，因此会先加锁后操作。

​	随着硬件指令集的发展(CAS处理器指令的出现)，我们可以使用基于冲突检测的乐观并发策略，认为每次操作都没有竞争，因此先操作后判断是否冲突，无冲突操作就成功了，有冲突在进行其他补偿措施。

​	JDK5之后，Java类库才开始使用CAS操作，由Unsafe提供，但是用户程序无法调用，想使用只能通过反射。JDK9之后提供给了用户程序。

#### 无同步方案

​	同步只是保障存在共享数据争用时正确性的手段，如果不存在共享数据，那它就不需要任何同步措施去保证其正确性。

​	Java提供了ThreadLocal，允许将数据保存在线程中，因此线程的数据是不共享的，因此线程安全。

### 锁优化

#### 自旋锁与自适应锁

​	经观察，在很多应用中，共享数据的锁定状态指挥持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得。因此当一个线程请求锁时，可以让其“等待一会”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。

​	自旋锁在JDK1.4.2中引入，默认关闭，需要通过-XX:+UseSpinning参数开启，在JDK6中默认开启。自选等待不能代替阻塞，线程本身一直在浪费处理器的执行时间，因此不能无限制自选等待。自旋次数默认时是十次，可以通过参数-XX:PreBlockSpin来更改。

​	但是每个锁的情况都不一样，设定的固定值并不一定最优。因此在JDK6中对自旋锁进行了优化，引入了自适应的自旋。即如果上次等待获取该锁成功了，就认为这次可能还会成功，就多等会。如果上次等待锁获取该锁失败了，这次等待时间就短点，甚至是以后不等待，直接阻塞。

#### 锁消除

​	指虚拟机即时编译器在运行时检测到某段需要同步的代码根本不可能存在共享数据竞争而实施的一种对所进行消除的优化策略。

​	如单线程中使用StringBuffer进行字符串拼接。

#### 锁粗化

​	原则上，编写代码时将同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步，这样是为了将需要同步的操作数量变小，即时存在锁竞争，也能快速的释放锁。

​	但是对于一系列的连续操作都对一个对象反复进行加锁和解锁，那即时没有线程竞争，频繁地进行互斥操作也会导致不必要的性能损耗。此时虚拟机会将锁的范围扩大，避免重复对一个对象加锁解锁。

#### 轻量级锁

​	轻量级锁是JDK6引入的，它的设计初衷是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。

​	加锁：在代码块即将进入同步块的时候，如果此同步对象没有被锁定，虚拟机将会在当前线程的栈帧中建立一个锁记录(Lock Record)，用于存储锁对象目前的Mark Word的拷贝，然后虚拟机使用CAS将锁对象的Mark Word更新为指向Lock Record的指针。如果更新成功，代表该线程拥有该锁(锁对象标示变为00)，如果更新失败检查锁对象的Mark Word的指针是否指向当前线程的栈帧，如果是，代表拥有该锁，继续执行。否则轻量级锁膨胀为重量级锁(锁对象标示变为10)，此时锁对象Mark Word中存储的是指向重量级锁的指针，后面的等待线程必须进入阻塞状态。

​	解锁：解锁也通过CAS实现，如果锁对象的Mark Word仍指向线程的锁记录，则会通过CAS将Mark Word和锁记录进行交换，交换成功则代表整个同步过程顺利完成。如果交换失败，则说明有其他线程来尝试获取过锁(锁会膨胀为重量级锁)，此时解锁需要唤醒被阻塞的线程。

#### 偏向锁

​	偏向锁也是JDK6引入的锁优化措施，它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的性能。如果说轻量级锁实在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS操作都不用做。

​	当锁对象第一次被线程获取时，虚拟机会使用CAS将获取该锁的线程ID记录到锁对象的Mark Word，后续持有该锁的线程进入同步块时不需要任何同步操作。

​	当其他线程去获取这个锁时，偏向模式马上结束。如果该锁现在被锁定，则升级为轻量级锁。否则则恢复到未锁定状态。

 	当对象进入偏向状态时，Mark Word大部分空间(23bit)用来存储ThreadId，这部分空间原来存储的对象哈希值如何处理？

​	正常状态对象一开始时没有hashCode的，第一次调用才生成。当对象计算过哈希值后，就不能进入偏向状态。在偏向状态的对象计算哈希值时，会立即膨胀为重量级锁，Mark Word存重量级锁的指针，代表重量级锁的ObjectMonitor类有字段存哈希值。轻量级锁的锁记录中存锁对象的Mark Word，也有哈希值。
