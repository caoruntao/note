

# JAVA

## Java代码如何执行

### 执行方式

高级编程语言执行一般分为 编译 和 翻译两种执行方式。

#### 编译执行

​		将 源代码 转换成 机器语言，通常是 二进制形式(机器码) 并保存下来(复用)，等待执行。目的是生成 可执行的程序。
​		优点:
​			因为提前编译生成 机器码，所以直接执行 编译后的文件即可，因此速度较快。
​		缺点:
​			源代码编译后只能在该类机器上运行，无法跨平台。

#### 解释执行

​		在程序运行时，将源代码转换为 机器语言(机器码)，并立即执行。
​		工作模式:
​			1.分析源代码，并且直接执行。
​			2.把源代码翻译成相对更加高效率的中间码，然后立即执行它。
​			3.执行由解释器内部的编译器预编译后保存的代码。
​		优点:
​			跨平台性，因为无需编译，因此只要解释器支持多平台，就有跨平台性。
​		缺点:
​			运行速度慢，解释器要额外的开销。

### Java执行方式

源代码(.java) - javac -> 字节码(.class) - jvm -> 机器码。先通过javac编译为字节码(Java字节码指令被固定为一个字节)，执行时JVM将字节码解释为机器码(不同平台有对应的JVM，因此可以跨平台)。虚拟机另一个好处是带来一个托管环境(Managed Runtime)，可以帮我们处理一些代码冗余而且容易出错的部分，如内存管理和垃圾回收等。

运行时属于解释执行，为了提高运行效率(程序符合二八原则，20%的代码占用80%的资源)，JVM也提供了编译执行的方式。因此JVM属于混合执行，可通过JVM参数控制。

#### 编译执行机制		

###### JIT(Just In Time)

即时编译。运行时，以方法为单位，将频繁执行的热点代码编译为机器码保存起来(Code Cache，非堆区)，编译完成后(编译时还是以解释的方式执行，编译和解释执行可以并行)，后续调用则直接调用编译完成后的机器码，提高运行效率。

编译器:

​	C1:

​		client模式，将由1500次的收集计算出，启动性能好。

​	C2:

​		server模式，将根据10000次的收集计算出，峰值性能好。

​	Graal:

从Java7开始，HotSpot(JVM)默认采用分层编译的方式:热点方法先被C1编译，然后热点方法中的热点会被进一步被C2编译。为了不干扰应用的正常运行，即时编译是放在额外的编译线程中执行的。HotSpot会根据CPU的数据量设置编译线程的数据，并且按1:2的比例配置C1和C2的编译器。

理论上讲，即时编译后的Java程序的执行效率是可能超过C++的。这是因为和静态编译相比，即时编译拥有程序运行时信息，并且根据这个信息做出优化。

###### AOT(Ahead-of-Time Compilation)

运行之前，将应用中或JDK中的字节码编译成机器码(与即时编译器区别)



## 数据类型

Java语言中类型分为两大类，基本数据类型和引用类型。基本数据类型有八个，分别为boolean、byte、char、short、int、long、float、double。引用类型分为四种，分别为类、接口、数组、泛型，因为泛型是通过类型擦除(考虑到向后兼容)实现的，所有可以认为只存在前三种。

Java引入基本数据类型来支持数值计算，因为使用基本数据类型能够提高程序执行效率和减少内存占用。所有的计算操作都会被转换成整数运算。

| 类型    | 值域                 | 默认值   | 虚拟机内部符号 |
| ------- | -------------------- | -------- | -------------- |
| boolean | {false, true}        | false    | Z              |
| byte    | [-128, 128]          | 0        | B              |
| char    | [0, 65535]           | '\u0000' | C              |
| short   | [-32768, 32767]      | 0        | S              |
| int     | [-2^31, 2^31 - 1]    | 0        | I              |
| long    | [-2^63, 2^63 - 1]    | 0L       | J              |
| float   | ~[-3.4E38, 3.4E38]   | +0.0F    | F              |
| double  | ~[-1.8E308, 1.8E308] | +0.0D    | D              |

boolean在Java语言规范中使用true或false来表示，在JVM规范中，boolean会映射为int类型，true映射为1，false映射为0，编码规范约束了Java字节码的具体实现。

if(boolean) 会判断boolean是否为0，0就跳过。if(boolean == true)会判断boolean是否为1，不为1就跳过。



Java虚拟机每调用一个Java方法便会创建一个栈帧。在解释器的解释栈帧中，主要包括两个主要组成部分，分别是局部变量区()和字节码的操作数栈。这里的局部变量是广义的，除了普遍意义下的局部变量之外，它还包含实例方法的“this 指针”以及方法所接收的参数。

在 Java 虚拟机规范中，局部变量区等价于一个数组，并且可以用正整数来索引。除了 long、double 值需要用两个数组单元来存储之外，其他基本类型以及引用类型的值均占用一个数组单元。当然，这种情况仅存在于局部变量，而并不会出现在存储于堆中的字段或者数组元素上。

如将int类型的值存储到boolean类型时，为了保证堆中的 boolean 值是合法的，HotSpot 在存储时显式地进行掩码操作，也就是说，只取最后一位的值存入 boolean 字段或数组中。Java 虚拟机的算数运算几乎全部依赖于操作数栈。也就是说，我们需要将堆中的 boolean、byte、char 以及 short 加载到操作数栈上，而后将栈上的值当成 int 类型来运算。对于无符号类型，加载伴随着零扩展(高位补0)。对于有符号类型，加载伴随着符号扩展(类型值填充低字节，正数最高位补0，负数补1，其余全部补0)。

## Java类如何加载

### 类加载器

JDK8及之前

启动类加载器：加载最为基础、最为重要的类，如存放在JRE的lib目录下的jar包中的类(以及由虚拟机参数-Xbootclasspath指定的类)。由C++编写，在java代码中表现为null。

扩展类加载器：加载相对次要、但又通用的类，比如存放在JRE的lib\ext目录下jar包中的类(以及由系统变量java.ext.dirs指定的类)。

应用类加载器：负责加载应用程序路径下的类(指由虚拟机参数-cp/-classpath、系统环境变量java.class.path指定的路径)。默认情况下，应用程序中包含的类便是由应用类加载器加载的。

JDK9及现在(引入模块化)

启动类加载器：加载少数几个关键模块，如java.base。

平台类加载器：其他模块。

程序类加载器

### 双亲委派机制

每当一个类加载器接收到加载请求时，它会先将请求转发给父类加载器。在父类加载器没有找到所请求的类的情况下，该类加载器才会尝试去加载。

提供了隔离机制，在 Java 虚拟机中，类的唯一性是由类加载器实例以及类的全名一同确定的。即便是同一串字节流，经由不同的类加载器加载，也会得到两个不同的类。提供了安全机制，最核心的类(如String)由启动类加载器加载，不可被相同类名的文件破坏。

### 类加载过程

#### 加载：

​	根据类的全限定名将该类的字节码加载到内存，生成代表该类的Class对象

#### 链接：

​	将创建好的Class对象合并到JVM，使之能够执行的过程。

##### 验证：

​	确保被加载类能够满足 Java 虚拟机的约束条件。

##### 准备：

​	为被加载类的静态字段分配内存，并设置默认值。被final修饰的static字段不会设置，因为在编译时就分配了。

##### 解析：

​	将类成员的符号引用变成直接引用。如果符号引用指向一个未被加载的类，或者未被加载类的字段或方法，那么解析将触发这个类的加载（但未必触发这个类的链接以及初始化。）

#### 初始化：

​	执行类的构造器方法init()的过程。这个方法不需要定义，是javac编译器自动收集类中所有类变量的赋值动作和静态代码块中的语句合并来的。



类加载时不一定会触发初始化，只用主动使用类时，才会触发，如

1. 当虚拟机启动时，初始化用户指定的主类；
2. 当遇到用以新建目标类实例的 new 指令时，初始化 new 指令的目标类；
3. 当遇到调用静态方法的指令时，初始化该静态方法所在的类；
4. 当遇到访问静态字段的指令时，初始化该静态字段所在的类；
5. 子类的初始化会触发父类的初始化；
6. 如果一个接口定义了 default 方法，那么直接实现或者间接实现该接口的类的初始化，会触发该接口的初始化；
7. 使用反射 API 对某个类进行反射调用时，初始化这个类；
8. 当初次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的方法所在的类。

## Java如何执行方法调用

### Java方法调用

#### 重载

在 Java 程序里，如果同一个类中出现多个名字相同，但参数类型不同的方法，我们称之为重载。

重载的方法在编译过程中即可完成识别。具体到每一个方法调用，Java 编译器会根据所传入参数的声明类型（注意与实际类型区分）来选取重载方法。选取的过程共分为三个阶段：

1. 在不考虑对基本类型自动装拆箱（auto-boxing，auto-unboxing），以及可变长参数的情况下选取重载方法；
2. 如果在第 1 个阶段中没有找到适配的方法，那么在允许自动装拆箱，但不允许可变长参数的情况下选取重载方法；
3. 如果在第 2 个阶段中没有找到适配的方法，那么在允许自动装拆箱以及可变长参数的情况下选取重载方法。

如果 Java 编译器在同一个阶段中找到了多个适配的方法，那么它会在其中选择一个最为贴切的，而决定贴切程度的一个关键就是形式参数类型的继承关系。

除了同一个类中的方法，重载也可以作用于这个类所继承而来的方法。也就是说，如果子类定义了与父类中非私有方法同名的方法，而且这两个方法的参数类型不同，那么在子类中，这两个方法同样构成了重载。

#### 重写

如果子类具有一个和父类非私有方法的方法名，方法参数，方法返回值(可以不一致，但是必须是返回值的子类)一致的方法，如果是非静态的方法可以认为子类重写了父类方法，如果是静态方法，可以认为子类中的方法会隐藏掉父类的方法。

众所周知，Java 是一门面向对象的编程语言，它的一个重要特性便是多态。而方法重写，正是多态最重要的一种体现方式：它允许子类在继承父类部分功能的同时，拥有自己独特的行为。

### JVM方法调用

Java 虚拟机识别方法的关键在于类名、方法名以及方法描述符（method descriptor）。方法描述符是由方法的参数类型以及返回类型所构成。在同一个类中，如果同时出现多个名字相同且描述符也相同的方法，那么 Java 虚拟机会在类的验证阶段报错。

#### JVM 的静态绑定和动态绑定

Java 虚拟机与 Java 语言不同，它并不限制名字与参数类型相同，但返回类型不同的方法出现在同一个类中，对于调用这些方法的字节码来说，由于字节码所附带的方法描述符包含了返回类型，因此 Java 虚拟机能够准确地识别目标方法。

Java 虚拟机中关于方法重写的判定同样基于方法描述符。也就是说，如果子类定义了与父类中非私有、非静态方法同名的方法，那么只有当这两个方法的参数类型以及返回类型一致，Java 虚拟机才会判定为重写。

对于 Java 语言中重写而 Java 虚拟机中非重写的情况，编译器会通过生成桥接方法来实现 Java 中的重写语义。

在某些文章中，重载也被称为静态绑定（static binding），或者编译时多态（compile-time polymorphism）；而重写则被称为动态绑定（dynamic binding）。Java 虚拟机中的静态绑定指的是在解析时便能够直接识别目标方法的情况，而动态绑定则指的是需要在运行过程中根据调用者的动态类型来识别目标方法的情况。

Java 字节码中与调用相关的指令共有五种：

1. invokestatic：用于调用静态方法。
2. invokespecial：用于调用私有实例方法、构造器，以及使用 super 关键字调用父类的实例方法或构造器，和所实现接口的默认方法。
3. invokevirtual：用于调用非私有实例方法。
4. invokeinterface：用于调用接口方法。
5. invokedynamic：用于调用动态方法。

#### 调用指令的符号引用

​	在编译过程中，我们并不知道目标方法的具体内存地址。因此，Java 编译器会暂时用符号引用来表示该目标方法。这一符号引用包括目标方法所在的类或接口的名字，以及目标方法的方法名和方法描述符。

​	符号引用存储在 class 文件的常量池之中。根据目标方法是否为接口方法，这些引用可分为接口符号引用和非接口符号引用。在执行使用了符号引用的字节码前，Java 虚拟机需要解析这些符号引用，并替换为实际引用。

​	对于非接口符号引用，假定该符号引用所指向的类为 C，则 Java 虚拟机会按照如下步骤进行查找。

1. 在 C 中查找符合名字及描述符的方法。
2. 如果没有找到，在 C 的父类中继续搜索，直至 Object 类。
3. 如果没有找到，在 C 所直接实现或间接实现的接口中搜索，这一步搜索得到的目标方法必须是非私有、非静态的。并且，如果目标方法在间接实现的接口中，则需满足 C 与该接口之间没有其他符合条件的目标方法。如果有多个符合条件的目标方法，则任意返回其中一个。

​	从这个解析算法可以看出，静态方法也可以通过子类来调用。此外，子类的静态方法会隐藏（注意与重写区分）父类中的同名、同描述符的静态方法。

​	对于接口符号引用，假定该符号引用所指向的接口为 I，则 Java 虚拟机会按照如下步骤进行查找。

1. 在 I 中查找符合名字及描述符的方法。
2. 如果没有找到，在 Object 类中的公有实例方法中搜索。
3. 如果没有找到，则在 I 的超接口中搜索。这一步的搜索结果的要求与非接口符号引用步骤 3 的要求一致。

​	**经过上述的解析步骤之后，符号引用会被解析成实际引用。对于可以静态绑定的方法调用而言，实际引用是一个指向方法的指针。对于需要动态绑定的方法调用而言，实际引用则是一个方法表的索引。**

#### 虚方法调用

​	Java方法调用中的invokevirtual和invokeinterface指令属于Java虚拟机的虚方法调用。在绝大数情况下(除非方法被声明为final)，Java虚拟机需要根据调用者的动态类型来确定虚方法调用的目标方法，此过程称为动态绑定。相对于静态绑定的方法调用来说，动态绑定的方法调用更耗时。

​	Java方法调用中的invokestatic和invokespecial指令属于静态绑定。如果虚方法调用指向一个标记为 final 的方法，那么 Java 虚拟机也可以静态绑定该虚方法调用的目标方法。

#### 方法表

​	Java虚拟机采用了一种空间换时间的策略来实现动态绑定。它为每个类生成一张方法表(类加载阶段中的准备阶阶段创建)，来快速定位目标方法。	

​	方法表本质上是一个数组，里面存放当前类和祖先类中非私有的实例方法，这些方法可能是已经实现的方法，也可能是抽象方法。方法表满足两个特性，一是子类方法表中包含父类方法表中的所有方法，二是子类方法在方法表中的索引值，与它所重写的父类方法的索引值相同。

​	我们知道，方法调用指令中的符号引用会在执行之前解析成实际引用。对于静态绑定的方法调用而言，实际引用将指向具体的目标方法。对于动态绑定的方法调用而言，实际引用则是方法表的索引值（实际上并不仅是索引值）。

​	实际上，使用了方法表的动态绑定与静态绑定相比，仅仅多出几个内存解引用操作：访问栈上的调用者，读取调用者的动态类型，读取该类型的方法表，读取方法表中某个索引值所对应的目标方法。相对于创建并初始化 Java 栈帧来说，这几个内存解引用操作的开销简直可以忽略不计。

​	方法表的动态绑定存在于解释执行中和即时编译的超多态情况。

#### 内联缓存

​	内联缓存是一种加快动态绑定的优化技术。它能够缓存调用者的动态类型，以及该类型所对应的目标方法，以后执行时，如果碰到已缓存的类型，内联缓存便会直接调用该类型所对应的目标方法。如果没有碰到缓存类型，则会退化为方法表的动态绑定。

​	在针对多态的优化手段中，我们通常会提及以下三个术语。

 	1. 单态（monomorphic）指的是仅有一种状态的情况。
 	2. 多态（polymorphic）指的是有限数量种状态的情况。二态（bimorphic）是多态的其中一种。
 	3. 超多态（megamorphic）指的是更多种状态的情况。通常我们用一个具体数值来区分多态和超多态。在这个数值之下，我们称之为多态。否则，我们称之为超多态。

​	单态内联缓存，顾名思义，便是只缓存了一种动态类型以及它所对应的目标方法。它的实现非常简单：比较所缓存的动态类型，如果命中，则直接调用对应的目标方法。

​	多态内联缓存则缓存了多个动态类型及其目标方法。它需要逐个将所缓存的动态类型与当前动态类型进行比较，如果命中，则调用对应的目标方法。

​	超多态内联缓存则放弃了优化的机会，它将直接访问方法表，来动态绑定目标方法。

为了节省内存空间，Java 虚拟机只采用单态内联缓存。当内联缓存没有命中时，Java虚拟机则劣化为超多态状态，将直接访问方法表，来动态绑定目标方法。

​	虽然内联缓存附带内联二字，但是它并没有内联目标方法。这里需要明确的是，任何方法调用除非被内联，否则都会有固定开销。这些开销来源于保存程序在该方法中的执行位置，以及新建、压入和弹出新方法所使用的栈帧。对于极其简单的方法而言，比如说 getter/setter，这部分固定开销占据的 CPU 时间甚至超过了方法本身。此外，在即时编译中，方法内联不仅仅能够消除方法调用的固定开销，而且还增加了进一步优化的可能性。



## Java如何处理异常

异常处理的两大组成元素是抛出异常和捕获异常。这两大要素共同实现程序控制流的非正常转移。

### 抛出异常

​	抛出异常可分为显式和隐式。显式抛出是指应用程序使用 throw 关键字手动将异常实例抛出。隐式抛出是指Java虚拟机在执行过程中，碰到无法继续执行的异常状态时自动抛出。

### 捕获异常

​	捕获异常则涉及了如下三种代码块：

	1. try 代码块：用来标记需要进行异常监控的代码。
	1. catch 代码块：跟在 try 代码块之后，用来捕获在 try 代码块中触发的某种指定类型的异常。除了声明所捕获异常的类型之外，catch 代码块还定义了针对该异常类型的异常处理器。在 Java 中，try 代码块后面可以跟着多个 catch 代码块，来捕获不同类型的异常。Java 虚拟机会从上至下匹配异常处理器。因此，前面的 catch 代码块所捕获的异常类型不能覆盖后边的，否则编译器会报错。
	1. finally代码块：跟在try代码块和catch代码块后，用来声明一段必须执行的代码。设计的初衷是为了避免跳过某些关键的清理代码，如关闭一些打开的系统资源。

​	在程序正常执行后，会调用finally代码块。否则会在catch 代码块捕获并处理过异常后调用。如果catch没有捕获到异常，则直接执行finally代码块然后继续抛出该异常。如果catch 代码块也抛出异常，finally代码块运行后会继续抛出该异常。最糟糕的情况是finally代码块也遇到异常，此时中断执行，并往外抛出异常。

### 异常的基本概念

​	在Java规范中，所有异常都是Throwable类或者其子类的实例。Throwable由两大直接子类。第一个是Error，涵盖程序不该捕获的异常，当程序触发Error时，它的执行状态已经无法恢复，需要中止线程甚至中止虚拟机。第二个是Exception，涵盖可能需要捕获并且处理的异常。Exception有一个特殊的子类RuntimeException，用来表示程序虽然无法继续执行，但是还能抢救一下。

​	Error和RuntimeException属于非检查异常(unchecked exception)，其他异常属于检查异常(checked exception)。检查异常需要在程序中显式的捕获，或者在方法中标记throws关键字，抛到调用者去处理。

​	异常实例的构造十分昂贵。由于构造异常实例时，Java虚拟机需要生成该异常的栈轨迹(stack trace)。该操作会一一访问当前线程的Java栈帧，并记录下各种调式信息，包括栈帧指向的方法名、类名、以及触发的位置。

### Java虚拟机捕获异常

​	在编译生成的字节码中，每个方法都有一个异常表。表中的每条记录都代表一个异常处理器，记录中包括from指针、to指针、target指针和捕获的异常类型。这些指针的值时字节码索引，用以定位字节码。

​	其中form指针和to指针标示了该异常处理器监控的范围，如try代码块覆盖的范围。target指针指向异常处理器的起始位置，如catch代码块的起始位置。

​	当程序触发异常时，Java 虚拟机会从上至下遍历异常表中的所有条目。当触发异常的字节码的索引值在某个异常表条目的监控范围内，Java 虚拟机会判断所抛出的异常和该条目想要捕获的异常是否匹配。

​	finally 代码块的编译比较复杂。当前版本 Java 编译器的做法，是复制 finally 代码块的内容，分别放在 try-catch 代码块所有正常执行路径以及异常执行路径的出口中。



如果 catch 代码块捕获了异常，并且触发了另一个异常，那么 finally 捕获并且重抛的异常是哪个呢？答案是后者。也就是说原本的异常便会被忽略掉，这对于代码调试来说十分不利。

### Java7的Suppressed异常以及语法糖

​	Java7引入Suppressed异常来解决原本的异常被忽略掉的问题。这个特性允许将一个异常依附于另一个异常上，因此，抛出的异常可以附带多个异常信息。然而Java层面的finally代码块缺少指向所捕获的异常的引用(catch代码块可以声明异常，finally代码块不可以)，所以这个特性使用起来非常繁琐。

​	为此，Java7专门构建了一个try-with-resources 的语法糖，在字节码层面自动使用Suppressed异常。当然，该语法糖的主要目的并不是使用 Suppressed 异常，而是精简资源打开关闭的用法。

​	try-with-resources 语法糖允许在 try 关键字后声明并实例化实现了 AutoCloseable 接口的类，编译器将自动添加对应的 close() 操作。与手工代码调用close()操作相比，try-with-resources 还会使用 Suppressed 异常的功能，来避免原异常“被消失”。

​	除了 try-with-resources 语法糖之外，Java 7 还支持在同一 catch 代码块中捕获多种异常。实际实现非常简单，生成多个异常表条目即可。

## Java处理反射

### 反射 	

​	Reflection(反射) 是 Java 程序开发语言的特征之一，它允许运行中的 Java 程序对自身进行检查。通过反射，我们可以在运行时，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性。

#### 功能

Java 反射主要提供以下功能：

- 在运行时判断任意一个对象所属的类；
- 在运行时构造任意一个类的对象；
- 在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）；
- 在运行时调用任意一个对象的方法

#### 运用

​	Java反射的基本运用:

	+ 获得 Class 对象。有三种方式，Class.forName("类名") 、对象.getClass() 、int.class。
	+ 判断是否为某个类的实例。instanceof关键字或者Class.对象的isInstance()方法。
	+ 创建实例。使用Class对象的newInstance()方法来创建Class对象对应类的实例。或者先通过Class对象获取指定的Constructor对象，再调用Constructor对象的newInstance()方法来创建实例。
	+ 获取方法。`getDeclaredMethods` 方法返回类或接口声明的所有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法。`getMethods` 方法返回某个类的所有公用（public）方法，包括其继承类的公用方法。
	+ 获取类的成员变量（字段）信息。`getFiled`：访问公有的成员变量。`getDeclaredField`：所有已声明的成员变量，但不能得到其父类的成员变量
	+ 调用方法。Method.invoke
	+ 利用反射创建数组。Array.newInstance(Class<?>,int)

### 反射调用实现

​	方法的反射调用通过Method.invoke实现，方法执行时会委派给MethodAccessor执行。MethodAccessor 是一个接口，它有两个已有的具体实现：一个通过本地方法来实现反射调用，另一个则使用了委派模式。每个 Method 实例的第一次反射调用都会生成一个委派实现，它所委派的具体实现便是一个本地实现(C++调用)。

~~~java
    public Object invoke(Object obj, Object... args)
        throws IllegalAccessException, IllegalArgumentException,
           InvocationTargetException
    {
        if (!override) {
            Class<?> caller = Reflection.getCallerClass();
            checkAccess(caller, clazz,
                        Modifier.isStatic(modifiers) ? null : obj.getClass(),
                        modifiers);
        }
        MethodAccessor ma = methodAccessor;             // read volatile
        if (ma == null) {
            ma = acquireMethodAccessor();
        }
        return ma.invoke(obj, args);
    }
~~~

​	反射调用先是调用了 Method.invoke，然后进入委派实现（DelegatingMethodAccessorImpl），再然后进入本地实现（NativeMethodAccessorImpl），最后到达目标方法。

​	Java 的反射调用机制还设立了另一种动态生成字节码的实现（下称动态实现），直接使用 invoke 指令来调用目标方法。之所以采用委派实现，便是为了能够在本地实现以及动态实现中切换。

~~~java
// 动态实现的伪代码，这里只列举了关键的调用逻辑，其实它还包括调用者检测、参数检测的字节码。
// 生成直接调用方法的Java代码，和平时写的方法调用一样
package jdk.internal.reflect;
public class GeneratedMethodAccessor1 extends ... { 
    @Overrides 
    public Object invoke(Object obj, Object[] args) throws ... { 
    	Test.target((int) args[0]); 
        return null; 
    }
}
~~~

​	动态实现和本地实现相比，其运行效率要快上 20 倍  。这是因为动态实现无需经过 Java 到 C++ 再到 Java 的切换，但由于生成字节码十分耗时，仅调用一次的话，反而是本地实现要快上 3 到 4 倍 。

​	考虑到许多反射调用仅会执行一次，Java 虚拟机设置了一个阈值 15（可以通过 -Dsun.reflect.inflationThreshold= 来调整），当某个反射调用的调用次数在 15 之下时，采用本地实现；当达到 15 时，便开始动态生成字节码，并将委派实现的委派对象切换至动态实现，这个过程我们称之为 Inflation。反射调用的 Inflation 机制是可以通过参数（-Dsun.reflect.noInflation=true）来关闭的。这样一来，在反射调用一开始便会直接生成动态实现，而不会使用委派实现或者本地实现。

### 反射调用开销

​	反射调用涉及到Class.forName，Class.getMethod 以及 Method.invoke 三个操作。其中，Class.forName 会调用本地方法，Class.getMethod 则会遍历该类的公有方法。如果没有匹配到，它还将遍历父类的公有方法。以 getMethod 为代表的查找方法操作，会返回查找得到结果的一份拷贝，将带来额外的堆空间消耗。

​	方法的反射调用会带来不少性能开销，原因主要有三个：变长参数方法导致的 Object 数组(Method.invoke是个变长参数)	，基本类型的自动装箱、拆箱，还有最重要的方法内联。

## JVM实现invokedynamic

​	在 Java 中，方法调用会被编译为 invokestatic，invokespecial，invokevirtual 以及 invokeinterface 四种指令。这些指令与包含目标方法类名、方法名以及方法描述符的符号引用捆绑。在实际运行之前，Java 虚拟机将根据这个符号引用链接到具体的目标方法。在这四种调用指令中，Java 虚拟机明确要求方法调用需要提供目标方法的类名。

​	Java 7 引入了一条新的指令 invokedynamic。该指令的调用机制抽象出调用点这一个概念，并允许应用程序将调用点链接至任意符合条件的方法上。 invokedynamic的实现基于方法句柄（MethodHandle）。

​	方法句柄是一个强类型的、能够被直接执行的引用。它仅关心所指向方法的参数类型以及返回类型，而不关心方法所在的类以及方法名。方法句柄的权限检查发生在创建过程中，相较于反射调用节省了调用时反复权限检查的开销。

​	方法句柄可以通过 invokeExact 以及 invoke 来调用。其中，invokeExact 要求传入的参数和所指向方法的描述符严格匹配。方法句柄还支持增删改参数的操作，这些操作是通过生成另一个充当适配器的方法句柄来实现的。

​	方法句柄可以通过 invokeExact 以及 invoke 来调用。其中，invokeExact 要求传入的参数和所指向方法的描述符严格匹配。方法句柄还支持增删改参数的操作，这些操作是通过生成另一个充当适配器的方法句柄来实现的。

​	invokedymaic 指令抽象出调用点的概念，并且将调用该调用点所链接的方法句柄。在第一次执行 invokedynamic 指令时，Java 虚拟机将执行它所对应的启动方法，生成并且绑定一个调用点。之后如果再次执行该指令，Java 虚拟机则直接调用已经绑定了的调用点所链接的方法。

​	Lambda 表达式到函数式接口的转换是通过 invokedynamic 指令来实现的。该 invokedynamic 指令对应的启动方法将通过 ASM 生成一个适配器类。对于没有捕获其他变量的 Lambda 表达式，该 invokedynamic 指令始终返回同一个适配器类的实例。对于捕获了其他变量的 Lambda 表达式，每次执行 invokedynamic 指令将新建一个适配器类实例。

​	不管是捕获型的还是未捕获型的 Lambda 表达式，它们的性能上限皆可以达到直接调用的性能。其中，捕获型 Lambda 表达式借助了即时编译器中的逃逸分析，来避免实际的新建适配器类实例的操作。

## Java字节码

​	Java字节码为Java虚拟机所使用的指令集，该指令集包含200多个指令，使用8bit(2^8=256)就能存下，因此被称为字节码。字节码与Java虚拟机基于栈的计算模型是密不可分的。

​	在解释执行时，每当Java方法分配栈帧时，Java虚拟机往往需要开辟一块额外的空间作为操作数栈，来存放计算的操作数以及返回结果。具体来说就是：执行每一条指令之前，Java虚拟机要求该指令的操作数已被压入操作数栈中。在执行指令时，Java虚拟机会将该指令所需的操作数弹出，并将指令的结果重新压入栈。栈帧另一重要组成部分则是局部变量表，字节码程序可以将计算结果缓存在局部变量表中。实际上，Java虚拟机将局部变量表当成一个数组，依次存放this指针(仅非静态方法)，所传入的参数，以及字节码中的局部变量。

### 操作数栈

#### 直接作用在操作数栈的指令

​	dup：复制栈顶元素。常用于复制new指令所生成的未经初始化的引用，当执行new指令时，Java虚拟机会将指向一块已分配、未初始化的内存的引用压入操作数栈中。接下来，需要以这个引用作为调用者来调用其构造器，也就是invokespeical指令，该指令将消耗操作数栈的元素，作为它的调用者和参数。如果不复制，引用被消耗后，会丢失引用。

​	pop：舍弃栈顶元素。常用于舍弃调用指令的返回结果。

​	上述两条指令只能处理非long和非double类型的值，因为long和double类型的值需要占用两个栈单元，其他类型的值只会占用一个栈单元。当遇到long或double类型的值时，复制栈顶元素使用dup2指令，舍弃栈顶元素使用pop2指令。

​	swap：交换栈顶两个元素的值。

#### 常量加载指令

​	ldc:load constant

| 类型                            | 常数指令 | 范围                          |
| ------------------------------- | -------- | ----------------------------- |
| int(boolean, byte, char, short) | iconst   | [-1, 5]                       |
|                                 | bipush   | [-128, 127]                   |
|                                 | sipush   | [-32768, 32767]               |
|                                 | ldc      | any int value                 |
| long                            | lconst   | 0, 1                          |
|                                 | ldc      | any long value                |
| float                           | fconst   | 0, 1, 2                       |
|                                 | ldc      | any float value               |
| double                          | dconst   | 0, 1                          |
|                                 | ldc      | any double value              |
| reference                       | aconst   | null                          |
|                                 | ldc      | String literal, Class literal |

​	正常情况下，操作数栈的压入弹出都是一条一条指令完成的。但是在抛异常时，Java虚拟机会清除操作数栈上的所有内容，而后将异常压入操作数栈上。

### 局部变量表

​	和操作数栈一样，long和double类型的值占据两个单元，其余类型占据一个的单元。

#### 局部变量表访问指令

| 类型                            | 加载指令 | 存储指令 |
| ------------------------------- | -------- | -------- |
| int(boolean, byte, char, short) | iload    | istore   |
| long                            | lload    | lstore   |
| float                           | fload    | fstore   |
| double                          | dload    | dstore   |
| reference                       | aload    | astore   |

​	局部变量数组的加载、存储指令都要指明所加载单元的下标。

​	Java字节码中唯一能直接作用于局部变量表的指令是iinc M N(M为非负整数，N为整数)，该指令指的是将局部变量数组的第M个单元的int值加N，常用于for循环中自增量的更新。

### 其他类别指令

​	new：后跟目标类，生成该类的未初始化的对象。

​	instanceof：后跟目标类，判断栈顶元素是否为目标类/接口的实例，是则压入1，否则压入0。

​	checkstat：后跟目标类，判断栈顶元素是否为目标类/接口的实例，不是便抛出异常。

​	athrow：将栈顶异常抛出。

​	monitorenter：为栈顶元素加锁。

​	monitorexit：为栈顶元素解锁。

​	getstatic：静态字段访问。

​	putstatic：静态字段赋值。

​	getfield：实例字段访问。

​	putfield：实例字段赋值。

​	invokestatic：执行静态方法。

​	invokespecial：执行私有的实例方法，构造器，通过super调用的方法等。

​	invokeinterface：执行从接口继承的方法。

​	invokevirtual：执行非私有的实例方法。

​	invokedynamic：执行动态绑定方法。

### 数组相关指令

​	newarray：新建基本类型的数组。

​	anewarray：新建引用类型的数组。

​	multianewarray：生成多维数组。

​	arraylength：数组长度。

#### 数组访问指令

​	数组的加载指令和存储指令。

| 类型          | 加载指令 | 存储指令 |
| ------------- | -------- | -------- |
| byte(boolean) | baload   | bastore  |
| char          | caload   | castore  |
| short         | saload   | sastore  |
| int           | iaload   | iastore  |
| long          | laload   | lastore  |
| float         | faload   | fastore  |
| double        | daload   | dastore  |
| reference     | aaload   | aastore  |

### 返回指令表

​	控制流指令，包括无条件跳转的goto，条件跳转指令，tableswitch(密集的case)和lookupswitch(非密集的case)，返回指令，以及被废弃的jsr，ret指令。返回指令区分类型。

| 返回类型                        | 返回指令 |
| ------------------------------- | -------- |
| void                            | return   |
| int(boolean, byte, char, short) | ireturn  |
| long                            | lreturn  |
| float                           | freturn  |
| double                          | dreturn  |
| reference                       | areturn  |

## Java语法糖

### 自动装箱和自动拆箱

​	Java语言中拥有8个基本类型，每个基本类型都有对应的包装类型。之所以需要包装类型，是因为许多Java核心类库的API都是面向对象的。如，Java核心类库的容器类，就只支持引用类型。

​	当我们向一个存储包装类对象的容器存入一个基本数据时，首先需要将其转换为对应的包装类([Wrapper].valueOf)，这个过程可以是显示的，也可以是隐式的，隐式的话就是自动装箱。

​	当我们使用一个包装类对象和对应的基本类型比较时，包装类型会自动转换为基本数据类型([Wrapper].xxValue)，然后进行比较，自动地从包装类型转换到基本数据类型的过程就是自动拆箱。

### 泛型与类型擦除

​	当我们不知道会使用什么类型时，一般会使用泛型来声明，然后到真正使用时在传入真正的类型。

​	虽然我们在存入时会存真正类型的对象，但是存储到底层时，依然会存储Object对象(对于限定了基层类的泛型参数，经过类型擦除后，所有的泛型参数都将变成所限定的继承类)，取出时在强转成真正类型的对象，这个过程叫做类型擦除。泛型使用类型擦除的机制来做主要为了向后兼容。虽然经过类型擦除后，对象会变为Object类型，但是编译时，Java编译器还是会对数据进行类型校验的。

### 桥接方法

​	在Java中，如果子类从父类继承了一个方法，然后将返回值改为父类返回值的子类，我们仍然认为符合Java语言的重写，毕竟都使用了@Override注解。但是在Java虚拟机层面，因为方法描述符不一样，会认为是两个不同的方法，为了保证编译而成的Java字节码能够保留重写的语义，Java编译器额外添加了一个桥接方法，桥接方法在字节码层面重写了父类的方法(返回值类型一致，方法描述符一样)，并将调用子类的方法(返回值是父类返回值的子类)。

​	在javap的输出中，桥接方法的访问标识符会出现ACC_BRIDGE(代表桥接方法)之外，还会出现ACC_SYNTHETIC(代表不可见)。当尝试调用桥接方法时，Java编译器会报错，如果想调用这个方法，需要使用反射机制。

### 其他语法糖

​	变长参数：可以不指定参数个数，可以随意输入多个。

​	try-with-resource：自动释放资源(需要实现AutoCloseable接口)。

​	同一个cath代码块可以捕获多种异常

​	foreach循环允许Java程序在for循环里遍历数组或者Iterable对象。对数组来说foreach循环将从0开始逐一访问数组中的元素，直至数组的末尾。

​	字符串switch，实际就是一个哈希桶，由于每个字符串都是常量，因此会将字符串转换为int值switch，比较字符串的哈希值。由于字符串哈希值容易碰撞，因此还需要用String.equals诸葛比较相同哈希值的字符串。

## 即时编译

​	即时编译是一项用来提升应用程序运行效率的技术。通常而言，字节码会先被JVM解释执行，之后反复执行的热点代码(以方法为单位)则会被即时编译为机器码，直接运行在底层硬件上，来提升运行效率。

### 分层编译模式

​	HotSpot虚拟机包含多个即时编译器C1，C2和Graal。Graal是个实现性质的即时编译器，可以通过参数-XX:UnlockExperimentalVMOptions -XX:UserJVMC1Compiler启动，来替换C2即时编译器。

​	在JDK7之前，我们需要根据程序的特性选择对应的即时编译器。对于执行时间较短的，或对程序启动性能有要求的程序，我们采用代码编译效率较快的C1，对应参数 -client。对于执行时间较长的，或对程序峰值性能有要求的程序，我们采用代码执行效率较快的C2，对应参数 -server。

​	JDK7引入了分层编译(-XX:TieredCompilation)的概念，综合了C1的启动性能优势和C2的峰值性能优势。JDK8默认开启了分层编译。分层编译将JVM的执行状态分为了5个层次。

 +	解释执行；
 +	执行不带profiling的C1代码(C1编译器生成的机器码)；
 +	执行仅带方法调用次数以及循环回边执行次数的profiling的C1代码；
 +	执行带所有profiling的C1代码；
 +	执行C2代码(C2编译器生成的机器码)。

​	通常情况下，C2代码的执行效率要比C1代码高出30%以上。然而，对于C1代码的三种状态，按执行效率从高到低则是1层 > 2层 > 3层。这是因为profiling越多，其额外的性能开销越大。

​	profiling是指程序执行过程中，收集能够反映程序执行状态数据的过程。收集到的数据我们称之为程序的profile，profiler大多通过注入(instrumentation)或者JVMTI事件来实现的。JVM也内置了profiling。

​	在5个层次的执行状态中，1层和4层为终止状态，当一个方法被终止状态编译后，如果编译后的代码没有失效，那么JVM是不会再次发出该方法的编译请求的。

![即时编译器的层级](.\static\image\即时编译器的层级.webp)

​	上图为4个不同的编译路径。

​	通常情况下，热点方法hi被三层的C1编译，然后在被4层的C2编译。

​	如果方法的字节码数据较少(getter/setter)，而且3层的profiling没有可收集的数据。那么，JVM会判定对于C1代码和C2代码的执行效率相同，JVM会在3层编译后，直接选择1层的C1编译。这是一个终止状态，因此JVM不会继续使用4层的C2编译。

​	C1忙碌时，JVM会在解释执行时对程序进行profiling，而后直接由4层的C2编译。

​	C2忙碌时，方法会被2层的C1编译，然后在被3层的C1编译，以减少方法在3层的执行时间。

	### 即时编译的触发

​	JVM是根据方法的调用次数以及循环回边的执行次数来触发即时编译的。前面提到，JVM在0层，2层和3层执行状态是进行profiling，其中就包含方法的调用次数和循环回边次数。循环回边是一个控制流图的概念。在字节码中，可以简单理解为往回跳转的指令。

​	在即时编译过程中，我们会识别循环的头部和尾部。循环尾部到循环头部的控制流边就是真正意义上的循环回边，C1编译器将在这个位置插入增加循环回边计数器的代码。

​	解释执行和C1代码中增加循环回边计数器的位置并不相同，但不影响程序。实际上，JVM并不会对即时编译器进行同步操作，因此收集的执行次数并不一定准确，但是即时编译的触发并不需要非常精准的数值，只要该数值足够大， 就说明包含热点代码。

​	不开启分层编译的情况下，当方法的调用次数和循环回边次数的和，超过阈值(-XX:CompileThreshold, C1默认1500，C2默认10000)时，便会触发即时编译。开启分层编译时，阈值将动态调整。

​	所谓的动态调整其实并不复杂：在比较阈值时，Java 虚拟机会将阈值与某个系数 s 相乘。该系数与当前待编译的方法数目成正相关，与编译线程的数目成负相关。

````
系数的计算方法为：
s = queue_size_X / (TierXLoadFeedback * compiler_count_X) + 1

其中X是执行层次，可取3或者4；
queue_size_X是执行层次为X的待编译方法的数目；
TierXLoadFeedback是预设好的参数，其中Tier3LoadFeedback为5，Tier4LoadFeedback为3；
compiler_count_X是层次X的编译线程数目。
````

​	在 64 位 Java 虚拟机中，默认情况下编译线程的总数目是根据处理器数量来调整的（对应参数 -XX:+CICompilerCountPerCPU，默认为 true；当通过参数 -XX:+CICompilerCount=N 强制设定总编译线程数目时，CICompilerCountPerCPU 将被设置为 false）。Java 虚拟机会将这些编译线程按照 1:2 的比例分配给 C1 和 C2（至少各为 1 个）。

### OSR 编译

​	可以看到，决定一个方法是否为热点代码的因素有两个：方法的调用次数、循环回边的执行次数。即时编译便是根据这两个计数器的和来触发的。为什么 Java 虚拟机需要维护两个不同的计数器呢？实际上，除了以方法为单位的即时编译之外，Java 虚拟机还存在着另一种以循环为单位的即时编译，叫做 On-Stack-Replacement（OSR）编译。循环回边计数器便是用来触发这种类型的编译的。

​	OSR 实际上是一种技术，它指的是在程序执行过程中，动态地替换掉 Java 方法栈桢，从而使得程序能够在非方法入口处进行解释执行和编译后的代码之间的切换。事实上，去优化（deoptimization）采用的技术也可以称之为 OSR。在不启用分层编译的情况下，触发 OSR 编译的阈值是由参数 -XX:CompileThreshold 指定的阈值的倍数。

```
(OnStackReplacePercentage - InterpreterProfilePercentage)/100其中-XX:InterpreterProfilePercentage的默认值为33，当使用C1时-XX:OnStackReplacePercentage为933，当使用C2时为140。
```

​	在启用分层编译的情况下，触发 OSR 编译的阈值则是由参数 -XX:TierXBackEdgeThreshold 指定的阈值乘以系数。OSR 编译在正常的应用程序中并不多见。它只在基准测试时比较常见，因此并不需要过多了解。

### Profiling

​	分层编译中的 0 层、2 层和 3 层都会进行 profiling，收集能够反映程序执行状态的数据。其中，最为基础的便是方法的调用次数以及循环回边的执行次数。它们被用于触发即时编译。

​	此外，0 层和 3 层还会收集用于 4 层 C2 编译的数据，比如说分支跳转字节码的分支 profile（branch profile），包括跳转次数和不跳转次数，以及非私有实例方法调用指令、强制类型转换 checkcast 指令、类型测试 instanceof 指令，和引用类型的数组存储 aastore 指令的类型 profile（receiver type profile）。

​	分支 profile 和类型 profile 的收集将给应用程序带来不少的性能开销。据统计，正是因为这部分额外的 profiling，使得 3 层 C1 代码的性能比 2 层 C1 代码的低 30%。在通常情况下，我们不会在解释执行过程中收集分支 profile 以及类型 profile。只有在方法触发 C1 编译后，Java 虚拟机认为该方法有可能被 C2 编译，方才在该方法的 C1 代码中收集这些 profile。

​	那么这些耗费巨大代价收集而来的 profile 具体有什么作用呢？答案是，C2 可以根据收集得到的数据进行猜测，假设接下来的执行同样会按照所收集的 profile 进行，从而作出比较激进的优化。

#### 基于分支 profile 的优化

​	根据条件跳转指令的分支 profile，即时编译器可以将从未执行过的分支剪掉，以避免编译这些很有可能不会用到的代码，从而节省编译时间以及部署代码所要消耗的内存空间。

​	此外，“剪枝”将精简程序的数据流，从而触发更多的优化。在现实中，分支 profile 出现仅跳转或者仅不跳转的情况并不多见。当然，即时编译器对分支 profile 的利用也不仅限于“剪枝”。它还会根据分支 profile，计算每一条程序执行路径的概率，以便某些编译器优化优先处理概率较高的路径。

#### 基于类型 profile 的优化

​	instanceof 以及方法调用的类型 profile。

​	在 Java 虚拟机中，instanceof 测试并不简单。如果 instanceof 的目标类型是 final 类型，那么 Java 虚拟机仅需比较测试对象的动态类型是否为该 final 类型。如果目标类型不是 final 类型，那么 Java 虚拟机需要从测试对象的动态类型开始，依次测试该类，该类的父类、祖先类，该类所直接实现或者间接实现的接口是否与目标类型一致。

​	和基于分支 profile 的优化一样，基于类型 profile 的优化同样也是作出假设，从而精简控制流以及数据流。

#### 去优化

​	不管是基于分支 profile 的优化，还是基于类型 profile 的优化，这两者的核心都是假设。对于分支 profile，即时编译器假设的是仅执行某一分支；对于类型 profile，即时编译器假设的是对象的动态类型仅为类型 profile 中的那几个。

​	那么当假设失败时，JVM会从执行即时编译生成的机器码切换回解释执行。即去优化。

​	在生成的机器码中，即时编译器将在假设失败的位置上插入一个陷阱（trap）。该陷阱实际上是一条 call 指令，调用至 Java 虚拟机里专门负责去优化的方法。与普通的 call 指令不一样的是，去优化方法将更改栈上的返回地址，并不再返回即时编译器生成的机器码中。

​	去优化的过程相当复杂。由于即时编译器采用了许多优化方式，其生成的代码和原本的字节码的差异非常之大。在去优化的过程中，需要将当前机器码的执行状态转换至某一字节码之前的执行状态，并从该字节码开始执行。这便要求即时编译器在编译过程中记录好这两种执行状态的映射。

​	举例来说，经过逃逸分析之后，机器码可能并没有实际分配对象，而是在各个寄存器中存储该对象的各个字段。在去优化过程中，Java 虚拟机需要还原出这个对象，以便解释执行时能够使用该对象。当根据映射关系创建好对应的解释执行栈桢后，Java 虚拟机便会采用 OSR 技术，动态替换栈上的内容，并在目标字节码处开始解释执行。

​	此外，在调用 Java 虚拟机的去优化方法时，即时编译器生成的机器码可以根据产生去优化的原因来决定是否保留这一份机器码，以及何时重新编译对应的 Java 方法。

+ 如果去优化的原因与优化无关，即使重新编译也不会改变生成的机器码，那么生成的机器码可以在调用去优化方法时传入 Action_None，表示保留这一份机器码，在下一次调用该方法时重新进入这一份机器码。
+ 如果去优化的原因与静态分析的结果有关，例如类层次分析，那么生成的机器码可以在调用去优化方法时传入 Action_Recompile，表示不保留这一份机器码，但是可以不经过重新 profile，直接重新编译。
+ 如果去优化的原因与基于 profile 的激进优化有关，那么生成的机器码需要在调用去优化方法时传入 Action_Reinterpret，表示不保留这一份机器码，而且需要重新收集程序的 profile。这是因为基于 profile 的优化失败的时候，往往代表这程序的执行状态发生改变，因此需要更正已收集的 profile，以更好地反映新的程序执行状态。

## 即时编译器的中间表达形式

###	中间表达形式（Intermediate Representation）

​	在编译原理课程中，我们通常将编译器分为前端和后端。其中，前端会对所输入的程序进行词法分析、语法分析、语义分析，然后生成中间表达形式，也就是 IR（Intermediate Representation ）。后端会对 IR 进行优化，然后生成目标代码。

​	对于即时编译器来说，所输入的 Java 字节码剥离了很多高级的 Java 语法，而且其采用的基于栈的计算模型非常容易建模。因此，即时编译器并不需要重新进行词法分析、语法分析以及语义分析，而是直接将 Java 字节码作为一种 IR。

​	不过，Java 字节码本身并不适合直接作为可供优化的 IR。这是因为现代编译器一般采用静态单赋值（Static Single Assignment，SSA）IR。这种 IR 的特点是每个变量只能被赋值一次，而且只有当变量被赋值之后才能使用。

​	借助了 SSA IR，编译器则可以通过查找赋值了但是没有使用的变量，来识别冗余赋值。并且对其他优化方式也有很大的帮助，例如常量折叠（constant folding）、常量传播（constant propagation）、强度削减（strength reduction）以及死代码删除（dead code elimination）等。

```
示例：
x1=4*1024经过常量折叠后变为x1=4096x1=4; 
y1=x1经过常量传播后变为x1=4; 
y1=4y1=x1*3经过强度削减后变为y1=(x1<<1)+x1
if(2>1){y1=1;}else{y2=1;}经过死代码删除后变为y1=1
```

​	SSA IR 会带来一个问题，那便是不同执行路径可能会对同一变量设置不同的值。例如下面这段代码 if 语句的两个分支中，变量 y 分别被赋值为 0 或 1，并且在接下来的代码中读取 y 的值。此时，根据不同的执行路径，所读取到的值也很有可能不同。为了解决这个问题，我们需要引入一个 Phi 函数的概念，能够根据不同的执行路径选择不同的值。

​	总之，即时编译器会将 Java 字节码转换成 SSA IR。更确切的说，是一张包含控制流和数据流的 IR 图，每个字节码对应其中的若干个节点（注意，有些字节码并没有对应的 IR 节点）。然后，即时编译器在 IR 图上面进行优化。我们可以将每一种优化看成一个独立的图算法，它接收一个 IR 图，并输出经过转换后的 IR 图。整个编译器优化过程便是一个个优化串联起来的。

### Sea-of-nodes

​	HotSpot 里的 C2 采用的是一种名为 Sea-of-Nodes 的 SSA IR。它的最大特点，便是去除了变量的概念，直接采用变量所指向的值，来进行运算。

​	Graal 的 IR 同样也是 Sea-of-Nodes 类型的，并且可以认为是 C2 IR 的精简版本。

#### IR 图

​	红色加粗线条为控制流，蓝色线条为数据流，而其他颜色的线条则是特殊的控制流或数据流。被控制流边所连接的是固定节点，其他的皆属于浮动节点。若干个顺序执行的节点将被包含在同一个基本块之中。

#### 基本块直接的控制流关系

​	基本块是仅有一个入口和一个出口的指令序列（IR 节点序列）。一个基本块的出口可以和若干个基本块的入口相连接，反之亦然。

​	浮动节点的位置并不固定。在编译过程中，编译器需要（多次）计算浮动节点具体的排布位置。这个过程我们称之为节点调度（node scheduling）。节点调度是根据节点之间的依赖关系来进行的。

​	需要注意的是，C2 没有固定节点这一概念，所有的 IR 节点都是浮动节点。它将根据各个基本块头尾之间的控制依赖，以及数据依赖和内存依赖，来进行节点调度。这里的内存依赖是什么一个概念呢？假设一段程序往内存中存储了一个值，而后又读取同一内存，那么显然程序希望读取到的是所存储的值。即时编译器不能任意调度对同一内存地址的读写，因为它们之间存在依赖关系。

​	C2 的做法便是将这种时序上的先后记录为内存依赖，并让节点调度算法在进行调度时考虑这些内存依赖关系。Graal 则将内存读写转换成固定节点。由于固定节点存在先后关系，因此无须额外记录内存依赖。

### Global Value Numbering

​	Global Value Numbering（GVN）是一种发现并消除等价计算的优化技术。因 Sea-of-Nodes 而变得非常容易。

​	举例来说，如果一段程序中出现了多次操作数相同的乘法，那么即时编译器可以将这些乘法并为一个，从而降低输出机器码的大小。如果这些乘法出现在同一执行路径上，那么 GVN 还将省下冗余的乘法操作。

​	在 Sea-of-Nodes 中，由于只存在值的概念，因此 GVN 算法将非常简单：如果一个浮动节点本身不存在内存副作用（由于 GVN 可能影响节点调度，如果有内存副作用的话，那么将引发一些源代码中不可能出现的情况） ，那么即时编译器只需判断该浮动节点是否与已存在的浮动节点的类型相同，所输入的 IR 节点是否一致，便可以将这两个浮动节点归并成一个。

​	我们可以将 GVN 理解为在 IR 图上的公共子表达式消除（Common Subexpression Elimination，CSE）。这两者的区别在于，GVN 直接比较值的相同与否，而 CSE 则是借助词法分析器来判断两个表达式相同与否。因此，在不少情况下，CSE 还需借助常量传播来达到消除的效果。

## 方法内联

​	方法内联是在编译过程中遇到方法调用时，将目标方法的方法体纳入编译范围之中，并取代原方法调用的优化手段。方法内联不仅可以消除调用本身带来的性能开销，还可以进一步触发更多的优化。

​	以getter/setter方法为列，如果没有方法内联，在调用时，程序需要保存当前方法的执行位置，创建并压入用于getter/setter的栈帧、访问字段、弹出栈帧、最后在恢复当前方法的执行。而当内联了对getter/setter方法的调用后，上诉操作仅剩字段访问。

​	方法内联是在解析字节码的过程中完成的。每当遇到方法调用的字节码时，即时编译器将决定是否需要内联该方法的调用。如果需要内联，则开始解析目标方法的字节码。即时编译器既可以在解析过程中替换方法调用字节码，也可以在 IR 图中替换方法调用 IR 节点。这两者都需要将目标方法的参数以及返回值映射到当前方法来。

​	即时编译器首先解析字节码，并生成 IR 图，然后在该 IR 图上进行优化。优化是由一个个独立的优化阶段（optimization phase）串联起来的。每个优化阶段都会对 IR 图进行转换。最后即时编译器根据 IR 图的节点以及调度顺序生成机器码。先比于C2编译器，Graal编译器还拥有一个独立的优化阶段，即寻找指代方法调用的IR节点，并将之替换为对目标方法的IR图。

### 方法内联的条件

​	方法内联能够触发更多的优化。通常而言，内联越多，生成代码的执行效率越高。然而，对于即时编译器来说，内联越多，编译时间也就越长，而程序达到峰值性能的时刻也被推迟。此外，内联越多也将导致生成的机器码越长。在JVM中，编译生成的机器码会被存储在Code Cache中。这个Code Cache是由大小限制的(-XX:ReservedCodeCacheSize)。

​	生成的机器码越长，越容易填满Code Cache，从而出现Code Cache已满，即时编译已被关闭的警告信息(Code Cache is full.Compiler has been disabled)。

​	因此，即时编译器不会无限制地进行方法内联。方法内联有一些规则。

+ 自动拆箱总会被内联、Throwable类的方法不能被其它类中的方法锁内联；
+ 由-XX:CompileCommand中的inline指令指定的方法，以及由@ForceInline注解的方法(仅限JDK内部方法)会被强制内联。
+ 由-XX:CompileCommand中的dontinline指令或exclude指令指定的方法，以及由@DontInline注解的方法(仅限JDK内部方法)，不会被内联。
+ 如果调用字节码对应的符号引用未被解析、目标方法所在的类未被初始化，或者目标方法是 native 方法，都将导致方法调用无法内联。
+ C2 不支持内联超过 9 层的调用（-XX:MaxInlineLevel ），以及 1 层的直接递归调用（ -XX:MaxRecursiveInlineLevel ）。PS：如果方法 a 调用了方法 b，而方法 b 调用了方法 c，那么我们称 b 为 a 的 1 层调用，而 c 为 a 的 2 层调用。
+ 即时编译器将根据方法调用指令所在的程序路径的热度，目标方法的调用次数及大小，以及当前 IR 图的大小来决定方法调用能否被内联。总体来说，即时编译器中的内联算法更青睐于小方法。

![方法内联相关参数](.\static\image\方法内联相关参数.webp)

### 虚方法调用的去虚化

​	方法内联对于静态方法调用，即时编译器可以轻易地确定唯一的目标方法。然而对于需要动态绑定的虚方法调用来说，即时编译器则需要先对虚方法调用进行去虚化（devirtualize），即转换为一个或多个直接调用，然后才能进行方法内联。

​	即时编译器的去虚化方式可分为完全去虚化以及条件去虚化（guarded devirtualization）。

#### 完全去虚化

​	完全去虚化是通过类型推导或者类层次分析（class hierarchy analysis），识别虚方法调用的唯一目标方法，从而将其转换为直接调用的一种优化手段。它的关键在于证明虚方法调用的目标方法是唯一的。

##### 基于类型推导的完全去虚化

​	基于类型推导的完全去虚化将通过数据流分析推导出调用者的动态类型，从而确定具体的目标方法。

​	在 Sea-of-Nodes 的 IR 系统中，变量不复存在，取而代之的是具体值。这些具体值的类型往往要比变量的声明类型精确。因此，通过将字节码转换为 Sea-of-Nodes IR 之后，即时编译器便可以直接去虚化，并将唯一的目标方法进一步内联进来。

​	对于需要额外的数据流分析方能确定动态类型时，即时编译器会放弃推导出调用者的动态类型，从而放弃内联，以节省编译时间，并依赖接下来的去虚化手段进行优化。其原因在于类型推导属于全局优化，本身比较浪费时间；另一方面，就算不进行基于类型推导的完全去虚化，也有接下来的基于类层次分析的去虚化，以及条件去虚化兜底，覆盖大部分的代码情况。

##### 基于类层次分析的完全去虚化

​	基于类层次分析的完全去虚化通过分析 Java 虚拟机中所有已被加载的类，判断某个抽象方法或者接口方法是否仅有一个实现。如果是，那么对这些方法的调用将只能调用至该具体实现中。

​	对于这些方法，JVM会为当前编译结果注册若干个假设，假定某抽象类只有一个子类，或者某抽象方法只有一个具体实现，又或者某类没有子类等。之后，每当新的类被加载，Java 虚拟机便会重新验证这些假设。如果某个假设不再成立，那么 Java 虚拟机便会对其所属的编译结果进行去优化。

#### 条件去虚化

​	条件去虚化则是将虚方法调用转换为若干个类型测试以及直接调用的一种优化手段。它的关键在于找出需要进行比较的类型。具体的原理是将调用者的动态类型，依次与 Java 虚拟机所收集的类型 Profile 中记录的类型相比较。如果匹配，则直接调用该记录类型所对应的目标方法。

​	如果遍历完类型 Profile 中的所有记录，仍旧匹配不到调用者的动态类型，那么即时编译器有两种选择。

​	第一，如果类型 Profile 是完整的，也就是说，所有出现过的动态类型都被记录至类型 Profile 之中，那么即时编译器可以让程序进行去优化，重新收集类型 Profile。

​	第二，如果类型 Profile 是不完整的，也就是说，某些出现过的动态类型并没有记录至类型 Profile 之中，那么重新收集并没有多大作用。此时，即时编译器(Graal)可以让程序进行原本的虚调用，通过内联缓存进行调用，或者通过方法表进行动态绑定。对于C2即时编译器，如果类型 Profile 是不完整的，即时编译器压根不会进行条件去虚化，而是直接使用内联缓存或者方法表。

## HotSpot VM的intrinsic

​	JDK9引入了@HotSpotIntrinsicCandidate注解。在 HotSpot 虚拟机中，所有被该注解标注的方法都是 HotSpot intrinsic。对这些方法的调用，会被 HotSpot 虚拟机替换成高效的指令序列(CPU 指令)，而原本的方法实现则会被忽略掉。

​	换句话说，HotSpot 虚拟机将为标注了@HotSpotIntrinsicCandidate注解的方法额外维护一套高效实现。当其他虚拟机没有维护这些intrinsic实现时，它们会使用原本的代码实现。

​	为什么不直接在源代码中使用这些高效实现呢？这是因为高效实现通常依赖于具体的 CPU 指令，而这些 CPU 指令不好在 Java 源程序中表达。再者，换了一个体系架构，说不定就没有对应的 CPU 指令，也就无法进行 intrinsic 优化了。

### intrinsic 与方法内联

​	HotSpot 虚拟机中，intrinsic 的实现方式分为两种。

​	一种是独立的桩程序。它既可以被解释执行器利用，直接替换对原方法的调用；也可以被即时编译器所利用，它把代表对原方法的调用的 IR 节点，替换为对这些桩程序的调用的 IR 节点。以这种形式实现的 intrinsic 比较少，主要包括Math类中的一些方法。

​	另一种则是特殊的编译器 IR 节点。这种实现方式仅能够被即时编译器所利用。在编译过程中，即时编译器会将对原方法的调用的 IR 节点，替换成特殊的 IR 节点，并参与接下来的优化过程。最终，即时编译器的后端将根据这些特殊的 IR 节点，生成指定的 CPU 指令。大部分的 intrinsic 都是通过这种方式实现的。

​	这个替换过程是在方法内联时进行的。当即时编译器碰到方法调用节点时，它将查询目标方法是不是 intrinsic。如果是，则插入相应的特殊 IR 节点；如果不是，则进行原本的内联工作。（即判断是否需要内联目标方法的方法体，并在需要内联的情况下，将目标方法的 IR 图纳入当前的编译范围之中。）

​	不少被标记为 intrinsic 的方法都是 native 方法。原本对这些 native 方法的调用需要经过 JNI（Java Native Interface），其性能开销十分巨大。但是，经过即时编译器的 intrinsic 优化之后，这部分 JNI 开销便直接消失不见，并且最终的结果也十分高效。

### 已有 intrinsic 简介

​	Unsafe类的方法。

​	StringBuilder和StringBuffer类的方法。

​	基本类型的包装类、Object类、Math类、System类中各个功能性方法，反射 API、MethodHandle类中与调用机制相关的方法，压缩、加密相关方法。

## Java对象内存布局

### 对象结构

#### 对象头(Object Header)

##### 对象标记(markOop)

​	存储对象本身运行时的数据，如哈希码、GC标记(分代年龄？)、锁信息、线程关联信息等。这部分数据在64位JVM占8字节(64bit/8byte)。

##### 类元信息(klassOop)

​	存储指向对象本身的类元数据(即Klass)的首地址。这部分数据在64位JVM中，如果开启压缩指针占4字节，不开启占8字节。

#### 数组长度

​	这部分只有是数组对象才有，如果是非数组对象，就没这部分了，这部分占4字节（32bit）。

#### 实例数据(Instance Data)

​	分为基础数据类型和引用类型。基础数据类型按照类型的大小计算，引用类型在64位JVM中，如果开启压缩指针占4字节，不开启占8字节。

#### 对齐填充(Padding)

​	默认情况下，Java 虚拟机堆中对象的起始地址需要对齐至 8(对应虚拟机选项 -XX:ObjectAlignmentInBytes，默认值为 8) 的倍数(内存对齐)。如果一个对象用不到 8N 个字节，那么空白的那部分空间就浪费掉了。这些浪费掉的空间我们称之为对象间的填充。-XX:ObjectAlignmentInBytes设置的越大越浪费，比如对于一个17字节的对象，如果ObjectAlignmentInBytes=8，则需要填充7字节。如果ObjectAlignmentInBytes=16，则需要填充15字节。

​	内存对齐和压缩指针有一定的关系。压缩指针的原理是寻址单位不同。未开启压缩指针前，指针保存对象的真实内存地址,开启后保存对象的映射地址。打个比方，路上停着的全是房车，而且每辆房车恰好占据两个停车位。现在，我们按照顺序给它们编号。也就是说，停在 0 号和 1 号停车位上的叫 0 号车，停在 2 号和 3 号停车位上的叫 1 号车，依次类推。原本的内存寻址用的是车位号。比如说我有一个值为 6 的指针，代表第 6 个车位，那么沿着这个指针可以找到 3 号车。现在我们规定指针里存的值是车号，比如 3 指代 3 号车。当需要查找 3 号车时，我便可以将该指针的值乘以 2，再沿着 6 号车位找到 3 号车。

​	默认情况下，JVM以8((对应虚拟机选项 -XX:ObjectAlignmentInBytes，默认值为 8))字节对齐，所以映射地址可以映射出真实内存地址的8倍。压缩指针占4个字节(32bit)，CPU寻址的单位为byte，映射的最大真实内存地址为 2 ^ 32 * 8 (byte)=  32G。所以对于64位JVM，不超过32G内存时自动开启压缩指针。

​	当然，就算是关闭了压缩指针，Java 虚拟机还是会进行内存对齐。此外，内存对齐不仅存在于对象与对象之间，也存在于对象中的字段之间。比如说，Java 虚拟机要求 long 字段、double 字段，以及非压缩指针状态下的引用字段地址为 8 的倍数。

​	字段内存对齐的其中一个原因，是让字段只出现在同一 CPU 的缓存行中。如果字段不是对齐的，那么就有可能出现跨缓存行的字段。也就是说，该字段的读取可能需要替换两个缓存行，而该字段的存储也会同时污染两个缓存行。这两种情况对程序的执行效率而言都是不利的。

#### 字段重排序

​	**字段重排列，顾名思义，就是 Java 虚拟机重新分配字段的先后顺序，以达到内存对齐的目的。**Java 虚拟机中有三种排列方法（对应 Java 虚拟机选项 -XX:FieldsAllocationStyle，默认值为 1），但都会遵循如下两个规则。

​	其一，**如果一个字段占据 C 个字节，那么该字段的偏移量需要对齐至 NC。这里偏移量指的是字段地址与对象的起始地址差值。**以 long 类为例，它仅有一个 long 类型的实例字段。在使用了压缩指针的 64 位虚拟机中，尽管对象头的大小为 12 个字节，该 long 类型字段的偏移量也只能是 16，而中间空着的 4 个字节便会被浪费掉。

​	其二，**子类所继承字段的偏移量，需要与父类对应字段的偏移量保持一致。在具体实现中，Java 虚拟机还会对齐子类字段的起始位置。**对于使用了压缩指针的 64 位虚拟机，子类第一个字段需要对齐至 4N；而对于关闭了压缩指针的 64 位虚拟机，子类第一个字段则需要对齐至 8N。

~~~java
class A {
  long l;
  int i；
}

class B extends A {
  long l;
  int i;
}
~~~

~~~java
# 启用压缩指针时，B类的字段分布
B object internals:
 OFFSET  SIZE   TYPE DESCRIPTION
      0     4        (object header)
      4     4        (object header)
      8     4        (object header)
     12     4    int A.i                                       0
     16     8   long A.l                                       0
     24     8   long B.l                                       0
     32     4    int B.i                                       0
     36     4        (loss due to the next object alignment)
~~~

​	当启用压缩指针时，可以看到 Java 虚拟机将 A 类的 int 字段放置于 long 字段之前，以填充因为 long 字段对齐造成的 4 字节缺口。由于对象整体大小需要对齐至 8N，因此对象的最后会有 4 字节的空白填充。

~~~
# 关闭压缩指针时，B类的字段分布
B object internals:
 OFFSET  SIZE   TYPE DESCRIPTION
      0     4        (object header)
      4     4        (object header)
      8     4        (object header)
     12     4        (object header)
     16     8   long A.l
     24     4    int A.i
     28     4        (alignment/padding gap)                  
     32     8   long B.l
     40     4    int B.i
     44     4        (loss due to the next object alignment)
~~~

​	Java 8 还引入了一个新的注释 @Contended，用来解决对象字段之间的虚共享（false sharing）问题。这个注释也会影响到字段的排列。Java 虚拟机会让不同的 @Contended 字段处于独立的缓存行中，因此你会看到大量的空间被浪费掉。

## 垃圾回收(Garbage Collection)

​	JVM中内存是自动管理的，由垃圾回收器将已经分配出去的，但却不再使用的内存回收回来，以便能够再次分配。大致流程为先辨别(标记)出不使用的对象，然后进行回收。

### 标记方法

#### 引用计数法(reference counting)

​	为每个对象添加一个引用计数器，用来统计指向该对象的引用个数。一旦某个对象的引用计数器为 0，则说明该对象已经死亡，便可以被回收了。

​	除了需要额外的空间来存储计数器，以及繁琐的更新操作，引用计数法还有一个重大的漏洞，那便是无法处理循环引用对象。假设对象 a 与 b 相互引用，除此之外没有其他引用指向 a 或者 b。在这种情况下，a 和 b 实际上已经死了，但由于它们的引用计数器皆不为 0，在引用计数法的心中，这两个对象还活着。因此，这些循环引用对象所占据的空间将不可回收，从而造成了内存泄露。

#### 根可达算法

​	这个算法的实质在于将一系列 GC Roots 作为初始的存活对象合集（live set），然后从该合集出发，探索所有能够被该集合引用到的对象，并将其加入到该集合中，这个过程我们也称之为标记（mark）。最终，未被探索到的对象便是死亡的，是可以回收的。

​	GC Roots可以暂时理解为由堆外指向堆内的引用，一般分为如下几种：

 	1. 已加载类的静态变量；
 	2. 常量引用的对象；
 	3. Java 方法栈桢中的局部变量；
 	4. 本地方法占中引用的对象；

​	虽然可达性分析的算法本身很简明，但是在实践中还是有不少其他问题需要解决的。比如说，在多线程环境下，其他线程可能会更新已经访问过的对象中的引用，从而造成误报（将引用设置为 null）或者漏报（将引用设置为未被访问过的对象）。误报对于JVM来说，最多损失了部分垃圾回收的机会。但是漏报比较麻烦，如果垃圾回收器回收事实上仍被引用的对象内存。一旦从原引用访问已经被回收了的对象，则很有可能会直接导致 Java 虚拟机崩溃。

##### Stop-the-world 以及安全点

​	怎么解决这个问题呢？在 Java 虚拟机里，传统的垃圾回收算法采用的是一种简单粗暴的方式，那便是 Stop-the-world，停止其他非垃圾回收线程的工作，直到完成垃圾回收。这也就造成了垃圾回收所谓的暂停时间（GC pause）。

​	**Java 虚拟机中的 Stop-the-world 是通过安全点（safepoint）机制来实现的。当 Java 虚拟机收到 Stop-the-world 请求，它便会等待所有的线程都到达安全点，才允许请求 Stop-the-world 的线程进行独占的工作。**安全点的初始目的并不是让其他线程停下，而是找到一个稳定的执行状态。在这个执行状态下，Java 虚拟机的堆栈不会发生变化。这么一来，垃圾回收器便能够“安全”地执行可达性分析。

​	举个例子，当 Java 程序通过 JNI 执行本地代码时，如果这段代码不访问 Java 对象、调用 Java 方法或者返回至原 Java 方法，那么 Java 虚拟机的堆栈不会发生改变，也就代表着这段本地代码可以作为同一个安全点。只要不离开这个安全点，Java 虚拟机便能够在垃圾回收的同时，继续运行这段本地代码。

​	由于本地代码需要通过 JNI 的 API 来完成上述三个操作，因此 Java 虚拟机仅需在 API 的入口处进行安全点检测（safepoint poll），测试是否有其他线程请求停留在安全点里，便可以在必要的时候挂起当前线程。

​	除了执行 JNI 本地代码外，Java 线程还有其他几种状态：解释执行字节码、执行即时编译器生成的机器码和线程阻塞。阻塞的线程由于处于 Java 虚拟机线程调度器的掌控之下，因此属于安全点。其他几种状态则是运行状态，**需要虚拟机保证在可预见的时间内进入安全点。否则，垃圾回收线程可能长期处于等待所有线程进入安全点的状态，从而变相地提高了垃圾回收的暂停时间。**

​	对于解释执行来说，字节码与字节码之间皆可作为安全点。Java 虚拟机采取的做法是，当有安全点请求时，执行一条字节码便进行一次安全点检测。

​	执行即时编译器生成的机器码则比较复杂。由于这些代码直接运行在底层硬件之上，不受 Java 虚拟机掌控，因此在生成机器码时，即时编译器需要插入安全点检测，以避免机器码长时间没有安全点检测的情况。HotSpot 虚拟机的做法便是在生成代码的方法出口以及非计数循环的循环回边（back-edge）处插入安全点检测。

​	那么为什么不在每一条机器码或者每一个机器码基本块处插入安全点检测呢？原因主要有两个。

​	第一，安全点检测本身也有一定的开销。不过 HotSpot 虚拟机已经将机器码中安全点检测简化为一个内存访问操作。在有安全点请求的情况下，Java 虚拟机会将安全点检测访问的内存所在的页设置为不可读，并且定义一个 segfault 处理器，来截获因访问该不可读内存而触发 segfault 的线程，并将它们挂起。

​	第二，即时编译器生成的机器码打乱了原本栈桢上的对象分布状况。在进入安全点时，机器码还需提供一些额外的信息，来表明哪些寄存器，或者当前栈帧上的哪些内存空间存放着指向对象的引用，以便垃圾回收器能够枚举 GC Roots。

### 整理方法

#### 清除(sweep)

​	将死亡对象所占据的内存标记为空闲内存，并记录在一个空闲列表（free list）之中。当需要新建对象时，内存管理模块便会从该空闲列表中寻找空闲内存，并划分给新建的对象。

​	清除这种回收方式的原理及其简单，但是有两个缺点。一是会**造成内存碎片**。由于 Java 虚拟机的堆中对象必须是连续分布的，因此可能出现总空闲内存足够，但是无法分配的极端情况。另一个则是**分配效率较低**。如果是一块连续的内存空间，那么我们可以通过指针加法（pointer bumping）来做分配。而对于空闲列表，Java 虚拟机则需要逐个访问列表中的项，来查找能够放入新建对象的空闲内存。

#### 压缩	

​	将存活的对象聚集到内存区域的起始位置，从而留下一段连续的内存空间。这种做法能够解决内存碎片化的问题，但代价是压缩算法的性能开销。

#### 复制

​	即把内存区域分为两等分，分别用两个指针 from 和 to 来维护，并且只是用 from 指针指向的内存区域来分配内存。当发生垃圾回收时，便把存活的对象复制到 to 指针指向的内存区域中，并且交换 from 指针和 to 指针的内容。复制这种回收方式同样能够解决内存碎片化的问题，但是它的缺点也极其明显，即堆空间的使用效率极其低下。

### 分代回收

​	根据假设，大部分的 Java 对象只存活一小段时间，而存活下来的小部分 Java 对象则会存活很长一段时间。提出了JVM的分代回收思想，新生代和老年代，可以对不同代使用不同的回收算法。

​	对于新生代，我们猜测大部分的 Java 对象只存活一小段时间，那么便可以频繁地采用耗时较短的垃圾回收算法，让大部分的垃圾都能够在新生代被回收掉。对于老年代，我们猜测大部分的垃圾已经在新生代中被回收了，而在老年代中的对象有大概率会继续存活。当真正触发针对老年代的回收时，则代表这个假设出错了，或者堆的空间已经耗尽了。这时候，Java 虚拟机往往需要做一次全堆扫描，耗时也将不计成本。

### JVM堆划分

​	前面提到，Java 虚拟机将堆划分为新生代和老年代。其中，新生代又被划分为 Eden 区，以及两个大小相同的 Survivor 区。默认情况下，Java 虚拟机采取的是一种动态分配的策略（对应 Java 虚拟机参数 -XX:+UsePSAdaptiveSurvivorSizePolicy），根据生成对象的速率，以及 Survivor 区的使用情况动态调整 Eden 区和 Survivor 区的比例。当然，你也可以通过参数 -XX:SurvivorRatio 来固定这个比例。但是需要注意的是，其中一个 Survivor 区会一直为空，因此比例越低浪费的堆空间将越高。

​	通常来说，当我们调用 new 指令时，它会在 Eden 区中划出一块作为存储对象的内存。由于堆空间是线程共享的，因此直接在这里边划空间是需要进行同步的。否则，将有可能出现两个对象共用一段内存的事故。为了防止该情况，JVM采用TLAB（Thread Local Allocation Buffer，对应虚拟机参数 -XX:+UseTLAB，默认开启）预先给线程分配一段连续的内存，作为线程私有的 TLAB。这个操作需要加锁，线程需要维护两个指针（实际上可能更多，但重要也就两个），一个指向 TLAB 中空余内存的起始位置，一个则指向 TLAB 末尾。接下来的 new 指令，便可以直接通过指针加法（bump the pointer）来实现，即把指向空余内存位置的指针加上所请求的字节数。如果加法后空余内存指针的值仍小于或等于指向末尾的指针，则代表分配成功。否则，TLAB 已经没有足够的空间来满足本次新建操作。这个时候，便需要当前线程重新申请新的 TLAB。

​	当 Eden 区的空间耗尽了怎么办？这个时候 Java 虚拟机便会触发一次 Minor GC，来收集新生代的垃圾。存活下来的对象，则会被送到 Survivor 区。前面提到，新生代共有两个 Survivor 区，我们分别用 from 和 to 来指代。其中 to 指向的 Survivior 区是空的。当发生 Minor GC 时，Eden 区和 from 指向的 Survivor 区中的存活对象会被复制到 to 指向的 Survivor 区中，然后交换 from 和 to 指针，以保证下一次 Minor GC 时，to 指向的 Survivor 区还是空的。

​	Java 虚拟机会记录 Survivor 区中的对象一共被来回复制了几次。如果一个对象被复制的次数为 15（对应虚拟机参数 -XX:+MaxTenuringThreshold，对象头中使用4bit来存，因此最大15），那么该对象将被晋升（promote）至老年代。另外，如果单个 Survivor 区已经被占用了 50%（对应虚拟机参数 -XX:TargetSurvivorRatio），那么较高复制次数的对象也会被晋升至老年代。

​	总而言之，当发生 Minor GC 时，我们应用了标记 - 复制算法，将 Survivor 区中的老存活对象晋升到老年代，然后将剩下的存活对象和 Eden 区的存活对象复制到另一个 Survivor 区中。理想情况下，Eden 区中的对象基本都死亡了，那么需要复制的数据将非常少，因此采用这种标记 - 复制算法的效果极好。Minor GC 的另外一个好处是不用对整个堆进行垃圾回收。但是，它却有一个问题，那就是老年代的对象可能引用新生代的对象。也就是说，在标记存活对象的时候，我们需要扫描老年代中的对象。如果该对象拥有对新生代对象的引用，那么这个引用也会被作为 GC Roots。

​	这样一来，岂不是又做了一次全堆扫描呢？

### 卡表

​	HotSpot 给出的解决方案是一项叫做卡表（Card Table）的技术。该技术将整个堆划分为一个个大小为 512 字节的卡，并且维护一个卡表，用来存储每张卡的一个标识位。这个标识位代表对应的卡是否可能存有指向新生代对象的引用。如果可能存在，那么我们就认为这张卡是脏的。

​	在进行 Minor GC 的时候，我们便可以不用扫描整个老年代，而是在卡表中寻找脏卡，并将脏卡中的对象加入到 Minor GC 的 GC Roots 里。当完成所有脏卡的扫描之后，Java 虚拟机便会将所有脏卡的标识位清零。由于 Minor GC 伴随着存活对象的复制，而复制需要更新指向该对象的引用。因此，在更新引用的同时，我们又会设置引用所在的卡的标识位。这个时候，我们可以确保脏卡中必定包含指向新生代对象的引用。在 Minor GC 之前，我们并不能确保脏卡中包含指向新生代对象的引用。其原因和如何设置卡的标识位有关。首先，如果想要保证每个可能有指向新生代对象引用的卡都被标记为脏卡，那么 Java 虚拟机需要截获每个引用型实例变量的写操作，并作出对应的写标识位操作。这个操作在解释执行器中比较容易实现。但是在即时编译器生成的机器码中，则需要插入额外的逻辑。这也就是所谓的写屏障（write barrier，注意不要和 volatile 字段的写屏障混淆）。写屏障需要尽可能地保持简洁。这是因为我们并不希望在每条引用型实例变量的写指令后跟着一大串注入的指令。因此，写屏障并不会判断更新后的引用是否指向新生代中的对象，而是宁可错杀，不可放过，一律当成可能指向新生代对象的引用。

​	虽然写屏障不可避免地带来一些开销，但是它能够加大 Minor GC 的吞吐率（ 应用运行时间 /(应用运行时间 + 垃圾回收时间) ）。总的来说还是值得的。不过，在高并发环境下，写屏障又带来了虚共享（false sharing）问题。

​	在介绍对象内存布局中我曾提到虚共享问题，讲的是几个 volatile 字段出现在同一缓存行里造成的虚共享。这里的虚共享则是卡表中不同卡的标识位之间的虚共享问题。在 HotSpot 中，卡表是通过 byte 数组来实现的。对于一个 64 字节的缓存行来说，如果用它来加载部分卡表，那么它将对应 64 张卡，也就是 32KB 的内存。如果同时有两个 Java 线程，在这 32KB 内存中进行引用更新操作，那么也将造成存储卡表的同一部分的缓存行的写回、无效化或者同步操作，因而间接影响程序性能。为此，HotSpot 引入了一个新的参数 -XX:+UseCondCardMark，来尽量减少写卡表的操作。

### 垃圾回收器

## JAVA内存模型

​	由于计算机处理器和存储设备的运算速度有几个数量级的差距，所以现代计算机系统不得不加入一层高速缓存来作为内存和处理器之间的缓存。基于高速缓存的存储交互很好的解决了处理器和内存速度的矛盾，但引入了缓存一致性(Cache Coherence)问题，即多个高速缓存将同一个数据写入到主内存中，以哪个为准。为了解决一致性问题，又引入了一些协议，如MESI等。

​	JVM的即时编译器为了提高执行速度，可能会对执行进行重排序，以此来提高执行速度。但是无法对有数据以来的指令进行重排序，而且要遵守“线程内表现为串行的语义”(Within-Thread As-If-Serial Semantics)，即代码在单线程中重排序的执行结果和未重排序的执行结果一致。但因为执行重排序以及工作内存(高速缓存)与主内存同步延迟的情况导致会出现并发安全(执行结果不唯一(每次执行可能有不同的结果)，且与预期不符合)问题。

​	Java内存模型(Java Memory Model,JMM)来屏蔽各种硬件的和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。可以解决相同的代码在不同的平台并发行为不一致的情况。

​	JMM主要的目的时定义程序中各种变量(实例字段，静态字段和构成数组对象的元素，不包括线程私有的变量(如局部变量，方法参数))的访问规则，即关注在虚拟机中把变量值存储到内存中和从内存中取出变量值这样的底层细节。JMM规定所有的变量都存储在主内存中，每个线程还有自己的工作内存(保存主内存变量的副本，不是全部复制，只复制需要的字段)。线程对变量的操作要在工作内存中进行，不能直接操作主内存。不同线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。

### 内存间交互操作

​	关于主内存和工作内存之间具体的交互协议，即如何把一个变量从主内存复制到工作内存，如何把工作内存的变量同步回主内存。JMM定义了8个原子性操作来完成。

#### 原子性操作

+ lock：作用于主内存变量，将一个变量标记为线程独占。
+ unlock：作用于主内存变量，将处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。
+ read：作用于主内存变量，将变量的值从主内存拷贝到工作内存，以便随后的load操作使用。
+ load：作用于工作内存变量，将read操作拷贝的变量的值放到工作内存的变量副本中。
+ use：作用于工作内存变量，将工作内存的变量的值传递给执行引擎，每当JVM遇到一个需要使用变量的值的字节码指令时需要执行这个操作。
+ assign：作用于工作内存变量，将从执行引擎接收的值赋给工作内存中的变量，每当JVM遇到一个需要给变量赋值的字节码指令时需要执行这个操作。
+ store：作用于工作内存变量，将变量的值从工作内存拷贝到主内存，以便随后的write操作使用。
+ write：作用于主内存变量，将store操作拷贝的变量的值同步回主内存变量中。

read和load操作，还有store和write操作必须按顺序执行，但不要求连续执行。

#### 原子性操作规则

JMM还规定了8中基本操作时必须满足如下规则：

+ 不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者工作内存发起回写操作但主内存不接受的情况。
+ 不允许一个线程丢弃它最近的assign操作，即变量在工作内存中改变了必须把变化同步会主内存。
+ 不允许一个线程无原因地(没发生过任何assign操作)把变量从工作内存同步回主内存。
+ 一个新的变量只能在主内存中"产生"，不允许在工作内存中直接使用一个未被初始化(load或assign)的变量，换句话说就是对一个变量实施use、store操作之前，必须执行assign和load操作。
+ 一个变量在同一时刻只允许一个线程对其进行lock操作，但lock操作可以被同一个线程重复执行多次，多次执行lock操作后，必须执行相同次数的unlock操作才能解锁。
+ 如果对一个变量执行lock操作，将会清空工作内存中该变量的值，在执行引擎使用这个变量前，需要重新执行load或assign以初始化变量的值。
+ 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定的变量。
+ 对一个变量执行unlock操作之前，必须先把该变量同步会主内存中(执行store、write操作)。

为了准确地描述出Java程序那些内存访问操作在并发下是安全的。

#### volatile特殊规则

​	被volatile修饰的变量具有可见性和有序性(禁止指令重排序)，但不具有原子性。

​	可见性保证：因为volatile变量每次使用时都会进行read、load操作从主内存读取变量值，每次修改时都会进行store、write操作将变量的值同步回主内存中，因此volatile的值对所有线程是立刻可见的。

​	有序性保证（禁止指令重排序）：通过对比volatile变量和非volatile变量赋值的字节码可以发现，volatile变量赋值后会多执行一个"lock addl $0x0,(%esp)"操作，这个操作相当于一个内存屏障保证(Memory Barrier/Memory Fence，指令重排序时不能把后面的指令重排序到内存屏障之前的位置)。"lock addl $0x0,(%esp)"(把ESP寄存器的值加0)是一个空操作，不适用空操作专用指令nop是因为规定lock前缀不允许配合nop执行。lock前缀会将本处理器的缓存写入到内存中，相当于进行了store和write操作，可以让volatile变量的修改对其他处理器立刻可见。指令重排序无法对有依赖关系的数据进行排序，"lock addl $0x0,(%esp)"刷新缓存时，代表之前有数据依赖的操作都已生效，这样就筑起了“内存屏障”。

JMM对volatile变量定义的特殊规则

+ 要求use、load、read操作必须连续且一起出现。每次都能从主内存中获取最新的变量值。
+ 要求assign、store、write操作必须连续且一起出现。每次修改都能立刻同步会主内存。
+ 同一线程中，先对volatile变量A进行了use或assign操作，后对volatile变量B进行了use或assign操作，那么变量A的read或write操作先于变量B的read或write操作。规定volatile修饰的变量不会被指令重排序优化，从而保证代码的执行顺序和程序的顺序相同。

#### 针对long和double变量的特殊规则

​	JMM允许JVM对未被volatile修饰的64位数据读写分为两次32位的操作来进行。

#### 原子性、可见性和有序性

​	JMM围绕着在并发过程中如何处理原子性、可见性和有序性这三个特征建立的。下面罗列了哪些操作实现了这三个特性

​	原子性：JMM直接保证的原子性操作包括read、load、use、assign、store、write这六个。如果需要更大范围的原子性保证可以使用lock和unlock，JVM未暴露这两个操作，但提供了更高层次的字节码指令monitorenter和moniterexit来隐式地操作。这两个字节码指令对应着synchronized关键字。

​	可见性：volatile变量由每次读主内存的值，每次将修改写回主内存保证。synchronized由 对一个变量执行unlock操作之前，必须先把该变量同步会主内存中(执行store、write操作) 规则保证。final修饰的字段在构造器中一旦初始化完成，且构造器没将”this“的引用传递出去，其他线程就能看到final字段的值。

​	有序性：Java中，如果在本线程内观察，所有的操作都是有序的(线程内表现为串行的语义)；如果在一个线程内观察另一个线程，所有的操作都是无需的(指令重排序和工作内存和主内存同步延迟)。volatile变量通过内存屏障保证。synchronized由 一个变量在同一时刻只允许一个线程对其进行lock操作 规则保证。

#### 先行发生规则

​	先行发生时Java内存模型中定义的亮相操作之间的偏序关系，比如操作A先行发生于操作B，就是说操作B发生之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。通过先行发生规则，我们可以通过几个简单的规则一揽子解决并发环境下两个操作之间是否可能存在冲突的所有问题。

​	Java内存模型中有一些“天然的”先行发生关系，这些关系无须任何同步器协助便已存在，可以在编码中直接使用。

+ 程序次序规则（Program Order Rule）：在一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作。注意，这里说的是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。

+ 管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是“同一个锁”，而“后面”是指时间上的先后。

+ volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面对这个变量

  的读操作，这里的“后面”同样是指时间上的先后。

+ 线程启动规则（Thread Start Rule）：Thread对象的start()方法先行发生于此线程的每一个动作。

+ 线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread::join()方法是否结束、Thread::isAlive()的返回值等手段检测线程是否已经终止执行。

+ 线程中断规则（Thread Interruption Rule）：对线程interrupt()方法的调用先行发生于被中断线程

  的代码检测到中断事件的发生，可以通过Thread::interrupted()方法检测到是否有中断发生。

+ 对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的

  finalize()方法的开始。

+ 传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出

  操作A先行发生于操作C的结论。

Java语言无须任何同步手段保障就能成立的先行发生规则有且只有上面这些。

​	时间先后顺序与先行发生(逻辑上的发生)原则之间基本没有因果关系，所以我们衡量并发安全问题的时候不要受时间顺序的干扰，一切必须以先行发生原则为准。如根据程序次序规则，代码是按控制流顺序执行，但是因为即时编译器的重排序，导致代码的顺序改变，但是这并不影响先行发生规则的正确性，因为我们在这条线程之中没有办法感知到这一点。

## Java与线程

​	并发并不一定要依赖于多线程(多进程并发)，但是在Java中并发基本上都离不开多线程。在操作系统中，进程是资源分配的最小单位，线程是调度执行的最小单位。一个进程可以包含多个线程。

​	目前，线程是Java里面进行处理器资源调度的最小单位，如果日后Loom项目能为Java引入纤程(Fiber)的话，协程就能成为调度的最小单位。Java屏蔽了各平台线程操作的差异性，提供了Thread类，通过调用start()来开启一个线程。Thread类大部分方法都被native修饰，代表通过和平台相关的手段来实现线程。

### 线程的实现

​	实现线程的主要方式有三种：使用内核线程实现(1:1)，使用用户线程实现(1:N)，使用用户线程加轻量级进程混合实现(M:N)。

	#### 内核线程实现

​	内核线程(Kernel-Level Thraed，KLT)就是有操作系统内核(Kernel)支持的线程，这种线程由内核来完成线程切换，内核通过操作调度器(Scheduler)对线程进行调度，并负责将线程的任务人设到各个处理器上(CPU)。

​	程序一般不会直接使用内核线程，而是使用内核线程的一个高级接口-轻量级进程(Light Weight Process, LWP)，轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才有轻量级进程。

```
        P							 P
LWP    LWP     LWP              LWP     LWP
 |      |       |                |       |
KLT    KLT     KLT              KLT     KLT

                 |       |      |
                 Thread Scheduler
                  |	    |      |
                 CPU   CPU     CPU
```

​	由于内核线程的支持，每个轻量级进程成为一个独立的调度单元，即使其中一个被系统阻塞，也不影响整个进程继续执行。轻量级进程由自己的局限性：

+ 由于基于内核线程实现，所以线程的各种操作(创建、析构和同步)都要进行系统调用。而系统调用需要在用户态和内核态切换，代价较高(主要开销来自于响应中断、保护和恢复执行现场的成本)。
+ 由于每个轻量级进程都需要一个内核线程支持，因此轻量级进程需要消耗一定的内核资源(内核线程的栈空间)，因此一个系统支持的轻量级进程数量有限。

#### 用户线程

​	广义上讲，一个线程只要不是内核线程，都可以认为是用户线程(User Thread, UT)的一种。从这中定义上看，轻量级进程属于用户线程，但是由于基于内核线程，许多操作要进行系统调用，因此效率受限，不具备通常意义上用户线程的优点。

​	狭义上讲，用户线程是指完全建立在用户空间的线程库上，系统内核感知不到用户线程的存在及实现。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要切换到内核态，因此操作可以是非常快且低消耗，也能够支持更大规模的线程数量。

```
UT   UT   UT                   UT    UT
     P                             P
                  CPU
```

​	用户线程的优势在于不需要内核线程的支持，劣势也是由于缺少内核线程的支持，所有的线程操作都需要用户线程去处理。线程的创建、销毁、切换和调度都是用户必须考虑的问题，而且由于操作系统只把处理器资源分配到进程，那诸如“阻塞如何处理”，“多处理器系统中如何将线程映射到其他处理器上”这类问题解决是异常困难的，甚至无法解决。

#### 混合实现

​	即轻量级进程和用户线程并存。用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并且可以支持大规模的用户线程并发。而操作系统支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核线程的线程调度及处理器映射，并且用户线程的系统调用通过轻量级进程来完成，大大降低了整个进程被阻塞的风险。

```
UT      UT      UT
    LWP    LWP
    
    KLT    KLT
   Thread Scheduler
CPU   CPU      CPU   
```

#### Java线程的实现

​	Java线程如何实现不受Java虚拟机规范的约束。Java线程在早期的Classic虚拟机上，是基于一种被称为"绿色线程"的用户线程实现，后来主流的JVM线程模型慢慢都被替换成基于内核线程的实现。

### Java线程调度

​	线程调度是指系统为线程分配处理器使用权的过程。

	#### 协同式线程调度

​	线程的执行时间由线程本身来控制，线程把自己的工作执行完之后，要主动通知系统切换到另一个线程上区。协调式多线程的最大好处是实现简单，而且由于线程要把自己的事情都干完后才会进行线程切换，切换线程操作对于线程是可知的，所有一般不会有线程同步的问题。

​	缺点为线程执行时间不可控，甚至如果线程的代码编写有问题，一直不告知系统进行线程切换，那么程序会一直阻塞在那里。

#### 抢占式线程调度

​	线程的执行时间由系统来分配，线程的切换不由线程本身决定。线程可以出让执行时间，但不能主动获取执行时间。在这种方式下，线程的执行时间是系统可控的，也不会有一个线程导致整个进程或者整个系统阻塞的问题。Java就是采用抢占式线程的调度。

### Java线程状态

​	Java语言定义了6中线程状态，任一时间点中，一个线程有且只有一种状态。

	+	新建(New)：创建后尚未启动(Thread#start方法)的线程。
	+	运行(Runable)：调用Thread#start方法后，线程会处于运行态。该状态对应操作系统线程状态中的Running和Ready，该状态的线程可能处于执行中，也可能正在等待分配执行时间。
	+	无期限等待(Wating)：处于这种状态的线程不会被分配处理器执行时间，他们需要等待被其他线程显式唤醒(Object#notify/Object#notifyAll)。调用Object#wait/Thread#join/LockSupport#park方法会进入此状态。
	+	有期限等待(Timed Waitting)：处于这种状态的线程不会被分配处理器执行时间，不过无需等待被其他线程显式唤醒，在一定时间后会由系统自动唤醒。调用Object#wait(Timeout)/Thread#join调用Object#wait/Thread#join/LockSupport#park方法会进入此状态。/LockSupport#parkNanos/LockSupport#parkUntil方法会进入此状态。
	+	阻塞(Blocked)：线程被阻塞了，与等待状态的区别是阻塞状态在等待获取一个排它锁。
	+	结束(Terminated)：已终止线程的线程状态，线程已经结束执行。

```
状态转换图
New  					|---synchronized--->      Blocked
|						|
|----start()-->      Runable     ---sleep()--->   Timed Waitting
						|				 
						|				 
Wating		 <--wait()--|	     ---run()结束--->  Terminated
```

### 协程

​	当今对Web应用的服务要求不论是请求数量上还是复杂度上，对比十年前已经不可同日口语。一方面源于业务量的增长，另一方面源于为了应对业务复杂化而不断进行的服务细分。现代B/S系统对一次外部业务请求的相应，往往需要分布在不同机器上的大量服务共同协助来实现，这种服务细分的架构在减少单个服务复杂性、增加复用性的同时，也不可避免地增加了服务的数量，缩短了留给每个服务的响应时间。这要求每一个服务都必须在极短的时间内完成计算，也要求服务提供者能同时处理数量更庞大的请求，这样才不会出现请求由于某个服务被阻塞而出现等待。

​	这种情形下，当前的线程模型不足以支撑(64位Linux HotSpot给线程栈默认容量为1M，内存不足以支撑更大规模的线程，并且当线程多时，线程切换也会浪费很多资源)。因此需要更轻量级的线程，也就是协程。协程类比用户线程，更小，而且不用用户态和内核态切换，省资源，缺点为要自己写调度等操作。

​	Java将来可能会引入Loom项目的纤程(Fiber)。

## 线程安全与锁优化

​	高效并发要求在保证并发正确性的基础上，来实现高效。线程安全可以借鉴《Java并发编程实战》中的比较恰当的定义：“当多个线程同时访问同一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要额外的同步、或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获取正确的结果，那就称这个而对象是线程安全的”。可以简单理解为，多个线程对共享数据协调工作时，无需考虑线程的调度情况，得到的结果唯一且符合预期。

### Java语言中的线程安全

#### 不可变

​	在Java语言中，不可变(Immutable)对象一定是线程安全的。final关键字。

#### 绝对线程安全

​	满足上述线程安全的定义，即“不管运行时环境如何，调用者都不需要任何额外的同步措施”。

#### 相对线程安全

​	Java API中标注自己是线程安全的类，大多数是处于该级别。该级别保证对这个对象单次的操作是线程安全的，调用时无需进行额外的保障措施，但是对于一些特定顺序的调用，需要调用者使用额外的同步手段来保证。

#### 线程兼容

​	指对象本身并不是线程安全的，但是通过调用者正确地使用同步手段可以保证对象在并发环境中可以安全使用。

#### 线程对立

​	不管调用者是否采取同步措施，都无法保证线程安全。

### 线程安全的实现方法

#### 互斥同步

​	互斥同步(Mutual Exclusion & Synchorization)是一种最常见也是最主要的并发正确性保障手段。同步是指在多个线程并发访问共享数据时，保证共享数据在同一时刻只被一条(或者一些，使用信号量时)线程使用。而互斥时实现同步的一种手段，临界区(Critical Section)、互斥量(Mutex)、信号量(Semaphore)都是常见的互斥实现方式。因此互斥同步中，互斥是因，同步是果；互斥是方法，同步是目的。

​	Java提供了synchorized关键字来提供互斥同步，synchorized关键字在经过javac编译后，会在同步块前后生成monitorenter和monitorexit两个字节码指令。

​	JDK5引入了JUC，提供了Lock接口的实现ReentrantLock，相比于synchorized关键字，ReentrantLock有三种高级功能:

	+	等待可中断：当持有锁的下次你哼长期不释放锁时，正在等待的线程可以选择放弃等待，改为处理其他事情。可中断特性对于处理器执行时间非常长的同步块很有帮助。
	+	公平锁：当多个线程在等待同一个锁时，需要排队来依次获得锁。非公平锁是谁抢到算谁的，相比于公平锁，性能会好些。ReentrantLock支持公平锁，synchorized关键字只支持非公平锁。
	+	锁绑定多个条件：一个ReentrantLock对象可以绑定多个Condition对象。synchorized关键字中，锁对象的wait()和notify()/notifyAll()方法配合可以实现且只能实现一个隐含的条件。

​	synchorized关键字在JDK6添加了大量锁优化的手段，性能方面不会相差ReentrantLock很多，并且synchorized关键字的加锁解锁由JVM来管理，无需程序员介入，而且JVM针对synchorized关键字更方便做优化。因此如果不是为了上面三种高级功能，尽量使用synchorized关键字。

#### 非阻塞同步

​	互斥同步最主要的问题就是进行线程阻塞和唤醒所需要的性能开销，因此互斥同步也被称为阻塞同步。互斥同步属于一种悲观的并发策略，认为每次操作数据时都会有竞争，因此会先加锁后操作。

​	随着硬件指令集的发展(CAS处理器指令的出现)，我们可以使用基于冲突检测的乐观并发策略，认为每次操作都没有竞争，因此先操作后判断是否冲突，无冲突操作就成功了，有冲突在进行其他补偿措施。

​	JDK5之后，Java类库才开始使用CAS操作，由Unsafe提供，但是用户程序无法调用，想使用只能通过反射。JDK9之后提供给了用户程序。

#### 无同步方案

​	同步只是保障存在共享数据争用时正确性的手段，如果不存在共享数据，那它就不需要任何同步措施去保证其正确性。

​	Java提供了ThreadLocal，允许将数据保存在线程中，因此线程的数据是不共享的，因此线程安全。

### 锁优化

#### 自旋锁与自适应锁

​	经观察，在很多应用中，共享数据的锁定状态指挥持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得。因此当一个线程请求锁时，可以让其“等待一会”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。

​	自旋锁在JDK1.4.2中引入，默认关闭，需要通过-XX:+UseSpinning参数开启，在JDK6中默认开启。自选等待不能代替阻塞，线程本身一直在浪费处理器的执行时间，因此不能无限制自选等待。自旋次数默认时是十次，可以通过参数-XX:PreBlockSpin来更改。

​	但是每个锁的情况都不一样，设定的固定值并不一定最优。因此在JDK6中对自旋锁进行了优化，引入了自适应的自旋。即如果上次等待获取该锁成功了，就认为这次可能还会成功，就多等会。如果上次等待锁获取该锁失败了，这次等待时间就短点，甚至是以后不等待，直接阻塞。

#### 锁消除

​	指虚拟机即时编译器在运行时检测到某段需要同步的代码根本不可能存在共享数据竞争而实施的一种对所进行消除的优化策略。

​	如单线程中使用StringBuffer进行字符串拼接。

#### 锁粗化

​	原则上，编写代码时将同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步，这样是为了将需要同步的操作数量变小，即时存在锁竞争，也能快速的释放锁。

​	但是对于一系列的连续操作都对一个对象反复进行加锁和解锁，那即时没有线程竞争，频繁地进行互斥操作也会导致不必要的性能损耗。此时虚拟机会将锁的范围扩大，避免重复对一个对象加锁解锁。

#### 轻量级锁

​	轻量级锁是JDK6引入的，它的设计初衷是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。

​	加锁：在代码块即将进入同步块的时候，如果此同步对象没有被锁定，虚拟机将会在当前线程的栈帧中建立一个锁记录(Lock Record)，用于存储锁对象目前的Mark Word的拷贝，然后虚拟机使用CAS将锁对象的Mark Word更新为指向Lock Record的指针。如果更新成功，代表该线程拥有该锁(锁对象标示变为00)，如果更新失败检查锁对象的Mark Word的指针是否指向当前线程的栈帧，如果是，代表拥有该锁，继续执行。否则轻量级锁膨胀为重量级锁(锁对象标示变为10)，此时锁对象Mark Word中存储的是指向重量级锁的指针，后面的等待线程必须进入阻塞状态。

​	解锁：解锁也通过CAS实现，如果锁对象的Mark Word仍指向线程的锁记录，则会通过CAS将Mark Word和锁记录进行交换，交换成功则代表整个同步过程顺利完成。如果交换失败，则说明有其他线程来尝试获取过锁(锁会膨胀为重量级锁)，此时解锁需要唤醒被阻塞的线程。

#### 偏向锁

​	偏向锁也是JDK6引入的锁优化措施，它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的性能。如果说轻量级锁实在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS操作都不用做。

​	当锁对象第一次被线程获取时，虚拟机会使用CAS将获取该锁的线程ID记录到锁对象的Mark Word，后续持有该锁的线程进入同步块时不需要任何同步操作。

​	当其他线程去获取这个锁时，偏向模式马上结束。如果该锁现在被锁定，则升级为轻量级锁。否则则恢复到未锁定状态。

 	当对象进入偏向状态时，Mark Word大部分空间(23bit)用来存储ThreadId，这部分空间原来存储的对象哈希值如何处理？

​	正常状态对象一开始时没有hashCode的，第一次调用才生成。当对象计算过哈希值后，就不能进入偏向状态。在偏向状态的对象计算哈希值时，会立即膨胀为重量级锁，Mark Word存重量级锁的指针，代表重量级锁的ObjectMonitor类有字段存哈希值。轻量级锁的锁记录中存锁对象的Mark Word，也有哈希值。
